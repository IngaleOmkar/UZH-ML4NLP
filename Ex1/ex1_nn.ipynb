{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/Andrian0s/ML4NLP1-2024-Tutorial-Notebooks/blob/main/exercises/ex1/ex1_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"Q-2GcUhgB0S7"},"source":["# ML4NLP1\n","## Starting Point for Exercise 1, part II\n","\n","This notebook is supposed to serve as a starting point and/or inspiration when starting exercise 1, part II.\n","\n","One of the goals of this exercise is o make you acquainted with **skorch**. You will probably need to consult the [documentation](https://skorch.readthedocs.io/en/stable/)."]},{"cell_type":"markdown","metadata":{"id":"V920LTuiq40d"},"source":["# Installing skorch and loading libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:24:51.965250Z","iopub.status.busy":"2024-10-09T08:24:51.964828Z","iopub.status.idle":"2024-10-09T08:24:51.976929Z","shell.execute_reply":"2024-10-09T08:24:51.976044Z","shell.execute_reply.started":"2024-10-09T08:24:51.965205Z"},"id":"utYcb97jq40t","trusted":true},"outputs":[],"source":["import subprocess\n","\n","# Installation on Google Colab\n","try:\n","    import google.colab\n","    subprocess.run(['python', '-m', 'pip', 'install', 'skorch'])\n","except ImportError:\n","    pass"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:24:51.979164Z","iopub.status.busy":"2024-10-09T08:24:51.978860Z","iopub.status.idle":"2024-10-09T08:25:15.377566Z","shell.execute_reply":"2024-10-09T08:25:15.376528Z","shell.execute_reply.started":"2024-10-09T08:24:51.979133Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: skorch in /opt/conda/lib/python3.10/site-packages (1.0.0)\n","Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from skorch) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from skorch) (1.2.2)\n","Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from skorch) (1.14.1)\n","Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from skorch) (0.9.0)\n","Requirement already satisfied: tqdm>=4.14.0 in /opt/conda/lib/python3.10/site-packages (from skorch) (4.66.4)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->skorch) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->skorch) (3.5.0)\n","Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\n","Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n"]}],"source":["!pip install skorch\n","!pip install gdown"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:25:15.379359Z","iopub.status.busy":"2024-10-09T08:25:15.379001Z","iopub.status.idle":"2024-10-09T08:25:18.001077Z","shell.execute_reply":"2024-10-09T08:25:18.000228Z","shell.execute_reply.started":"2024-10-09T08:25:15.379310Z"},"id":"WZ3Y_KHvq40x","trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from skorch import NeuralNetClassifier\n","\n","import pandas as pd\n","import numpy as np\n","import csv\n","import re\n","import string\n","from collections import defaultdict\n","\n","# Set seed for reproducibility\n","seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"dAnY8yaDq400"},"source":["## Training a classifier and making predictions"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-09T08:25:18.002883Z","iopub.status.busy":"2024-10-09T08:25:18.002306Z","iopub.status.idle":"2024-10-09T08:25:39.728851Z","shell.execute_reply":"2024-10-09T08:25:39.727752Z","shell.execute_reply.started":"2024-10-09T08:25:18.002829Z"},"id":"zWjt9xGoswAC","outputId":"5e9f1bd0-c578-4591-bb31-a31a6626c971","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs\n","To: /kaggle/working/x_train.txt\n","100%|███████████████████████████████████████| 64.1M/64.1M [00:00<00:00, 206MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6\n","To: /kaggle/working/x_test.txt\n","100%|███████████████████████████████████████| 65.2M/65.2M [00:00<00:00, 231MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl\n","To: /kaggle/working/y_train.txt\n","100%|█████████████████████████████████████████| 480k/480k [00:00<00:00, 109MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X\n","To: /kaggle/working/y_test.txt\n","100%|█████████████████████████████████████████| 480k/480k [00:00<00:00, 111MB/s]\n"]}],"source":["# Download dataset\n","!gdown 1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs # x_train\n","!gdown 1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6 # x_test\n","!gdown 1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl # y_train\n","!gdown 1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X # y_test"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:25:39.733004Z","iopub.status.busy":"2024-10-09T08:25:39.732677Z","iopub.status.idle":"2024-10-09T08:25:41.382737Z","shell.execute_reply":"2024-10-09T08:25:41.381846Z","shell.execute_reply.started":"2024-10-09T08:25:39.732971Z"},"id":"-M6DgXdjtJyH","trusted":true},"outputs":[],"source":["with open(f'x_train.txt') as f:\n","    x_train = f.read().splitlines()\n","with open(f'y_train.txt') as f:\n","    y_train = f.read().splitlines()\n","with open(f'x_test.txt') as f:\n","    x_test = f.read().splitlines()\n","with open(f'y_test.txt') as f:\n","    y_test = f.read().splitlines()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"execution":{"iopub.execute_input":"2024-10-09T08:25:41.384247Z","iopub.status.busy":"2024-10-09T08:25:41.383923Z","iopub.status.idle":"2024-10-09T08:25:43.521161Z","shell.execute_reply":"2024-10-09T08:25:43.520220Z","shell.execute_reply.started":"2024-10-09T08:25:41.384215Z"},"id":"oRqfDA9FuoX1","outputId":"23c71978-d23f-48e5-88ad-f36308461277","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Klement Gottwaldi surnukeha palsameeriti ning ...</td>\n","      <td>est</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sebes, Joseph; Pereira Thomas (1961) (på eng)....</td>\n","      <td>swe</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...</td>\n","      <td>mai</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Après lo cort periòde d'establiment a Basilèa,...</td>\n","      <td>oci</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...</td>\n","      <td>tha</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text label\n","0  Klement Gottwaldi surnukeha palsameeriti ning ...   est\n","1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....   swe\n","2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...   mai\n","3  Après lo cort periòde d'establiment a Basilèa,...   oci\n","4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...   tha"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Combine x_train and y_train into one dataframe\n","train_df = pd.DataFrame({'text': x_train, 'label': y_train})\n","# Write train_df to csv with tab as separator\n","train_df.to_csv('train_df.csv', index=False, sep='\\t')\n","# Comibne x_test and y_test into one dataframe\n","test_df = pd.DataFrame({'text': x_test, 'label': y_test})\n","# Inspect the first 5 items in the train split\n","train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"-s_6f3E7Kt0s"},"source":["### Data preparation\n","\n","Prepare your dataset for this experiment using the same method as you did in part 1.\n","\n","Get a subset of the train/test data that includes 20 languages. Include English, German, Dutch, Danish, Swedish, Norwegian, and Japanese, plus 13 additional languages of your choice based on the items in the list of labels.\n","\n","Don't forget to encode your labels using the adjusted code snippet from part 1!\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-09T08:25:43.523302Z","iopub.status.busy":"2024-10-09T08:25:43.522542Z","iopub.status.idle":"2024-10-09T08:25:43.882595Z","shell.execute_reply":"2024-10-09T08:25:43.881607Z","shell.execute_reply.started":"2024-10-09T08:25:43.523254Z"},"id":"PXpIOpjRxzTl","outputId":"f1c4f2eb-8422-465b-e988-3d02c9bc1f1f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['銀行券は帝国国庫及びドイツ帝国銀行(Reichsbank)から発行され、帝国のいくつかの構成国の銀行からも発行された。帝国国庫発行の帝国紙幣(Reichskassenschein)は5、10、20、50マルクが発行された一方、ドイツ帝国銀行券(Reichsbanknote)は20、50、100、1000マルクが発行された。1914年以降に発行されたこれらの銀行券はパピエルマルクと呼ばれる。', 'في عام 2007، كرئيس أساقفة و كاردينال بوينس آيرس، قدم بيرجوليو النسخة النهائية من البيان المشترك الصادر عن أساقفة أمريكا اللاتينية المسمى \"وثيقة أباريسيدا\" بعد إقراره من قبل البابا بندكت السادس عشر. نصت الوثيقة على ضرورة الامتثال و قبول تعاليم الكنيسة ضد \"جرائم نكراء\" مثل الإجهاض والقتل الرحيم: \"نأمل أن المشرعين ورؤساء الحكومات، والعاملين في مجال الصحة، سيدركون كرامة الحياة الإنسانية وأهمية العائلة في شعوبنا، و سيدافعون عن حمايتها من جرائم نكراء مثل الإجهاض والقتل الرحيم، وهذه هي مسؤوليتهم. ونحن نلزم أنفسنا \"تماسك إفخارستي\"، بما معناه، يجب أن نكون واعين بأن الناس لا يستطيعون الحصول على القربان المقدس وفي الوقت نفسه هم يعملون ضد الوصايا، ولا سيما عندما يوافقون على الإجهاض والقتل الرحيم، وغيرها من الجرائم الخطيرة ضد الحياة والعائلة، وهو ينطبق بشكل خاص على مسؤولية المشرعين والحكام، والعاملين في مجال الصحة\". وقد وصف الحركة المؤيدة للإجهاض باعتباره \"ثقافة الموت\"، و كان يعارض توزيع وسائل منع الحمل مجانًا في الأرجنتين.', 'Luis Alberto Suárez Díaz (s. 24. tammikuuta 1987 Salto, Uruguay) on uruguaylainen jalkapalloilija, joka pelaa hyökkääjänä tai oikeana laitalinkkinä Barcelonassa ja edustaa myös Uruguayn maajoukkuetta. Suárez tunnetaan lempinimellä El Pistolero (suom. revolverisankari).', \"Bij installatie zal een instantienaam en een aantal poortnummers worden bepaald. De instantienaam bestaat uit twee tekens en moet beginnen met een letter. Deze code zal gebruikt worden om te berekenen op welke poorten de Ingres Servers zal luisteren. Standaard zal er gebruikgemaakt worden van de de code 'll', welke zal luisteren naar de poorten 21064 tot 21071.\", '1951年5月14日，联合国大会额外措施委员会通过了美国提出的对中华人民共和国和朝鲜民主主义人民共和国实行禁运的提案。5月18日该提案被联合国大会表决通过为联合国大会500号决议“ADDITIONAL MEASURES TO BE EMPLOYED TO MEET THE AGRESSION IN KOREA”。5月22日，中国政府外交部就联大500号决议发表声明，指出这是联大“又一破坏联合国宪章，侵越安全理事会权限并蓄意扩大侵略战争的非法行动”。43个国家接受联大500号决议并加以实行。中国从西方国家的进口额，1952年比1951年下跌了四成。1951年5月，政务院发布允许对外资企业征用或征购。']\n","['jpn', 'ara', 'fin', 'nld', 'zho']\n"]}],"source":["# TODO: Create your train/test subsets of languages\n","# Note, make sure these are the same as what you used in Part 1!\n","\n","from sklearn.model_selection import train_test_split\n","\n","# TODO: Create your train/test subsets of languages\n","language_filter = ['eng','deu','nld','dan','swe','nob','jpn', #basics\n","                   'fra', 'spa', 'rus', 'por', 'ita', 'kor', 'ara', 'zho', 'hin', 'tam', 'tha', 'vie', 'fin' #additionals\n","                   ]\n","# Filter x and y based on the language filter\n","filtered_x = [text for text,label in zip(x_train + x_test,y_train + y_test) if label in language_filter]\n","filtered_y = [label for label in y_train + y_test if label in language_filter]\n","\n","# Split the train/test data into 8:2\n","x_train,x_test,y_train,y_test = train_test_split(filtered_x,filtered_y,test_size = 0.2,random_state=42)\n","\n","#display\n","print(x_train[:5])\n","print(y_train[:5])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-09T08:25:43.884211Z","iopub.status.busy":"2024-10-09T08:25:43.883874Z","iopub.status.idle":"2024-10-09T08:25:43.914834Z","shell.execute_reply":"2024-10-09T08:25:43.913943Z","shell.execute_reply.started":"2024-10-09T08:25:43.884174Z"},"id":"vMp0gji4MCDl","outputId":"11406782-1d32-41ab-fc28-605994b5bdd9","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['ara' 'dan' 'deu' 'eng' 'fin' 'fra' 'hin' 'ita' 'jpn' 'kor' 'nld' 'nob'\n"," 'por' 'rus' 'spa' 'swe' 'tam' 'tha' 'vie' 'zho']\n","[ 8  0  4 ... 19 18  1]\n","[ 7 15 12 ...  1  1  0]\n"]}],"source":["# TODO: Use your adjusted code from part 1 to encode the labels again\n","from sklearn.preprocessing import LabelEncoder\n","\n","label_encoder = LabelEncoder().fit(y_train)\n","y_train, y_test = label_encoder.transform(y_train), label_encoder.transform(y_test)\n","print(label_encoder.classes_)\n","print(y_train)\n","print(y_test)"]},{"cell_type":"markdown","metadata":{"id":"iGBLxHU-LcVL"},"source":["### Feature Extraction"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:25:43.916409Z","iopub.status.busy":"2024-10-09T08:25:43.916010Z","iopub.status.idle":"2024-10-09T08:25:48.586161Z","shell.execute_reply":"2024-10-09T08:25:48.585116Z","shell.execute_reply.started":"2024-10-09T08:25:43.916365Z"},"id":"2-Ls0e0GQgMF","trusted":true},"outputs":[],"source":["# First, we extract some simple features as input for the neural network\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2), max_features=100, binary=True)\n","X = vectorizer.fit_transform(x_train)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:25:48.587798Z","iopub.status.busy":"2024-10-09T08:25:48.587459Z","iopub.status.idle":"2024-10-09T08:25:48.613902Z","shell.execute_reply":"2024-10-09T08:25:48.612957Z","shell.execute_reply.started":"2024-10-09T08:25:48.587765Z"},"id":"9EiRal_1Q0iJ","trusted":true},"outputs":[],"source":["# We need to change the datatype to make it play nice with pytorch\n","X = X.astype(np.float32)\n","y = y_train.astype(np.int64)"]},{"cell_type":"markdown","metadata":{"id":"oMFoiitJq407"},"source":["In the following, we define a vanilla neural network with two hidden layers. The output layer should have as many outputs as there are classes. In addition, it should have a nonlinearity function."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:25:48.615282Z","iopub.status.busy":"2024-10-09T08:25:48.614980Z","iopub.status.idle":"2024-10-09T08:25:48.622868Z","shell.execute_reply":"2024-10-09T08:25:48.621834Z","shell.execute_reply.started":"2024-10-09T08:25:48.615250Z"},"id":"7Q5EDIGQUUBy","trusted":true},"outputs":[],"source":["# TODO: In the following, you can find a small (almost) working example of a neural network.\n","# Unfortunately, again, the cat messed up some of the code. Please fix the code such that it is executable. (Hint: the input and output sizes look a bit weird...)\n","\n","class ClassifierModule(nn.Module):\n","    def __init__(\n","        self,\n","        num_units=200,\n","        nonlin=F.relu,\n","        num_classes=20,\n","        input_size=100,\n","    ):\n","        super(ClassifierModule, self).__init__()\n","        self.num_units = num_units\n","        self.nonlin = nonlin\n","\n","        self.dense0 = nn.Linear(input_size, num_units)\n","        self.nonlin = nonlin\n","        self.dense1 = nn.Linear(num_units, 50)\n","        self.output = nn.Linear(50, num_classes)\n","\n","    def forward(self, X, **kwargs):\n","        X = self.nonlin(self.dense0(X))\n","        X = F.relu(self.dense1(X))\n","        X = self.output(X)\n","        return X.squeeze(dim=1)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:25:48.624406Z","iopub.status.busy":"2024-10-09T08:25:48.624078Z","iopub.status.idle":"2024-10-09T08:25:48.638249Z","shell.execute_reply":"2024-10-09T08:25:48.637532Z","shell.execute_reply.started":"2024-10-09T08:25:48.624370Z"},"id":"wKnJECeQGpyI","trusted":true},"outputs":[],"source":["# Initalise the neural net classifier.\n","net = NeuralNetClassifier(\n","    ClassifierModule(\n","        input_size=X.shape[1],\n","        num_units=200,\n","        num_classes=len(label_encoder.classes_),\n","        nonlin=F.relu,\n","    ),\n","    max_epochs=20,\n","    criterion=nn.CrossEntropyLoss(),\n","    lr=0.1,\n","    device='cuda',  # comment this to train with CPU\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-09T08:25:48.639658Z","iopub.status.busy":"2024-10-09T08:25:48.639318Z","iopub.status.idle":"2024-10-09T08:26:23.136285Z","shell.execute_reply":"2024-10-09T08:26:23.135198Z","shell.execute_reply.started":"2024-10-09T08:25:48.639626Z"},"id":"QcNOd9yBSxys","outputId":"53b79f0e-c2fe-4bb0-e230-ee63200e3281","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7376\u001b[0m       \u001b[32m0.2303\u001b[0m        \u001b[35m2.4827\u001b[0m  1.8264\n","      2        \u001b[36m2.1024\u001b[0m       \u001b[32m0.4122\u001b[0m        \u001b[35m1.7188\u001b[0m  1.6383\n","      3        \u001b[36m1.5182\u001b[0m       \u001b[32m0.5319\u001b[0m        \u001b[35m1.3270\u001b[0m  1.6527\n","      4        \u001b[36m1.2503\u001b[0m       \u001b[32m0.6306\u001b[0m        \u001b[35m1.1424\u001b[0m  1.6323\n","      5        \u001b[36m1.0864\u001b[0m       \u001b[32m0.6506\u001b[0m        \u001b[35m1.0249\u001b[0m  1.6339\n","      6        \u001b[36m0.9856\u001b[0m       \u001b[32m0.6606\u001b[0m        \u001b[35m0.9579\u001b[0m  1.6523\n","      7        \u001b[36m0.9264\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.9192\u001b[0m  1.7078\n","      8        \u001b[36m0.8891\u001b[0m       \u001b[32m0.6753\u001b[0m        \u001b[35m0.8941\u001b[0m  1.7495\n","      9        \u001b[36m0.8632\u001b[0m       \u001b[32m0.6787\u001b[0m        \u001b[35m0.8764\u001b[0m  1.6792\n","     10        \u001b[36m0.8434\u001b[0m       \u001b[32m0.6819\u001b[0m        \u001b[35m0.8627\u001b[0m  1.6645\n","     11        \u001b[36m0.8274\u001b[0m       \u001b[32m0.6837\u001b[0m        \u001b[35m0.8522\u001b[0m  1.6592\n","     12        \u001b[36m0.8140\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.8439\u001b[0m  1.6481\n","     13        \u001b[36m0.8026\u001b[0m       \u001b[32m0.6897\u001b[0m        \u001b[35m0.8367\u001b[0m  1.6638\n","     14        \u001b[36m0.7927\u001b[0m       \u001b[32m0.6919\u001b[0m        \u001b[35m0.8308\u001b[0m  1.7095\n","     15        \u001b[36m0.7841\u001b[0m       \u001b[32m0.6941\u001b[0m        \u001b[35m0.8262\u001b[0m  1.6220\n","     16        \u001b[36m0.7761\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.8223\u001b[0m  1.6867\n","     17        \u001b[36m0.7692\u001b[0m       0.6950        \u001b[35m0.8199\u001b[0m  1.6479\n","     18        \u001b[36m0.7627\u001b[0m       0.6937        \u001b[35m0.8176\u001b[0m  1.6457\n","     19        \u001b[36m0.7570\u001b[0m       \u001b[32m0.6966\u001b[0m        \u001b[35m0.8155\u001b[0m  1.6677\n","     20        \u001b[36m0.7515\u001b[0m       \u001b[32m0.6972\u001b[0m        \u001b[35m0.8143\u001b[0m  1.7016\n"]},{"data":{"text/plain":["<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n","  module_=ClassifierModule(\n","    (dense0): Linear(in_features=100, out_features=200, bias=True)\n","    (dense1): Linear(in_features=200, out_features=50, bias=True)\n","    (output): Linear(in_features=50, out_features=20, bias=True)\n","  ),\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Train the classifier\n","net.fit(X, y)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-09T08:26:23.141438Z","iopub.status.busy":"2024-10-09T08:26:23.140936Z","iopub.status.idle":"2024-10-09T08:26:24.706920Z","shell.execute_reply":"2024-10-09T08:26:24.705526Z","shell.execute_reply.started":"2024-10-09T08:26:23.141400Z"},"id":"7SWtTc1zjie8","outputId":"2d98581e-cbd7-4af8-ccd4-1320e41d8b48","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.682\n"]}],"source":["X_test = vectorizer.transform(x_test)\n","X_test = X_test.astype(np.float32)\n","y_test_np = np.array(y_test, dtype=np.int64)\n","\n","y_pred = net.predict(X_test)\n","test_accuracy = np.mean(y_pred == y_test_np)\n","print(f\"Test Accuracy: {test_accuracy}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Experimenting with a better count vectorizer"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:26:24.709016Z","iopub.status.busy":"2024-10-09T08:26:24.708421Z","iopub.status.idle":"2024-10-09T08:26:29.547251Z","shell.execute_reply":"2024-10-09T08:26:29.546395Z","shell.execute_reply.started":"2024-10-09T08:26:24.708961Z"},"trusted":true},"outputs":[],"source":["vectorizer_updated = CountVectorizer(analyzer='char', ngram_range=(2, 2), max_features=5000, binary=True)\n","X_cv_updated = vectorizer_updated.fit_transform(x_train)\n","X_cv_updated = X_cv_updated.astype(np.float32)\n","y_cv_updted = y_train.astype(np.int64)\n","\n","net_cv_updated = NeuralNetClassifier(\n","    ClassifierModule(\n","        input_size=X_cv_updated.shape[1],\n","        num_units=200,\n","        num_classes=len(label_encoder.classes_),\n","        nonlin=F.relu,\n","    ),\n","    max_epochs=20,\n","    criterion=nn.CrossEntropyLoss(),\n","    lr=0.1,\n","    device='cuda',  # comment this to train with CPU\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:26:29.549071Z","iopub.status.busy":"2024-10-09T08:26:29.548583Z","iopub.status.idle":"2024-10-09T08:27:07.122340Z","shell.execute_reply":"2024-10-09T08:27:07.121388Z","shell.execute_reply.started":"2024-10-09T08:26:29.549025Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.3122\u001b[0m       \u001b[32m0.6966\u001b[0m        \u001b[35m1.2376\u001b[0m  1.8738\n","      2        \u001b[36m0.7029\u001b[0m       \u001b[32m0.8925\u001b[0m        \u001b[35m0.3870\u001b[0m  1.8367\n","      3        \u001b[36m0.2740\u001b[0m       \u001b[32m0.9647\u001b[0m        \u001b[35m0.2131\u001b[0m  1.9036\n","      4        \u001b[36m0.1582\u001b[0m       \u001b[32m0.9731\u001b[0m        \u001b[35m0.1500\u001b[0m  1.8623\n","      5        \u001b[36m0.1123\u001b[0m       \u001b[32m0.9766\u001b[0m        \u001b[35m0.1245\u001b[0m  1.8618\n","      6        \u001b[36m0.0886\u001b[0m       \u001b[32m0.9781\u001b[0m        \u001b[35m0.1110\u001b[0m  1.8986\n","      7        \u001b[36m0.0732\u001b[0m       \u001b[32m0.9788\u001b[0m        \u001b[35m0.1026\u001b[0m  1.8417\n","      8        \u001b[36m0.0620\u001b[0m       \u001b[32m0.9794\u001b[0m        \u001b[35m0.0969\u001b[0m  1.8381\n","      9        \u001b[36m0.0534\u001b[0m       \u001b[32m0.9803\u001b[0m        \u001b[35m0.0927\u001b[0m  1.8774\n","     10        \u001b[36m0.0464\u001b[0m       \u001b[32m0.9809\u001b[0m        \u001b[35m0.0898\u001b[0m  1.9043\n","     11        \u001b[36m0.0406\u001b[0m       \u001b[32m0.9816\u001b[0m        \u001b[35m0.0876\u001b[0m  1.8853\n","     12        \u001b[36m0.0358\u001b[0m       0.9816        \u001b[35m0.0861\u001b[0m  1.8430\n","     13        \u001b[36m0.0316\u001b[0m       0.9812        \u001b[35m0.0850\u001b[0m  1.9020\n","     14        \u001b[36m0.0281\u001b[0m       0.9816        \u001b[35m0.0842\u001b[0m  1.8862\n","     15        \u001b[36m0.0250\u001b[0m       0.9816        \u001b[35m0.0836\u001b[0m  1.8124\n","     16        \u001b[36m0.0223\u001b[0m       \u001b[32m0.9819\u001b[0m        \u001b[35m0.0833\u001b[0m  1.8568\n","     17        \u001b[36m0.0199\u001b[0m       \u001b[32m0.9831\u001b[0m        \u001b[35m0.0831\u001b[0m  1.9488\n","     18        \u001b[36m0.0179\u001b[0m       0.9828        \u001b[35m0.0830\u001b[0m  1.9160\n","     19        \u001b[36m0.0161\u001b[0m       0.9825        0.0830  1.8658\n","     20        \u001b[36m0.0146\u001b[0m       0.9825        0.0831  1.8535\n"]},{"data":{"text/plain":["<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n","  module_=ClassifierModule(\n","    (dense0): Linear(in_features=5000, out_features=200, bias=True)\n","    (dense1): Linear(in_features=200, out_features=50, bias=True)\n","    (output): Linear(in_features=50, out_features=20, bias=True)\n","  ),\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["net_cv_updated.fit(X_cv_updated, y_cv_updted)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:27:07.123854Z","iopub.status.busy":"2024-10-09T08:27:07.123568Z","iopub.status.idle":"2024-10-09T08:27:08.909027Z","shell.execute_reply":"2024-10-09T08:27:08.907981Z","shell.execute_reply.started":"2024-10-09T08:27:07.123823Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.98075\n"]}],"source":["X_cv_updated_test = vectorizer_updated.transform(x_test)\n","X_cv_updated_test = X_cv_updated_test.astype(np.float32)\n","y_test_np = np.array(y_test, dtype=np.int64)\n","\n","y_cv_updated_pred = net_cv_updated.predict(X_cv_updated_test)\n","test_cv_updated_accuracy = np.mean(y_cv_updated_pred == y_test_np)\n","print(f\"Test Accuracy: {test_cv_updated_accuracy}\")"]},{"cell_type":"markdown","metadata":{"id":"JiovRi0liZ9c"},"source":["### Experimenting with TF-IDF vectorizer instead of count vectorizer"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-09T08:27:08.910830Z","iopub.status.busy":"2024-10-09T08:27:08.910407Z","iopub.status.idle":"2024-10-09T08:28:08.591467Z","shell.execute_reply":"2024-10-09T08:28:08.590452Z","shell.execute_reply.started":"2024-10-09T08:27:08.910784Z"},"id":"ojozp-muhd34","outputId":"074ca18d-4853-40f4-98f9-e7a1989ae56f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9951\u001b[0m       \u001b[32m0.0872\u001b[0m        \u001b[35m2.9903\u001b[0m  1.8490\n","      2        \u001b[36m2.9857\u001b[0m       \u001b[32m0.1500\u001b[0m        \u001b[35m2.9791\u001b[0m  1.9064\n","      3        \u001b[36m2.9710\u001b[0m       \u001b[32m0.4909\u001b[0m        \u001b[35m2.9594\u001b[0m  1.9040\n","      4        \u001b[36m2.9404\u001b[0m       \u001b[32m0.6366\u001b[0m        \u001b[35m2.9112\u001b[0m  1.8626\n","      5        \u001b[36m2.8476\u001b[0m       0.4706        \u001b[35m2.7438\u001b[0m  1.8867\n","      6        \u001b[36m2.5506\u001b[0m       0.4234        \u001b[35m2.3325\u001b[0m  1.8923\n","      7        \u001b[36m2.1478\u001b[0m       \u001b[32m0.7450\u001b[0m        \u001b[35m1.9551\u001b[0m  1.8532\n","      8        \u001b[36m1.7604\u001b[0m       \u001b[32m0.7822\u001b[0m        \u001b[35m1.5475\u001b[0m  1.8669\n","      9        \u001b[36m1.3485\u001b[0m       \u001b[32m0.8159\u001b[0m        \u001b[35m1.1456\u001b[0m  1.8581\n","     10        \u001b[36m0.9953\u001b[0m       \u001b[32m0.8512\u001b[0m        \u001b[35m0.8554\u001b[0m  1.9163\n","     11        \u001b[36m0.7498\u001b[0m       \u001b[32m0.9025\u001b[0m        \u001b[35m0.6467\u001b[0m  1.8946\n","     12        \u001b[36m0.5602\u001b[0m       \u001b[32m0.9266\u001b[0m        \u001b[35m0.4783\u001b[0m  1.8745\n","     13        \u001b[36m0.4161\u001b[0m       \u001b[32m0.9397\u001b[0m        \u001b[35m0.3618\u001b[0m  1.8496\n","     14        \u001b[36m0.3229\u001b[0m       \u001b[32m0.9516\u001b[0m        \u001b[35m0.2917\u001b[0m  1.9436\n","     15        \u001b[36m0.2662\u001b[0m       \u001b[32m0.9575\u001b[0m        \u001b[35m0.2488\u001b[0m  1.8675\n","     16        \u001b[36m0.2295\u001b[0m       \u001b[32m0.9606\u001b[0m        \u001b[35m0.2199\u001b[0m  1.9009\n","     17        \u001b[36m0.2034\u001b[0m       \u001b[32m0.9637\u001b[0m        \u001b[35m0.1988\u001b[0m  1.8694\n","     18        \u001b[36m0.1835\u001b[0m       \u001b[32m0.9675\u001b[0m        \u001b[35m0.1826\u001b[0m  1.8592\n","     19        \u001b[36m0.1675\u001b[0m       \u001b[32m0.9706\u001b[0m        \u001b[35m0.1696\u001b[0m  1.8483\n","     20        \u001b[36m0.1545\u001b[0m       \u001b[32m0.9719\u001b[0m        \u001b[35m0.1590\u001b[0m  1.8490\n"]},{"data":{"text/plain":["<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n","  module_=ClassifierModule(\n","    (dense0): Linear(in_features=5000, out_features=200, bias=True)\n","    (dense1): Linear(in_features=200, out_features=50, bias=True)\n","    (output): Linear(in_features=50, out_features=20, bias=True)\n","  ),\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Use TF-IDF vectorizer for better feature representation\n","vectorizer_tfidf = TfidfVectorizer(analyzer='char', ngram_range=(2,4), max_features=5000, use_idf=True) # Increased ngram range and max_features\n","X_tfidf = vectorizer_tfidf.fit_transform(x_train)\n","X_tfidf = X_tfidf.astype(np.float32)\n","y_tfidf = y_train.astype(np.int64)\n","\n","\n","# Initalise the neural net classifier.\n","net_tfid = NeuralNetClassifier(\n","    ClassifierModule(\n","        input_size=X_tfidf.shape[1],\n","        num_units=200,\n","        num_classes=len(label_encoder.classes_),\n","        nonlin=F.relu,\n","    ),\n","    max_epochs=20,\n","    criterion=nn.CrossEntropyLoss(),\n","    lr=0.1,\n","    device='cuda',  # comment this to train with CPU\n",")\n","\n","# Train the classifier\n","net_tfid.fit(X_tfidf, y_tfidf)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-09T08:28:08.593933Z","iopub.status.busy":"2024-10-09T08:28:08.593015Z","iopub.status.idle":"2024-10-09T08:28:12.768358Z","shell.execute_reply":"2024-10-09T08:28:12.767255Z","shell.execute_reply.started":"2024-10-09T08:28:08.593881Z"},"id":"Q3jbEf64jtGR","outputId":"64623d2b-f5b3-4629-eb71-2b64feb8f115","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy with TF-IDF: 0.96575\n"]}],"source":["X_test_tfidf = vectorizer_tfidf.transform(x_test)\n","X_test_tfidf = X_test_tfidf.astype(np.float32)\n","y_test_np = np.array(y_test, dtype=np.int64)\n","\n","y_pred_tfidf = net_tfid.predict(X_test_tfidf)\n","test_accuracy_tfidf = np.mean(y_pred_tfidf == y_test_np)\n","print(f\"Test Accuracy with TF-IDF: {test_accuracy_tfidf}\")\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:28:12.770128Z","iopub.status.busy":"2024-10-09T08:28:12.769752Z","iopub.status.idle":"2024-10-09T08:28:12.784790Z","shell.execute_reply":"2024-10-09T08:28:12.783838Z","shell.execute_reply.started":"2024-10-09T08:28:12.770090Z"},"id":"BCwaMlVkifDx","trusted":true},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","from skorch.callbacks import EarlyStopping\n","\n","# Define the parameter grid for GridSearchCV\n","param_grid = {\n","    'module__num_units': [100, 200, 300],\n","    'module__nonlin': [F.relu], #, F.tanh],\n","    'module__input_size': [X_tfidf.shape[1]],\n","    'lr': [0.01, 0.1],\n","    'max_epochs': [20, 30],\n","    'callbacks': [[('EarlyStopping', EarlyStopping(patience=patience))] for patience in [5]]\n","}\n","\n","net_tfidf_gs = NeuralNetClassifier(\n","    ClassifierModule(\n","        input_size=X_tfidf.shape[1],\n","        num_units=200,\n","        num_classes=len(label_encoder.classes_),\n","        nonlin=F.relu,\n","    ),\n","    max_epochs=20,\n","    criterion=nn.CrossEntropyLoss(),\n","    lr=0.1,\n","    device='cuda',  # comment this to train with CPU\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-09T08:28:12.786435Z","iopub.status.busy":"2024-10-09T08:28:12.786108Z","iopub.status.idle":"2024-10-09T08:48:38.221060Z","shell.execute_reply":"2024-10-09T08:48:38.220047Z","shell.execute_reply.started":"2024-10-09T08:28:12.786403Z"},"id":"uP_UIB_OnHZC","outputId":"8bf71086-f01e-4b54-cf91-a45a495e8914","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9994\u001b[0m       \u001b[32m0.0487\u001b[0m        \u001b[35m2.9990\u001b[0m  1.2689\n","      2        \u001b[36m2.9986\u001b[0m       0.0487        \u001b[35m2.9982\u001b[0m  1.2490\n","      3        \u001b[36m2.9979\u001b[0m       0.0487        \u001b[35m2.9975\u001b[0m  1.2642\n","      4        \u001b[36m2.9972\u001b[0m       0.0487        \u001b[35m2.9968\u001b[0m  1.2499\n","      5        \u001b[36m2.9965\u001b[0m       0.0487        \u001b[35m2.9962\u001b[0m  1.2368\n","      6        \u001b[36m2.9958\u001b[0m       0.0487        \u001b[35m2.9955\u001b[0m  1.2814\n","      7        \u001b[36m2.9952\u001b[0m       0.0487        \u001b[35m2.9949\u001b[0m  1.2331\n","      8        \u001b[36m2.9946\u001b[0m       0.0487        \u001b[35m2.9942\u001b[0m  1.2916\n","      9        \u001b[36m2.9939\u001b[0m       0.0487        \u001b[35m2.9936\u001b[0m  1.2477\n","     10        \u001b[36m2.9933\u001b[0m       0.0487        \u001b[35m2.9929\u001b[0m  1.2509\n","     11        \u001b[36m2.9926\u001b[0m       0.0487        \u001b[35m2.9922\u001b[0m  1.2408\n","     12        \u001b[36m2.9919\u001b[0m       0.0487        \u001b[35m2.9916\u001b[0m  1.2823\n","     13        \u001b[36m2.9912\u001b[0m       0.0487        \u001b[35m2.9909\u001b[0m  1.2956\n","     14        \u001b[36m2.9906\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9901\u001b[0m  1.2954\n","     15        \u001b[36m2.9898\u001b[0m       \u001b[32m0.0530\u001b[0m        \u001b[35m2.9894\u001b[0m  1.2509\n","     16        \u001b[36m2.9891\u001b[0m       \u001b[32m0.0600\u001b[0m        \u001b[35m2.9887\u001b[0m  1.2728\n","     17        \u001b[36m2.9884\u001b[0m       \u001b[32m0.0862\u001b[0m        \u001b[35m2.9879\u001b[0m  1.2807\n","     18        \u001b[36m2.9876\u001b[0m       \u001b[32m0.1101\u001b[0m        \u001b[35m2.9872\u001b[0m  1.2671\n","     19        \u001b[36m2.9869\u001b[0m       \u001b[32m0.1218\u001b[0m        \u001b[35m2.9864\u001b[0m  1.2556\n","     20        \u001b[36m2.9861\u001b[0m       \u001b[32m0.1476\u001b[0m        \u001b[35m2.9856\u001b[0m  1.2512\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.0002\u001b[0m       \u001b[32m0.0492\u001b[0m        \u001b[35m2.9998\u001b[0m  1.2913\n","      2        \u001b[36m2.9994\u001b[0m       0.0492        \u001b[35m2.9990\u001b[0m  1.2350\n","      3        \u001b[36m2.9987\u001b[0m       0.0492        \u001b[35m2.9983\u001b[0m  1.2421\n","      4        \u001b[36m2.9980\u001b[0m       0.0492        \u001b[35m2.9976\u001b[0m  1.2727\n","      5        \u001b[36m2.9973\u001b[0m       0.0492        \u001b[35m2.9969\u001b[0m  1.2715\n","      6        \u001b[36m2.9966\u001b[0m       0.0492        \u001b[35m2.9963\u001b[0m  1.2568\n","      7        \u001b[36m2.9960\u001b[0m       0.0492        \u001b[35m2.9956\u001b[0m  1.2574\n","      8        \u001b[36m2.9953\u001b[0m       0.0492        \u001b[35m2.9950\u001b[0m  1.2551\n","      9        \u001b[36m2.9947\u001b[0m       0.0492        \u001b[35m2.9943\u001b[0m  1.2796\n","     10        \u001b[36m2.9940\u001b[0m       0.0492        \u001b[35m2.9937\u001b[0m  1.2396\n","     11        \u001b[36m2.9934\u001b[0m       0.0492        \u001b[35m2.9930\u001b[0m  1.2512\n","     12        \u001b[36m2.9927\u001b[0m       0.0492        \u001b[35m2.9924\u001b[0m  1.2348\n","     13        \u001b[36m2.9921\u001b[0m       0.0492        \u001b[35m2.9917\u001b[0m  1.2329\n","     14        \u001b[36m2.9914\u001b[0m       0.0492        \u001b[35m2.9910\u001b[0m  1.2486\n","     15        \u001b[36m2.9907\u001b[0m       0.0492        \u001b[35m2.9904\u001b[0m  1.2527\n","     16        \u001b[36m2.9900\u001b[0m       0.0492        \u001b[35m2.9897\u001b[0m  1.2617\n","     17        \u001b[36m2.9893\u001b[0m       0.0492        \u001b[35m2.9890\u001b[0m  1.3681\n","     18        \u001b[36m2.9886\u001b[0m       0.0492        \u001b[35m2.9883\u001b[0m  1.2769\n","     19        \u001b[36m2.9879\u001b[0m       0.0492        \u001b[35m2.9876\u001b[0m  1.2508\n","     20        \u001b[36m2.9872\u001b[0m       0.0492        \u001b[35m2.9868\u001b[0m  1.2536\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9983\u001b[0m       \u001b[32m0.0492\u001b[0m        \u001b[35m2.9979\u001b[0m  1.2645\n","      2        \u001b[36m2.9977\u001b[0m       0.0492        \u001b[35m2.9973\u001b[0m  1.2431\n","      3        \u001b[36m2.9971\u001b[0m       0.0492        \u001b[35m2.9968\u001b[0m  1.2612\n","      4        \u001b[36m2.9965\u001b[0m       0.0492        \u001b[35m2.9962\u001b[0m  1.2728\n","      5        \u001b[36m2.9960\u001b[0m       0.0492        \u001b[35m2.9957\u001b[0m  1.2426\n","      6        \u001b[36m2.9954\u001b[0m       0.0492        \u001b[35m2.9952\u001b[0m  1.2439\n","      7        \u001b[36m2.9949\u001b[0m       0.0492        \u001b[35m2.9946\u001b[0m  1.2726\n","      8        \u001b[36m2.9944\u001b[0m       0.0492        \u001b[35m2.9941\u001b[0m  1.2385\n","      9        \u001b[36m2.9938\u001b[0m       0.0492        \u001b[35m2.9936\u001b[0m  1.2520\n","     10        \u001b[36m2.9933\u001b[0m       0.0492        \u001b[35m2.9930\u001b[0m  1.2405\n","     11        \u001b[36m2.9927\u001b[0m       0.0492        \u001b[35m2.9924\u001b[0m  1.2444\n","     12        \u001b[36m2.9922\u001b[0m       0.0492        \u001b[35m2.9919\u001b[0m  1.3016\n","     13        \u001b[36m2.9916\u001b[0m       0.0492        \u001b[35m2.9913\u001b[0m  1.2528\n","     14        \u001b[36m2.9910\u001b[0m       0.0492        \u001b[35m2.9907\u001b[0m  1.2383\n","     15        \u001b[36m2.9904\u001b[0m       0.0492        \u001b[35m2.9901\u001b[0m  1.2483\n","     16        \u001b[36m2.9898\u001b[0m       0.0492        \u001b[35m2.9895\u001b[0m  1.2460\n","     17        \u001b[36m2.9892\u001b[0m       0.0492        \u001b[35m2.9889\u001b[0m  1.2382\n","     18        \u001b[36m2.9886\u001b[0m       0.0492        \u001b[35m2.9883\u001b[0m  1.2335\n","     19        \u001b[36m2.9880\u001b[0m       0.0492        \u001b[35m2.9876\u001b[0m  1.2412\n","     20        \u001b[36m2.9873\u001b[0m       0.0492        \u001b[35m2.9870\u001b[0m  1.2910\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9983\u001b[0m       \u001b[32m0.0492\u001b[0m        \u001b[35m2.9981\u001b[0m  1.3362\n","      2        \u001b[36m2.9978\u001b[0m       0.0492        \u001b[35m2.9975\u001b[0m  1.2642\n","      3        \u001b[36m2.9972\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9969\u001b[0m  1.2604\n","      4        \u001b[36m2.9966\u001b[0m       \u001b[32m0.0689\u001b[0m        \u001b[35m2.9964\u001b[0m  1.2527\n","      5        \u001b[36m2.9961\u001b[0m       \u001b[32m0.0862\u001b[0m        \u001b[35m2.9958\u001b[0m  1.2469\n","      6        \u001b[36m2.9956\u001b[0m       \u001b[32m0.0914\u001b[0m        \u001b[35m2.9953\u001b[0m  1.2437\n","      7        \u001b[36m2.9951\u001b[0m       0.0853        \u001b[35m2.9948\u001b[0m  1.2517\n","      8        \u001b[36m2.9946\u001b[0m       0.0759        \u001b[35m2.9943\u001b[0m  1.2924\n","      9        \u001b[36m2.9941\u001b[0m       0.0679        \u001b[35m2.9938\u001b[0m  1.2538\n","     10        \u001b[36m2.9936\u001b[0m       0.0637        \u001b[35m2.9933\u001b[0m  1.3123\n","     11        \u001b[36m2.9931\u001b[0m       0.0604        \u001b[35m2.9928\u001b[0m  1.3298\n","     12        \u001b[36m2.9926\u001b[0m       0.0567        \u001b[35m2.9923\u001b[0m  1.2891\n","     13        \u001b[36m2.9921\u001b[0m       0.0539        \u001b[35m2.9918\u001b[0m  1.2621\n","     14        \u001b[36m2.9915\u001b[0m       0.0530        \u001b[35m2.9912\u001b[0m  1.2566\n","     15        \u001b[36m2.9910\u001b[0m       0.0520        \u001b[35m2.9907\u001b[0m  1.2919\n","     16        \u001b[36m2.9905\u001b[0m       0.0515        \u001b[35m2.9902\u001b[0m  1.2467\n","     17        \u001b[36m2.9899\u001b[0m       0.0515        \u001b[35m2.9896\u001b[0m  1.2611\n","     18        \u001b[36m2.9894\u001b[0m       0.0511        \u001b[35m2.9890\u001b[0m  1.2482\n","     19        \u001b[36m2.9888\u001b[0m       0.0511        \u001b[35m2.9885\u001b[0m  1.2916\n","     20        \u001b[36m2.9882\u001b[0m       0.0511        \u001b[35m2.9879\u001b[0m  1.2545\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9989\u001b[0m       \u001b[32m0.0506\u001b[0m        \u001b[35m2.9986\u001b[0m  1.2592\n","      2        \u001b[36m2.9984\u001b[0m       0.0506        \u001b[35m2.9980\u001b[0m  1.2537\n","      3        \u001b[36m2.9979\u001b[0m       0.0506        \u001b[35m2.9975\u001b[0m  1.3136\n","      4        \u001b[36m2.9973\u001b[0m       0.0506        \u001b[35m2.9970\u001b[0m  1.2810\n","      5        \u001b[36m2.9968\u001b[0m       0.0506        \u001b[35m2.9965\u001b[0m  1.3594\n","      6        \u001b[36m2.9963\u001b[0m       0.0506        \u001b[35m2.9960\u001b[0m  1.3318\n","      7        \u001b[36m2.9958\u001b[0m       0.0506        \u001b[35m2.9955\u001b[0m  1.2615\n","      8        \u001b[36m2.9953\u001b[0m       0.0506        \u001b[35m2.9950\u001b[0m  1.2386\n","      9        \u001b[36m2.9948\u001b[0m       0.0506        \u001b[35m2.9945\u001b[0m  1.2427\n","     10        \u001b[36m2.9943\u001b[0m       0.0506        \u001b[35m2.9940\u001b[0m  1.3409\n","     11        \u001b[36m2.9939\u001b[0m       0.0506        \u001b[35m2.9936\u001b[0m  1.2647\n","     12        \u001b[36m2.9934\u001b[0m       0.0506        \u001b[35m2.9931\u001b[0m  1.2485\n","     13        \u001b[36m2.9929\u001b[0m       0.0506        \u001b[35m2.9926\u001b[0m  1.2513\n","     14        \u001b[36m2.9925\u001b[0m       0.0506        \u001b[35m2.9922\u001b[0m  1.2705\n","     15        \u001b[36m2.9920\u001b[0m       0.0506        \u001b[35m2.9917\u001b[0m  1.2677\n","     16        \u001b[36m2.9915\u001b[0m       0.0506        \u001b[35m2.9912\u001b[0m  1.2480\n","     17        \u001b[36m2.9910\u001b[0m       0.0506        \u001b[35m2.9907\u001b[0m  1.2607\n","     18        \u001b[36m2.9905\u001b[0m       \u001b[32m0.0511\u001b[0m        \u001b[35m2.9902\u001b[0m  1.2959\n","     19        \u001b[36m2.9900\u001b[0m       \u001b[32m0.0609\u001b[0m        \u001b[35m2.9897\u001b[0m  1.2587\n","     20        \u001b[36m2.9895\u001b[0m       \u001b[32m0.0759\u001b[0m        \u001b[35m2.9892\u001b[0m  1.2496\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9983\u001b[0m       \u001b[32m0.0506\u001b[0m        \u001b[35m2.9978\u001b[0m  1.3321\n","      2        \u001b[36m2.9978\u001b[0m       0.0501        \u001b[35m2.9973\u001b[0m  1.2790\n","      3        \u001b[36m2.9972\u001b[0m       0.0501        \u001b[35m2.9968\u001b[0m  1.2429\n","      4        \u001b[36m2.9967\u001b[0m       0.0501        \u001b[35m2.9963\u001b[0m  1.2593\n","      5        \u001b[36m2.9962\u001b[0m       0.0501        \u001b[35m2.9958\u001b[0m  1.2831\n","      6        \u001b[36m2.9957\u001b[0m       0.0501        \u001b[35m2.9953\u001b[0m  1.2904\n","      7        \u001b[36m2.9952\u001b[0m       0.0501        \u001b[35m2.9948\u001b[0m  1.2530\n","      8        \u001b[36m2.9947\u001b[0m       0.0501        \u001b[35m2.9943\u001b[0m  1.2707\n","      9        \u001b[36m2.9942\u001b[0m       0.0501        \u001b[35m2.9938\u001b[0m  1.3260\n","     10        \u001b[36m2.9938\u001b[0m       0.0501        \u001b[35m2.9933\u001b[0m  1.2545\n","     11        \u001b[36m2.9933\u001b[0m       0.0501        \u001b[35m2.9929\u001b[0m  1.2318\n","     12        \u001b[36m2.9928\u001b[0m       0.0506        \u001b[35m2.9924\u001b[0m  1.2479\n","     13        \u001b[36m2.9923\u001b[0m       \u001b[32m0.0515\u001b[0m        \u001b[35m2.9919\u001b[0m  1.2619\n","     14        \u001b[36m2.9918\u001b[0m       \u001b[32m0.0534\u001b[0m        \u001b[35m2.9914\u001b[0m  1.2474\n","     15        \u001b[36m2.9913\u001b[0m       \u001b[32m0.0558\u001b[0m        \u001b[35m2.9909\u001b[0m  1.2563\n","     16        \u001b[36m2.9908\u001b[0m       \u001b[32m0.0572\u001b[0m        \u001b[35m2.9904\u001b[0m  1.2465\n","     17        \u001b[36m2.9903\u001b[0m       \u001b[32m0.0614\u001b[0m        \u001b[35m2.9899\u001b[0m  1.2768\n","     18        \u001b[36m2.9898\u001b[0m       \u001b[32m0.0670\u001b[0m        \u001b[35m2.9894\u001b[0m  1.2737\n","     19        \u001b[36m2.9893\u001b[0m       \u001b[32m0.0778\u001b[0m        \u001b[35m2.9888\u001b[0m  1.2518\n","     20        \u001b[36m2.9887\u001b[0m       \u001b[32m0.0928\u001b[0m        \u001b[35m2.9883\u001b[0m  1.2594\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9993\u001b[0m       \u001b[32m0.0483\u001b[0m        \u001b[35m2.9991\u001b[0m  1.3094\n","      2        \u001b[36m2.9987\u001b[0m       0.0483        \u001b[35m2.9984\u001b[0m  1.2419\n","      3        \u001b[36m2.9981\u001b[0m       0.0483        \u001b[35m2.9979\u001b[0m  1.2488\n","      4        \u001b[36m2.9975\u001b[0m       0.0483        \u001b[35m2.9973\u001b[0m  1.2928\n","      5        \u001b[36m2.9970\u001b[0m       0.0483        \u001b[35m2.9967\u001b[0m  1.2468\n","      6        \u001b[36m2.9964\u001b[0m       0.0483        \u001b[35m2.9962\u001b[0m  1.2523\n","      7        \u001b[36m2.9959\u001b[0m       0.0483        \u001b[35m2.9957\u001b[0m  1.2553\n","      8        \u001b[36m2.9953\u001b[0m       \u001b[32m0.0534\u001b[0m        \u001b[35m2.9951\u001b[0m  1.2747\n","      9        \u001b[36m2.9948\u001b[0m       \u001b[32m0.0661\u001b[0m        \u001b[35m2.9946\u001b[0m  1.2813\n","     10        \u001b[36m2.9943\u001b[0m       \u001b[32m0.0797\u001b[0m        \u001b[35m2.9941\u001b[0m  1.2866\n","     11        \u001b[36m2.9938\u001b[0m       \u001b[32m0.0886\u001b[0m        \u001b[35m2.9936\u001b[0m  1.2588\n","     12        \u001b[36m2.9933\u001b[0m       \u001b[32m0.1129\u001b[0m        \u001b[35m2.9931\u001b[0m  1.3237\n","     13        \u001b[36m2.9928\u001b[0m       \u001b[32m0.1392\u001b[0m        \u001b[35m2.9926\u001b[0m  1.3354\n","     14        \u001b[36m2.9923\u001b[0m       \u001b[32m0.1462\u001b[0m        \u001b[35m2.9921\u001b[0m  1.2405\n","     15        \u001b[36m2.9918\u001b[0m       0.1462        \u001b[35m2.9915\u001b[0m  1.2459\n","     16        \u001b[36m2.9913\u001b[0m       \u001b[32m0.1471\u001b[0m        \u001b[35m2.9910\u001b[0m  1.2840\n","     17        \u001b[36m2.9907\u001b[0m       \u001b[32m0.1490\u001b[0m        \u001b[35m2.9905\u001b[0m  1.2456\n","     18        \u001b[36m2.9902\u001b[0m       \u001b[32m0.1584\u001b[0m        \u001b[35m2.9899\u001b[0m  1.2545\n","     19        \u001b[36m2.9897\u001b[0m       \u001b[32m0.1823\u001b[0m        \u001b[35m2.9894\u001b[0m  1.2419\n","     20        \u001b[36m2.9891\u001b[0m       \u001b[32m0.2170\u001b[0m        \u001b[35m2.9888\u001b[0m  1.2622\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9988\u001b[0m       \u001b[32m0.0698\u001b[0m        \u001b[35m2.9984\u001b[0m  1.2477\n","      2        \u001b[36m2.9981\u001b[0m       \u001b[32m0.0736\u001b[0m        \u001b[35m2.9977\u001b[0m  1.2384\n","      3        \u001b[36m2.9975\u001b[0m       0.0614        \u001b[35m2.9972\u001b[0m  1.2387\n","      4        \u001b[36m2.9970\u001b[0m       0.0544        \u001b[35m2.9966\u001b[0m  1.2842\n","      5        \u001b[36m2.9964\u001b[0m       0.0511        \u001b[35m2.9960\u001b[0m  1.2641\n","      6        \u001b[36m2.9958\u001b[0m       0.0511        \u001b[35m2.9955\u001b[0m  1.2503\n","      7        \u001b[36m2.9953\u001b[0m       0.0511        \u001b[35m2.9949\u001b[0m  1.2414\n","      8        \u001b[36m2.9947\u001b[0m       0.0511        \u001b[35m2.9944\u001b[0m  1.3137\n","      9        \u001b[36m2.9942\u001b[0m       0.0511        \u001b[35m2.9938\u001b[0m  1.2753\n","     10        \u001b[36m2.9936\u001b[0m       0.0511        \u001b[35m2.9933\u001b[0m  1.2331\n","     11        \u001b[36m2.9931\u001b[0m       0.0511        \u001b[35m2.9927\u001b[0m  1.2380\n","     12        \u001b[36m2.9925\u001b[0m       0.0511        \u001b[35m2.9922\u001b[0m  1.2721\n","     13        \u001b[36m2.9919\u001b[0m       0.0511        \u001b[35m2.9915\u001b[0m  1.2725\n","     14        \u001b[36m2.9913\u001b[0m       0.0511        \u001b[35m2.9909\u001b[0m  1.2591\n","     15        \u001b[36m2.9907\u001b[0m       0.0511        \u001b[35m2.9903\u001b[0m  1.2695\n","     16        \u001b[36m2.9901\u001b[0m       0.0511        \u001b[35m2.9897\u001b[0m  1.2469\n","     17        \u001b[36m2.9895\u001b[0m       0.0520        \u001b[35m2.9891\u001b[0m  1.2950\n","     18        \u001b[36m2.9889\u001b[0m       0.0534        \u001b[35m2.9885\u001b[0m  1.2334\n","     19        \u001b[36m2.9882\u001b[0m       0.0586        \u001b[35m2.9879\u001b[0m  1.2715\n","     20        \u001b[36m2.9876\u001b[0m       0.0665        \u001b[35m2.9872\u001b[0m  1.2636\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9975\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9971\u001b[0m  1.2635\n","      2        \u001b[36m2.9969\u001b[0m       0.0501        \u001b[35m2.9966\u001b[0m  1.2645\n","      3        \u001b[36m2.9964\u001b[0m       0.0501        \u001b[35m2.9961\u001b[0m  1.2495\n","      4        \u001b[36m2.9959\u001b[0m       0.0501        \u001b[35m2.9955\u001b[0m  1.2589\n","      5        \u001b[36m2.9954\u001b[0m       \u001b[32m0.0511\u001b[0m        \u001b[35m2.9950\u001b[0m  1.2547\n","      6        \u001b[36m2.9948\u001b[0m       \u001b[32m0.0539\u001b[0m        \u001b[35m2.9945\u001b[0m  1.2660\n","      7        \u001b[36m2.9943\u001b[0m       \u001b[32m0.0628\u001b[0m        \u001b[35m2.9940\u001b[0m  1.2948\n","      8        \u001b[36m2.9938\u001b[0m       \u001b[32m0.0736\u001b[0m        \u001b[35m2.9935\u001b[0m  1.2915\n","      9        \u001b[36m2.9933\u001b[0m       \u001b[32m0.0778\u001b[0m        \u001b[35m2.9930\u001b[0m  1.2624\n","     10        \u001b[36m2.9928\u001b[0m       \u001b[32m0.0839\u001b[0m        \u001b[35m2.9925\u001b[0m  1.2686\n","     11        \u001b[36m2.9923\u001b[0m       \u001b[32m0.0848\u001b[0m        \u001b[35m2.9920\u001b[0m  1.2564\n","     12        \u001b[36m2.9918\u001b[0m       \u001b[32m0.0942\u001b[0m        \u001b[35m2.9915\u001b[0m  1.2547\n","     13        \u001b[36m2.9912\u001b[0m       \u001b[32m0.1101\u001b[0m        \u001b[35m2.9909\u001b[0m  1.2534\n","     14        \u001b[36m2.9907\u001b[0m       \u001b[32m0.1218\u001b[0m        \u001b[35m2.9904\u001b[0m  1.2591\n","     15        \u001b[36m2.9901\u001b[0m       \u001b[32m0.1256\u001b[0m        \u001b[35m2.9898\u001b[0m  1.2918\n","     16        \u001b[36m2.9896\u001b[0m       \u001b[32m0.1261\u001b[0m        \u001b[35m2.9893\u001b[0m  1.2532\n","     17        \u001b[36m2.9890\u001b[0m       0.1256        \u001b[35m2.9887\u001b[0m  1.2855\n","     18        \u001b[36m2.9884\u001b[0m       0.1246        \u001b[35m2.9881\u001b[0m  1.2893\n","     19        \u001b[36m2.9879\u001b[0m       0.1256        \u001b[35m2.9875\u001b[0m  1.2795\n","     20        \u001b[36m2.9872\u001b[0m       \u001b[32m0.1298\u001b[0m        \u001b[35m2.9869\u001b[0m  1.2526\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m3.0002\u001b[0m       \u001b[32m0.0530\u001b[0m        \u001b[35m3.0001\u001b[0m  1.3069\n","      2        \u001b[36m2.9996\u001b[0m       \u001b[32m0.0534\u001b[0m        \u001b[35m2.9994\u001b[0m  1.2721\n","      3        \u001b[36m2.9989\u001b[0m       0.0525        \u001b[35m2.9988\u001b[0m  1.2355\n","      4        \u001b[36m2.9984\u001b[0m       0.0525        \u001b[35m2.9982\u001b[0m  1.2397\n","      5        \u001b[36m2.9978\u001b[0m       0.0525        \u001b[35m2.9977\u001b[0m  1.2472\n","      6        \u001b[36m2.9973\u001b[0m       0.0520        \u001b[35m2.9972\u001b[0m  1.2452\n","      7        \u001b[36m2.9968\u001b[0m       0.0511        \u001b[35m2.9966\u001b[0m  1.2333\n","      8        \u001b[36m2.9962\u001b[0m       0.0511        \u001b[35m2.9961\u001b[0m  1.2482\n","      9        \u001b[36m2.9957\u001b[0m       0.0511        \u001b[35m2.9956\u001b[0m  1.2477\n","     10        \u001b[36m2.9953\u001b[0m       0.0506        \u001b[35m2.9951\u001b[0m  1.3082\n","     11        \u001b[36m2.9948\u001b[0m       0.0506        \u001b[35m2.9946\u001b[0m  1.2442\n","     12        \u001b[36m2.9943\u001b[0m       0.0506        \u001b[35m2.9941\u001b[0m  1.2626\n","     13        \u001b[36m2.9938\u001b[0m       0.0506        \u001b[35m2.9936\u001b[0m  1.2549\n","     14        \u001b[36m2.9933\u001b[0m       0.0506        \u001b[35m2.9931\u001b[0m  1.3177\n","     15        \u001b[36m2.9928\u001b[0m       0.0506        \u001b[35m2.9926\u001b[0m  1.2877\n","     16        \u001b[36m2.9923\u001b[0m       0.0506        \u001b[35m2.9921\u001b[0m  1.2322\n","     17        \u001b[36m2.9918\u001b[0m       0.0506        \u001b[35m2.9916\u001b[0m  1.2658\n","     18        \u001b[36m2.9913\u001b[0m       0.0506        \u001b[35m2.9911\u001b[0m  1.2858\n","     19        \u001b[36m2.9907\u001b[0m       0.0511        \u001b[35m2.9906\u001b[0m  1.2632\n","     20        \u001b[36m2.9902\u001b[0m       0.0511        \u001b[35m2.9900\u001b[0m  1.2531\n","     21        \u001b[36m2.9897\u001b[0m       0.0511        \u001b[35m2.9895\u001b[0m  1.2601\n","     22        \u001b[36m2.9892\u001b[0m       0.0511        \u001b[35m2.9889\u001b[0m  1.2468\n","     23        \u001b[36m2.9886\u001b[0m       0.0515        \u001b[35m2.9884\u001b[0m  1.2541\n","     24        \u001b[36m2.9881\u001b[0m       0.0525        \u001b[35m2.9878\u001b[0m  1.2556\n","     25        \u001b[36m2.9875\u001b[0m       \u001b[32m0.0544\u001b[0m        \u001b[35m2.9873\u001b[0m  1.2375\n","     26        \u001b[36m2.9869\u001b[0m       \u001b[32m0.0562\u001b[0m        \u001b[35m2.9867\u001b[0m  1.3539\n","     27        \u001b[36m2.9864\u001b[0m       \u001b[32m0.0590\u001b[0m        \u001b[35m2.9861\u001b[0m  1.2449\n","     28        \u001b[36m2.9858\u001b[0m       \u001b[32m0.0600\u001b[0m        \u001b[35m2.9855\u001b[0m  1.2455\n","     29        \u001b[36m2.9852\u001b[0m       \u001b[32m0.0609\u001b[0m        \u001b[35m2.9849\u001b[0m  1.2570\n","     30        \u001b[36m2.9845\u001b[0m       \u001b[32m0.0642\u001b[0m        \u001b[35m2.9842\u001b[0m  1.2787\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9993\u001b[0m       \u001b[32m0.0492\u001b[0m        \u001b[35m2.9990\u001b[0m  1.2492\n","      2        \u001b[36m2.9987\u001b[0m       0.0492        \u001b[35m2.9984\u001b[0m  1.2631\n","      3        \u001b[36m2.9982\u001b[0m       0.0492        \u001b[35m2.9978\u001b[0m  1.2931\n","      4        \u001b[36m2.9976\u001b[0m       0.0492        \u001b[35m2.9973\u001b[0m  1.2595\n","      5        \u001b[36m2.9971\u001b[0m       0.0492        \u001b[35m2.9968\u001b[0m  1.2425\n","      6        \u001b[36m2.9966\u001b[0m       \u001b[32m0.0515\u001b[0m        \u001b[35m2.9963\u001b[0m  1.2629\n","      7        \u001b[36m2.9961\u001b[0m       \u001b[32m0.0750\u001b[0m        \u001b[35m2.9958\u001b[0m  1.2556\n","      8        \u001b[36m2.9956\u001b[0m       \u001b[32m0.0923\u001b[0m        \u001b[35m2.9952\u001b[0m  1.2664\n","      9        \u001b[36m2.9951\u001b[0m       \u001b[32m0.0984\u001b[0m        \u001b[35m2.9947\u001b[0m  1.2530\n","     10        \u001b[36m2.9946\u001b[0m       0.0984        \u001b[35m2.9943\u001b[0m  1.2596\n","     11        \u001b[36m2.9941\u001b[0m       0.0984        \u001b[35m2.9938\u001b[0m  1.3020\n","     12        \u001b[36m2.9936\u001b[0m       0.0979        \u001b[35m2.9933\u001b[0m  1.2827\n","     13        \u001b[36m2.9931\u001b[0m       0.0979        \u001b[35m2.9928\u001b[0m  1.2633\n","     14        \u001b[36m2.9926\u001b[0m       0.0979        \u001b[35m2.9923\u001b[0m  1.2714\n","     15        \u001b[36m2.9921\u001b[0m       \u001b[32m0.0989\u001b[0m        \u001b[35m2.9918\u001b[0m  1.2685\n","     16        \u001b[36m2.9916\u001b[0m       \u001b[32m0.1026\u001b[0m        \u001b[35m2.9913\u001b[0m  1.2410\n","     17        \u001b[36m2.9911\u001b[0m       \u001b[32m0.1120\u001b[0m        \u001b[35m2.9908\u001b[0m  1.2941\n","     18        \u001b[36m2.9906\u001b[0m       \u001b[32m0.1303\u001b[0m        \u001b[35m2.9903\u001b[0m  1.2422\n","     19        \u001b[36m2.9901\u001b[0m       \u001b[32m0.1504\u001b[0m        \u001b[35m2.9898\u001b[0m  1.2758\n","     20        \u001b[36m2.9895\u001b[0m       \u001b[32m0.1678\u001b[0m        \u001b[35m2.9892\u001b[0m  1.3055\n","     21        \u001b[36m2.9890\u001b[0m       \u001b[32m0.1832\u001b[0m        \u001b[35m2.9887\u001b[0m  1.2545\n","     22        \u001b[36m2.9884\u001b[0m       \u001b[32m0.1884\u001b[0m        \u001b[35m2.9881\u001b[0m  1.2451\n","     23        \u001b[36m2.9879\u001b[0m       \u001b[32m0.1898\u001b[0m        \u001b[35m2.9876\u001b[0m  1.2440\n","     24        \u001b[36m2.9873\u001b[0m       \u001b[32m0.1921\u001b[0m        \u001b[35m2.9870\u001b[0m  1.2371\n","     25        \u001b[36m2.9867\u001b[0m       \u001b[32m0.1935\u001b[0m        \u001b[35m2.9864\u001b[0m  1.2390\n","     26        \u001b[36m2.9861\u001b[0m       \u001b[32m0.1973\u001b[0m        \u001b[35m2.9858\u001b[0m  1.2438\n","     27        \u001b[36m2.9855\u001b[0m       \u001b[32m0.2010\u001b[0m        \u001b[35m2.9851\u001b[0m  1.3169\n","     28        \u001b[36m2.9848\u001b[0m       \u001b[32m0.2052\u001b[0m        \u001b[35m2.9845\u001b[0m  1.2583\n","     29        \u001b[36m2.9842\u001b[0m       \u001b[32m0.2104\u001b[0m        \u001b[35m2.9838\u001b[0m  1.2481\n","     30        \u001b[36m2.9835\u001b[0m       \u001b[32m0.2142\u001b[0m        \u001b[35m2.9831\u001b[0m  1.2460\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9998\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9995\u001b[0m  1.2496\n","      2        \u001b[36m2.9991\u001b[0m       0.0501        \u001b[35m2.9988\u001b[0m  1.2439\n","      3        \u001b[36m2.9985\u001b[0m       0.0501        \u001b[35m2.9981\u001b[0m  1.2446\n","      4        \u001b[36m2.9979\u001b[0m       0.0501        \u001b[35m2.9975\u001b[0m  1.2820\n","      5        \u001b[36m2.9973\u001b[0m       0.0501        \u001b[35m2.9969\u001b[0m  1.2473\n","      6        \u001b[36m2.9967\u001b[0m       0.0501        \u001b[35m2.9964\u001b[0m  1.2616\n","      7        \u001b[36m2.9961\u001b[0m       0.0501        \u001b[35m2.9958\u001b[0m  1.2611\n","      8        \u001b[36m2.9956\u001b[0m       0.0501        \u001b[35m2.9953\u001b[0m  1.2414\n","      9        \u001b[36m2.9950\u001b[0m       0.0501        \u001b[35m2.9947\u001b[0m  1.2446\n","     10        \u001b[36m2.9945\u001b[0m       0.0501        \u001b[35m2.9942\u001b[0m  1.2425\n","     11        \u001b[36m2.9940\u001b[0m       0.0501        \u001b[35m2.9937\u001b[0m  1.2475\n","     12        \u001b[36m2.9935\u001b[0m       0.0501        \u001b[35m2.9932\u001b[0m  1.2799\n","     13        \u001b[36m2.9929\u001b[0m       0.0501        \u001b[35m2.9927\u001b[0m  1.2808\n","     14        \u001b[36m2.9924\u001b[0m       \u001b[32m0.0534\u001b[0m        \u001b[35m2.9921\u001b[0m  1.3187\n","     15        \u001b[36m2.9919\u001b[0m       \u001b[32m0.0576\u001b[0m        \u001b[35m2.9916\u001b[0m  1.2602\n","     16        \u001b[36m2.9914\u001b[0m       \u001b[32m0.0731\u001b[0m        \u001b[35m2.9911\u001b[0m  1.2561\n","     17        \u001b[36m2.9909\u001b[0m       \u001b[32m0.0984\u001b[0m        \u001b[35m2.9906\u001b[0m  1.2858\n","     18        \u001b[36m2.9903\u001b[0m       \u001b[32m0.1157\u001b[0m        \u001b[35m2.9901\u001b[0m  1.2406\n","     19        \u001b[36m2.9898\u001b[0m       \u001b[32m0.1298\u001b[0m        \u001b[35m2.9895\u001b[0m  1.2777\n","     20        \u001b[36m2.9893\u001b[0m       \u001b[32m0.1425\u001b[0m        \u001b[35m2.9890\u001b[0m  1.3252\n","     21        \u001b[36m2.9887\u001b[0m       \u001b[32m0.1696\u001b[0m        \u001b[35m2.9884\u001b[0m  1.2543\n","     22        \u001b[36m2.9882\u001b[0m       \u001b[32m0.1832\u001b[0m        \u001b[35m2.9879\u001b[0m  1.2342\n","     23        \u001b[36m2.9876\u001b[0m       \u001b[32m0.1879\u001b[0m        \u001b[35m2.9873\u001b[0m  1.2661\n","     24        \u001b[36m2.9870\u001b[0m       \u001b[32m0.1935\u001b[0m        \u001b[35m2.9867\u001b[0m  1.2550\n","     25        \u001b[36m2.9865\u001b[0m       \u001b[32m0.1987\u001b[0m        \u001b[35m2.9861\u001b[0m  1.2686\n","     26        \u001b[36m2.9859\u001b[0m       \u001b[32m0.2113\u001b[0m        \u001b[35m2.9855\u001b[0m  1.2596\n","     27        \u001b[36m2.9852\u001b[0m       \u001b[32m0.2273\u001b[0m        \u001b[35m2.9849\u001b[0m  1.2531\n","     28        \u001b[36m2.9846\u001b[0m       \u001b[32m0.2418\u001b[0m        \u001b[35m2.9843\u001b[0m  1.2930\n","     29        \u001b[36m2.9839\u001b[0m       \u001b[32m0.2521\u001b[0m        \u001b[35m2.9836\u001b[0m  1.2672\n","     30        \u001b[36m2.9833\u001b[0m       \u001b[32m0.2563\u001b[0m        \u001b[35m2.9829\u001b[0m  1.2517\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9980\u001b[0m       \u001b[32m0.0567\u001b[0m        \u001b[35m2.9976\u001b[0m  1.2822\n","      2        \u001b[36m2.9974\u001b[0m       0.0567        \u001b[35m2.9970\u001b[0m  1.2550\n","      3        \u001b[36m2.9968\u001b[0m       \u001b[32m0.0600\u001b[0m        \u001b[35m2.9965\u001b[0m  1.2668\n","      4        \u001b[36m2.9963\u001b[0m       \u001b[32m0.0642\u001b[0m        \u001b[35m2.9959\u001b[0m  1.2539\n","      5        \u001b[36m2.9958\u001b[0m       \u001b[32m0.0726\u001b[0m        \u001b[35m2.9954\u001b[0m  1.2586\n","      6        \u001b[36m2.9952\u001b[0m       \u001b[32m0.0797\u001b[0m        \u001b[35m2.9949\u001b[0m  1.2523\n","      7        \u001b[36m2.9947\u001b[0m       \u001b[32m0.0858\u001b[0m        \u001b[35m2.9944\u001b[0m  1.2503\n","      8        \u001b[36m2.9942\u001b[0m       \u001b[32m0.0923\u001b[0m        \u001b[35m2.9939\u001b[0m  1.3238\n","      9        \u001b[36m2.9937\u001b[0m       \u001b[32m0.0951\u001b[0m        \u001b[35m2.9934\u001b[0m  1.2602\n","     10        \u001b[36m2.9932\u001b[0m       \u001b[32m0.0970\u001b[0m        \u001b[35m2.9929\u001b[0m  1.2777\n","     11        \u001b[36m2.9927\u001b[0m       \u001b[32m0.0975\u001b[0m        \u001b[35m2.9924\u001b[0m  1.2393\n","     12        \u001b[36m2.9922\u001b[0m       \u001b[32m0.0979\u001b[0m        \u001b[35m2.9918\u001b[0m  1.2345\n","     13        \u001b[36m2.9916\u001b[0m       \u001b[32m0.0984\u001b[0m        \u001b[35m2.9913\u001b[0m  1.2798\n","     14        \u001b[36m2.9911\u001b[0m       0.0984        \u001b[35m2.9908\u001b[0m  1.2557\n","     15        \u001b[36m2.9906\u001b[0m       0.0979        \u001b[35m2.9902\u001b[0m  1.2511\n","     16        \u001b[36m2.9900\u001b[0m       0.0984        \u001b[35m2.9897\u001b[0m  1.2552\n","     17        \u001b[36m2.9894\u001b[0m       0.0984        \u001b[35m2.9891\u001b[0m  1.2706\n","     18        \u001b[36m2.9889\u001b[0m       \u001b[32m0.0989\u001b[0m        \u001b[35m2.9885\u001b[0m  1.2485\n","     19        \u001b[36m2.9883\u001b[0m       0.0989        \u001b[35m2.9879\u001b[0m  1.2566\n","     20        \u001b[36m2.9877\u001b[0m       0.0989        \u001b[35m2.9873\u001b[0m  1.2714\n","     21        \u001b[36m2.9870\u001b[0m       0.0989        \u001b[35m2.9867\u001b[0m  1.3081\n","     22        \u001b[36m2.9864\u001b[0m       0.0989        \u001b[35m2.9861\u001b[0m  1.2566\n","     23        \u001b[36m2.9858\u001b[0m       0.0989        \u001b[35m2.9854\u001b[0m  1.2635\n","     24        \u001b[36m2.9851\u001b[0m       0.0989        \u001b[35m2.9847\u001b[0m  1.2584\n","     25        \u001b[36m2.9844\u001b[0m       0.0989        \u001b[35m2.9840\u001b[0m  1.2692\n","     26        \u001b[36m2.9837\u001b[0m       \u001b[32m0.0993\u001b[0m        \u001b[35m2.9833\u001b[0m  1.2405\n","     27        \u001b[36m2.9830\u001b[0m       \u001b[32m0.0998\u001b[0m        \u001b[35m2.9826\u001b[0m  1.2432\n","     28        \u001b[36m2.9822\u001b[0m       0.0998        \u001b[35m2.9818\u001b[0m  1.2328\n","     29        \u001b[36m2.9815\u001b[0m       0.0998        \u001b[35m2.9810\u001b[0m  1.2728\n","     30        \u001b[36m2.9807\u001b[0m       \u001b[32m0.1007\u001b[0m        \u001b[35m2.9802\u001b[0m  1.2497\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9986\u001b[0m       \u001b[32m0.0511\u001b[0m        \u001b[35m2.9982\u001b[0m  1.2476\n","      2        \u001b[36m2.9980\u001b[0m       0.0511        \u001b[35m2.9976\u001b[0m  1.2718\n","      3        \u001b[36m2.9973\u001b[0m       0.0511        \u001b[35m2.9970\u001b[0m  1.3394\n","      4        \u001b[36m2.9967\u001b[0m       0.0511        \u001b[35m2.9963\u001b[0m  1.2473\n","      5        \u001b[36m2.9961\u001b[0m       0.0511        \u001b[35m2.9957\u001b[0m  1.2864\n","      6        \u001b[36m2.9954\u001b[0m       0.0511        \u001b[35m2.9951\u001b[0m  1.3145\n","      7        \u001b[36m2.9948\u001b[0m       0.0511        \u001b[35m2.9945\u001b[0m  1.2359\n","      8        \u001b[36m2.9942\u001b[0m       0.0511        \u001b[35m2.9939\u001b[0m  1.2495\n","      9        \u001b[36m2.9936\u001b[0m       0.0511        \u001b[35m2.9932\u001b[0m  1.2351\n","     10        \u001b[36m2.9930\u001b[0m       0.0511        \u001b[35m2.9926\u001b[0m  1.2843\n","     11        \u001b[36m2.9923\u001b[0m       0.0511        \u001b[35m2.9920\u001b[0m  1.2274\n","     12        \u001b[36m2.9917\u001b[0m       0.0511        \u001b[35m2.9913\u001b[0m  1.2397\n","     13        \u001b[36m2.9910\u001b[0m       0.0511        \u001b[35m2.9907\u001b[0m  1.2697\n","     14        \u001b[36m2.9904\u001b[0m       0.0511        \u001b[35m2.9900\u001b[0m  1.2890\n","     15        \u001b[36m2.9897\u001b[0m       \u001b[32m0.0515\u001b[0m        \u001b[35m2.9894\u001b[0m  1.2810\n","     16        \u001b[36m2.9891\u001b[0m       \u001b[32m0.0572\u001b[0m        \u001b[35m2.9887\u001b[0m  1.2635\n","     17        \u001b[36m2.9884\u001b[0m       \u001b[32m0.0694\u001b[0m        \u001b[35m2.9880\u001b[0m  1.2680\n","     18        \u001b[36m2.9877\u001b[0m       \u001b[32m0.0783\u001b[0m        \u001b[35m2.9873\u001b[0m  1.2502\n","     19        \u001b[36m2.9870\u001b[0m       \u001b[32m0.0876\u001b[0m        \u001b[35m2.9866\u001b[0m  1.2853\n","     20        \u001b[36m2.9862\u001b[0m       \u001b[32m0.0989\u001b[0m        \u001b[35m2.9859\u001b[0m  1.3151\n","     21        \u001b[36m2.9855\u001b[0m       \u001b[32m0.1148\u001b[0m        \u001b[35m2.9851\u001b[0m  1.2834\n","     22        \u001b[36m2.9847\u001b[0m       \u001b[32m0.1340\u001b[0m        \u001b[35m2.9844\u001b[0m  1.4819\n","     23        \u001b[36m2.9840\u001b[0m       \u001b[32m0.1584\u001b[0m        \u001b[35m2.9836\u001b[0m  1.2652\n","     24        \u001b[36m2.9832\u001b[0m       \u001b[32m0.1734\u001b[0m        \u001b[35m2.9828\u001b[0m  1.2630\n","     25        \u001b[36m2.9824\u001b[0m       \u001b[32m0.1795\u001b[0m        \u001b[35m2.9820\u001b[0m  1.2745\n","     26        \u001b[36m2.9815\u001b[0m       \u001b[32m0.1846\u001b[0m        \u001b[35m2.9811\u001b[0m  1.2743\n","     27        \u001b[36m2.9807\u001b[0m       \u001b[32m0.1879\u001b[0m        \u001b[35m2.9802\u001b[0m  1.3232\n","     28        \u001b[36m2.9797\u001b[0m       \u001b[32m0.1912\u001b[0m        \u001b[35m2.9793\u001b[0m  1.2933\n","     29        \u001b[36m2.9788\u001b[0m       \u001b[32m0.1954\u001b[0m        \u001b[35m2.9784\u001b[0m  1.3925\n","     30        \u001b[36m2.9779\u001b[0m       \u001b[32m0.1978\u001b[0m        \u001b[35m2.9774\u001b[0m  1.3286\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9984\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9982\u001b[0m  1.2518\n","      2        \u001b[36m2.9980\u001b[0m       0.0501        \u001b[35m2.9977\u001b[0m  1.2542\n","      3        \u001b[36m2.9975\u001b[0m       0.0501        \u001b[35m2.9973\u001b[0m  1.2574\n","      4        \u001b[36m2.9971\u001b[0m       0.0501        \u001b[35m2.9969\u001b[0m  1.2427\n","      5        \u001b[36m2.9967\u001b[0m       0.0501        \u001b[35m2.9965\u001b[0m  1.2380\n","      6        \u001b[36m2.9964\u001b[0m       0.0501        \u001b[35m2.9961\u001b[0m  1.2737\n","      7        \u001b[36m2.9960\u001b[0m       0.0501        \u001b[35m2.9958\u001b[0m  1.2782\n","      8        \u001b[36m2.9956\u001b[0m       0.0501        \u001b[35m2.9954\u001b[0m  1.2613\n","      9        \u001b[36m2.9952\u001b[0m       \u001b[32m0.0544\u001b[0m        \u001b[35m2.9950\u001b[0m  1.2696\n","     10        \u001b[36m2.9949\u001b[0m       \u001b[32m0.0623\u001b[0m        \u001b[35m2.9946\u001b[0m  1.2633\n","     11        \u001b[36m2.9945\u001b[0m       \u001b[32m0.0811\u001b[0m        \u001b[35m2.9943\u001b[0m  1.2501\n","     12        \u001b[36m2.9941\u001b[0m       \u001b[32m0.0867\u001b[0m        \u001b[35m2.9939\u001b[0m  1.2479\n","     13        \u001b[36m2.9938\u001b[0m       0.0745        \u001b[35m2.9935\u001b[0m  1.2688\n","     14        \u001b[36m2.9934\u001b[0m       0.0619        \u001b[35m2.9932\u001b[0m  1.2777\n","     15        \u001b[36m2.9930\u001b[0m       0.0548        \u001b[35m2.9928\u001b[0m  1.2461\n","     16        \u001b[36m2.9926\u001b[0m       0.0525        \u001b[35m2.9924\u001b[0m  1.2281\n","     17        \u001b[36m2.9923\u001b[0m       0.0511        \u001b[35m2.9920\u001b[0m  1.2432\n","     18        \u001b[36m2.9919\u001b[0m       0.0511        \u001b[35m2.9917\u001b[0m  1.2508\n","     19        \u001b[36m2.9915\u001b[0m       0.0511        \u001b[35m2.9913\u001b[0m  1.2553\n","     20        \u001b[36m2.9911\u001b[0m       0.0511        \u001b[35m2.9909\u001b[0m  1.2336\n","     21        \u001b[36m2.9907\u001b[0m       0.0511        \u001b[35m2.9905\u001b[0m  1.2719\n","     22        \u001b[36m2.9903\u001b[0m       0.0511        \u001b[35m2.9901\u001b[0m  1.3126\n","     23        \u001b[36m2.9899\u001b[0m       0.0520        \u001b[35m2.9897\u001b[0m  1.2479\n","     24        \u001b[36m2.9895\u001b[0m       0.0548        \u001b[35m2.9893\u001b[0m  1.2548\n","     25        \u001b[36m2.9891\u001b[0m       0.0614        \u001b[35m2.9888\u001b[0m  1.2457\n","     26        \u001b[36m2.9887\u001b[0m       0.0689        \u001b[35m2.9884\u001b[0m  1.2912\n","     27        \u001b[36m2.9882\u001b[0m       0.0783        \u001b[35m2.9880\u001b[0m  1.2437\n","     28        \u001b[36m2.9878\u001b[0m       0.0848        \u001b[35m2.9875\u001b[0m  1.2316\n","     29        \u001b[36m2.9873\u001b[0m       \u001b[32m0.0886\u001b[0m        \u001b[35m2.9870\u001b[0m  1.2588\n","     30        \u001b[36m2.9868\u001b[0m       \u001b[32m0.0933\u001b[0m        \u001b[35m2.9865\u001b[0m  1.2741\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9996\u001b[0m       \u001b[32m0.0506\u001b[0m        \u001b[35m2.9994\u001b[0m  1.2979\n","      2        \u001b[36m2.9989\u001b[0m       0.0506        \u001b[35m2.9987\u001b[0m  1.2325\n","      3        \u001b[36m2.9982\u001b[0m       0.0506        \u001b[35m2.9980\u001b[0m  1.2477\n","      4        \u001b[36m2.9975\u001b[0m       0.0506        \u001b[35m2.9974\u001b[0m  1.2395\n","      5        \u001b[36m2.9969\u001b[0m       0.0506        \u001b[35m2.9967\u001b[0m  1.2423\n","      6        \u001b[36m2.9963\u001b[0m       0.0506        \u001b[35m2.9961\u001b[0m  1.2557\n","      7        \u001b[36m2.9957\u001b[0m       0.0506        \u001b[35m2.9955\u001b[0m  1.2574\n","      8        \u001b[36m2.9951\u001b[0m       0.0506        \u001b[35m2.9949\u001b[0m  1.2554\n","      9        \u001b[36m2.9945\u001b[0m       0.0506        \u001b[35m2.9943\u001b[0m  1.2453\n","     10        \u001b[36m2.9939\u001b[0m       \u001b[32m0.0511\u001b[0m        \u001b[35m2.9937\u001b[0m  1.2299\n","     11        \u001b[36m2.9933\u001b[0m       \u001b[32m0.0530\u001b[0m        \u001b[35m2.9931\u001b[0m  1.2619\n","     12        \u001b[36m2.9927\u001b[0m       \u001b[32m0.0586\u001b[0m        \u001b[35m2.9925\u001b[0m  1.2695\n","     13        \u001b[36m2.9921\u001b[0m       \u001b[32m0.0717\u001b[0m        \u001b[35m2.9919\u001b[0m  1.2629\n","     14        \u001b[36m2.9915\u001b[0m       \u001b[32m0.0853\u001b[0m        \u001b[35m2.9913\u001b[0m  1.2666\n","     15        \u001b[36m2.9909\u001b[0m       \u001b[32m0.1007\u001b[0m        \u001b[35m2.9907\u001b[0m  1.2808\n","     16        \u001b[36m2.9903\u001b[0m       \u001b[32m0.1181\u001b[0m        \u001b[35m2.9901\u001b[0m  1.3783\n","     17        \u001b[36m2.9897\u001b[0m       \u001b[32m0.1345\u001b[0m        \u001b[35m2.9895\u001b[0m  1.2550\n","     18        \u001b[36m2.9891\u001b[0m       \u001b[32m0.1471\u001b[0m        \u001b[35m2.9889\u001b[0m  1.2400\n","     19        \u001b[36m2.9885\u001b[0m       \u001b[32m0.1598\u001b[0m        \u001b[35m2.9882\u001b[0m  1.3175\n","     20        \u001b[36m2.9878\u001b[0m       \u001b[32m0.1668\u001b[0m        \u001b[35m2.9876\u001b[0m  1.2905\n","     21        \u001b[36m2.9872\u001b[0m       \u001b[32m0.1776\u001b[0m        \u001b[35m2.9869\u001b[0m  1.2504\n","     22        \u001b[36m2.9865\u001b[0m       \u001b[32m0.1888\u001b[0m        \u001b[35m2.9862\u001b[0m  1.2595\n","     23        \u001b[36m2.9858\u001b[0m       \u001b[32m0.2048\u001b[0m        \u001b[35m2.9855\u001b[0m  1.3646\n","     24        \u001b[36m2.9851\u001b[0m       \u001b[32m0.2127\u001b[0m        \u001b[35m2.9848\u001b[0m  1.2476\n","     25        \u001b[36m2.9844\u001b[0m       \u001b[32m0.2202\u001b[0m        \u001b[35m2.9841\u001b[0m  1.2496\n","     26        \u001b[36m2.9836\u001b[0m       0.2193        \u001b[35m2.9833\u001b[0m  1.2510\n","     27        \u001b[36m2.9829\u001b[0m       0.2174        \u001b[35m2.9825\u001b[0m  1.2826\n","     28        \u001b[36m2.9820\u001b[0m       0.2184        \u001b[35m2.9817\u001b[0m  1.2448\n","     29        \u001b[36m2.9812\u001b[0m       \u001b[32m0.2245\u001b[0m        \u001b[35m2.9808\u001b[0m  1.2450\n","     30        \u001b[36m2.9803\u001b[0m       \u001b[32m0.2306\u001b[0m        \u001b[35m2.9800\u001b[0m  1.2530\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9982\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9978\u001b[0m  1.2952\n","      2        \u001b[36m2.9976\u001b[0m       0.0501        \u001b[35m2.9973\u001b[0m  1.2650\n","      3        \u001b[36m2.9972\u001b[0m       0.0501        \u001b[35m2.9968\u001b[0m  1.2387\n","      4        \u001b[36m2.9967\u001b[0m       0.0501        \u001b[35m2.9964\u001b[0m  1.2609\n","      5        \u001b[36m2.9963\u001b[0m       0.0501        \u001b[35m2.9960\u001b[0m  1.2790\n","      6        \u001b[36m2.9959\u001b[0m       0.0501        \u001b[35m2.9956\u001b[0m  1.2507\n","      7        \u001b[36m2.9954\u001b[0m       0.0501        \u001b[35m2.9952\u001b[0m  1.2679\n","      8        \u001b[36m2.9950\u001b[0m       0.0501        \u001b[35m2.9948\u001b[0m  1.3502\n","      9        \u001b[36m2.9946\u001b[0m       0.0501        \u001b[35m2.9944\u001b[0m  1.2473\n","     10        \u001b[36m2.9942\u001b[0m       0.0501        \u001b[35m2.9940\u001b[0m  1.3209\n","     11        \u001b[36m2.9939\u001b[0m       0.0501        \u001b[35m2.9936\u001b[0m  1.2610\n","     12        \u001b[36m2.9935\u001b[0m       0.0501        \u001b[35m2.9932\u001b[0m  1.2539\n","     13        \u001b[36m2.9931\u001b[0m       0.0501        \u001b[35m2.9928\u001b[0m  1.2650\n","     14        \u001b[36m2.9927\u001b[0m       0.0501        \u001b[35m2.9924\u001b[0m  1.2486\n","     15        \u001b[36m2.9923\u001b[0m       0.0501        \u001b[35m2.9920\u001b[0m  1.2862\n","     16        \u001b[36m2.9919\u001b[0m       0.0501        \u001b[35m2.9916\u001b[0m  1.3092\n","     17        \u001b[36m2.9914\u001b[0m       0.0501        \u001b[35m2.9912\u001b[0m  1.2517\n","     18        \u001b[36m2.9910\u001b[0m       \u001b[32m0.0558\u001b[0m        \u001b[35m2.9908\u001b[0m  1.2751\n","     19        \u001b[36m2.9906\u001b[0m       \u001b[32m0.0684\u001b[0m        \u001b[35m2.9903\u001b[0m  1.2597\n","     20        \u001b[36m2.9902\u001b[0m       \u001b[32m0.0843\u001b[0m        \u001b[35m2.9899\u001b[0m  1.2826\n","     21        \u001b[36m2.9898\u001b[0m       \u001b[32m0.0956\u001b[0m        \u001b[35m2.9895\u001b[0m  1.2591\n","     22        \u001b[36m2.9893\u001b[0m       \u001b[32m0.0979\u001b[0m        \u001b[35m2.9890\u001b[0m  1.2462\n","     23        \u001b[36m2.9889\u001b[0m       \u001b[32m0.0993\u001b[0m        \u001b[35m2.9886\u001b[0m  1.2711\n","     24        \u001b[36m2.9884\u001b[0m       \u001b[32m0.0998\u001b[0m        \u001b[35m2.9881\u001b[0m  1.2808\n","     25        \u001b[36m2.9880\u001b[0m       \u001b[32m0.1003\u001b[0m        \u001b[35m2.9877\u001b[0m  1.2639\n","     26        \u001b[36m2.9875\u001b[0m       \u001b[32m0.1026\u001b[0m        \u001b[35m2.9872\u001b[0m  1.2580\n","     27        \u001b[36m2.9870\u001b[0m       \u001b[32m0.1106\u001b[0m        \u001b[35m2.9867\u001b[0m  1.2698\n","     28        \u001b[36m2.9865\u001b[0m       \u001b[32m0.1190\u001b[0m        \u001b[35m2.9862\u001b[0m  1.2472\n","     29        \u001b[36m2.9860\u001b[0m       \u001b[32m0.1265\u001b[0m        \u001b[35m2.9857\u001b[0m  1.2618\n","     30        \u001b[36m2.9855\u001b[0m       \u001b[32m0.1350\u001b[0m        \u001b[35m2.9852\u001b[0m  1.2475\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9996\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9990\u001b[0m  1.2683\n","      2        \u001b[36m2.9989\u001b[0m       0.0501        \u001b[35m2.9984\u001b[0m  1.2607\n","      3        \u001b[36m2.9983\u001b[0m       0.0501        \u001b[35m2.9978\u001b[0m  1.2358\n","      4        \u001b[36m2.9977\u001b[0m       0.0501        \u001b[35m2.9972\u001b[0m  1.3175\n","      5        \u001b[36m2.9971\u001b[0m       0.0501        \u001b[35m2.9967\u001b[0m  1.2687\n","      6        \u001b[36m2.9966\u001b[0m       0.0501        \u001b[35m2.9961\u001b[0m  1.2576\n","      7        \u001b[36m2.9960\u001b[0m       0.0501        \u001b[35m2.9956\u001b[0m  1.2388\n","      8        \u001b[36m2.9955\u001b[0m       0.0501        \u001b[35m2.9951\u001b[0m  1.2558\n","      9        \u001b[36m2.9950\u001b[0m       0.0501        \u001b[35m2.9945\u001b[0m  1.2653\n","     10        \u001b[36m2.9944\u001b[0m       0.0501        \u001b[35m2.9940\u001b[0m  1.2568\n","     11        \u001b[36m2.9939\u001b[0m       0.0501        \u001b[35m2.9935\u001b[0m  1.2618\n","     12        \u001b[36m2.9934\u001b[0m       0.0501        \u001b[35m2.9930\u001b[0m  1.2515\n","     13        \u001b[36m2.9928\u001b[0m       0.0501        \u001b[35m2.9924\u001b[0m  1.2523\n","     14        \u001b[36m2.9923\u001b[0m       0.0501        \u001b[35m2.9919\u001b[0m  1.2547\n","     15        \u001b[36m2.9918\u001b[0m       \u001b[32m0.0506\u001b[0m        \u001b[35m2.9914\u001b[0m  1.2446\n","     16        \u001b[36m2.9912\u001b[0m       \u001b[32m0.0525\u001b[0m        \u001b[35m2.9908\u001b[0m  1.2813\n","     17        \u001b[36m2.9907\u001b[0m       \u001b[32m0.0614\u001b[0m        \u001b[35m2.9903\u001b[0m  1.2813\n","     18        \u001b[36m2.9901\u001b[0m       \u001b[32m0.0726\u001b[0m        \u001b[35m2.9897\u001b[0m  1.2455\n","     19        \u001b[36m2.9896\u001b[0m       \u001b[32m0.0806\u001b[0m        \u001b[35m2.9892\u001b[0m  1.2606\n","     20        \u001b[36m2.9890\u001b[0m       \u001b[32m0.0914\u001b[0m        \u001b[35m2.9886\u001b[0m  1.2596\n","     21        \u001b[36m2.9884\u001b[0m       \u001b[32m0.0937\u001b[0m        \u001b[35m2.9880\u001b[0m  1.2904\n","     22        \u001b[36m2.9878\u001b[0m       \u001b[32m0.0965\u001b[0m        \u001b[35m2.9874\u001b[0m  1.2660\n","     23        \u001b[36m2.9872\u001b[0m       \u001b[32m0.0970\u001b[0m        \u001b[35m2.9868\u001b[0m  1.3063\n","     24        \u001b[36m2.9865\u001b[0m       \u001b[32m0.0984\u001b[0m        \u001b[35m2.9861\u001b[0m  1.2424\n","     25        \u001b[36m2.9859\u001b[0m       \u001b[32m0.1012\u001b[0m        \u001b[35m2.9855\u001b[0m  1.3827\n","     26        \u001b[36m2.9852\u001b[0m       \u001b[32m0.1073\u001b[0m        \u001b[35m2.9848\u001b[0m  1.2589\n","     27        \u001b[36m2.9845\u001b[0m       \u001b[32m0.1195\u001b[0m        \u001b[35m2.9841\u001b[0m  1.2543\n","     28        \u001b[36m2.9839\u001b[0m       \u001b[32m0.1331\u001b[0m        \u001b[35m2.9834\u001b[0m  1.2442\n","     29        \u001b[36m2.9831\u001b[0m       \u001b[32m0.1425\u001b[0m        \u001b[35m2.9827\u001b[0m  1.3224\n","     30        \u001b[36m2.9824\u001b[0m       \u001b[32m0.1462\u001b[0m        \u001b[35m2.9820\u001b[0m  1.2577\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9962\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9932\u001b[0m  1.2710\n","      2        \u001b[36m2.9911\u001b[0m       \u001b[32m0.0722\u001b[0m        \u001b[35m2.9878\u001b[0m  1.3413\n","      3        \u001b[36m2.9851\u001b[0m       \u001b[32m0.1101\u001b[0m        \u001b[35m2.9811\u001b[0m  1.2611\n","      4        \u001b[36m2.9772\u001b[0m       \u001b[32m0.1823\u001b[0m        \u001b[35m2.9716\u001b[0m  1.2802\n","      5        \u001b[36m2.9652\u001b[0m       \u001b[32m0.2788\u001b[0m        \u001b[35m2.9564\u001b[0m  1.2629\n","      6        \u001b[36m2.9448\u001b[0m       \u001b[32m0.4035\u001b[0m        \u001b[35m2.9290\u001b[0m  1.2971\n","      7        \u001b[36m2.9054\u001b[0m       0.3786        \u001b[35m2.8727\u001b[0m  1.2602\n","      8        \u001b[36m2.8173\u001b[0m       0.2765        \u001b[35m2.7388\u001b[0m  1.2355\n","      9        \u001b[36m2.6120\u001b[0m       0.2882        \u001b[35m2.4538\u001b[0m  1.2351\n","     10        \u001b[36m2.2847\u001b[0m       \u001b[32m0.4794\u001b[0m        \u001b[35m2.1107\u001b[0m  1.2758\n","     11        \u001b[36m1.9568\u001b[0m       \u001b[32m0.6724\u001b[0m        \u001b[35m1.7954\u001b[0m  1.2666\n","     12        \u001b[36m1.6473\u001b[0m       \u001b[32m0.7352\u001b[0m        \u001b[35m1.4911\u001b[0m  1.2579\n","     13        \u001b[36m1.3474\u001b[0m       \u001b[32m0.7498\u001b[0m        \u001b[35m1.2006\u001b[0m  1.2601\n","     14        \u001b[36m1.0749\u001b[0m       \u001b[32m0.7685\u001b[0m        \u001b[35m0.9579\u001b[0m  1.2571\n","     15        \u001b[36m0.8631\u001b[0m       \u001b[32m0.8027\u001b[0m        \u001b[35m0.7778\u001b[0m  1.2406\n","     16        \u001b[36m0.7063\u001b[0m       \u001b[32m0.8519\u001b[0m        \u001b[35m0.6412\u001b[0m  1.2509\n","     17        \u001b[36m0.5859\u001b[0m       \u001b[32m0.8833\u001b[0m        \u001b[35m0.5334\u001b[0m  1.2362\n","     18        \u001b[36m0.4905\u001b[0m       \u001b[32m0.9100\u001b[0m        \u001b[35m0.4474\u001b[0m  1.2801\n","     19        \u001b[36m0.4147\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.3799\u001b[0m  1.2286\n","     20        \u001b[36m0.3561\u001b[0m       \u001b[32m0.9288\u001b[0m        \u001b[35m0.3294\u001b[0m  1.2468\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9973\u001b[0m       \u001b[32m0.0511\u001b[0m        \u001b[35m2.9931\u001b[0m  1.3078\n","      2        \u001b[36m2.9906\u001b[0m       0.0511        \u001b[35m2.9862\u001b[0m  1.2990\n","      3        \u001b[36m2.9828\u001b[0m       \u001b[32m0.1176\u001b[0m        \u001b[35m2.9772\u001b[0m  1.2695\n","      4        \u001b[36m2.9719\u001b[0m       \u001b[32m0.2207\u001b[0m        \u001b[35m2.9636\u001b[0m  1.2342\n","      5        \u001b[36m2.9537\u001b[0m       0.2170        \u001b[35m2.9390\u001b[0m  1.2708\n","      6        \u001b[36m2.9174\u001b[0m       \u001b[32m0.2338\u001b[0m        \u001b[35m2.8860\u001b[0m  1.2520\n","      7        \u001b[36m2.8335\u001b[0m       \u001b[32m0.2704\u001b[0m        \u001b[35m2.7598\u001b[0m  1.2585\n","      8        \u001b[36m2.6535\u001b[0m       0.2282        \u001b[35m2.5281\u001b[0m  1.2527\n","      9        \u001b[36m2.4074\u001b[0m       \u001b[32m0.3533\u001b[0m        \u001b[35m2.2880\u001b[0m  1.2820\n","     10        \u001b[36m2.1841\u001b[0m       \u001b[32m0.5689\u001b[0m        \u001b[35m2.0723\u001b[0m  1.2590\n","     11        \u001b[36m1.9591\u001b[0m       \u001b[32m0.6218\u001b[0m        \u001b[35m1.8310\u001b[0m  1.2508\n","     12        \u001b[36m1.6984\u001b[0m       \u001b[32m0.6870\u001b[0m        \u001b[35m1.5519\u001b[0m  1.2474\n","     13        \u001b[36m1.4061\u001b[0m       \u001b[32m0.7713\u001b[0m        \u001b[35m1.2569\u001b[0m  1.2878\n","     14        \u001b[36m1.1189\u001b[0m       \u001b[32m0.8135\u001b[0m        \u001b[35m0.9914\u001b[0m  1.2517\n","     15        \u001b[36m0.8731\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.7734\u001b[0m  1.2648\n","     16        \u001b[36m0.6809\u001b[0m       \u001b[32m0.8754\u001b[0m        \u001b[35m0.6118\u001b[0m  1.2463\n","     17        \u001b[36m0.5448\u001b[0m       \u001b[32m0.8936\u001b[0m        \u001b[35m0.5010\u001b[0m  1.2676\n","     18        \u001b[36m0.4514\u001b[0m       \u001b[32m0.9147\u001b[0m        \u001b[35m0.4241\u001b[0m  1.2488\n","     19        \u001b[36m0.3851\u001b[0m       \u001b[32m0.9264\u001b[0m        \u001b[35m0.3683\u001b[0m  1.2673\n","     20        \u001b[36m0.3357\u001b[0m       \u001b[32m0.9335\u001b[0m        \u001b[35m0.3261\u001b[0m  1.3146\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9965\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9936\u001b[0m  1.3038\n","      2        \u001b[36m2.9919\u001b[0m       0.0501        \u001b[35m2.9887\u001b[0m  1.2390\n","      3        \u001b[36m2.9863\u001b[0m       \u001b[32m0.1396\u001b[0m        \u001b[35m2.9824\u001b[0m  1.2367\n","      4        \u001b[36m2.9788\u001b[0m       \u001b[32m0.1757\u001b[0m        \u001b[35m2.9734\u001b[0m  1.2642\n","      5        \u001b[36m2.9674\u001b[0m       \u001b[32m0.3500\u001b[0m        \u001b[35m2.9594\u001b[0m  1.2593\n","      6        \u001b[36m2.9488\u001b[0m       \u001b[32m0.3880\u001b[0m        \u001b[35m2.9348\u001b[0m  1.2902\n","      7        \u001b[36m2.9129\u001b[0m       \u001b[32m0.4189\u001b[0m        \u001b[35m2.8835\u001b[0m  1.2730\n","      8        \u001b[36m2.8320\u001b[0m       0.3557        \u001b[35m2.7611\u001b[0m  1.3167\n","      9        \u001b[36m2.6420\u001b[0m       0.3055        \u001b[35m2.4971\u001b[0m  1.2559\n","     10        \u001b[36m2.3383\u001b[0m       0.3346        \u001b[35m2.1885\u001b[0m  1.2548\n","     11        \u001b[36m2.0435\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.9089\u001b[0m  1.2355\n","     12        \u001b[36m1.7470\u001b[0m       \u001b[32m0.5993\u001b[0m        \u001b[35m1.6086\u001b[0m  1.2697\n","     13        \u001b[36m1.4398\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m1.3273\u001b[0m  1.2560\n","     14        \u001b[36m1.1775\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m1.1036\u001b[0m  1.2376\n","     15        \u001b[36m0.9685\u001b[0m       \u001b[32m0.7352\u001b[0m        \u001b[35m0.9207\u001b[0m  1.2634\n","     16        \u001b[36m0.7979\u001b[0m       \u001b[32m0.7769\u001b[0m        \u001b[35m0.7688\u001b[0m  1.2989\n","     17        \u001b[36m0.6600\u001b[0m       \u001b[32m0.8290\u001b[0m        \u001b[35m0.6431\u001b[0m  1.2930\n","     18        \u001b[36m0.5479\u001b[0m       \u001b[32m0.8796\u001b[0m        \u001b[35m0.5378\u001b[0m  1.2849\n","     19        \u001b[36m0.4571\u001b[0m       \u001b[32m0.9128\u001b[0m        \u001b[35m0.4525\u001b[0m  1.2497\n","     20        \u001b[36m0.3870\u001b[0m       \u001b[32m0.9241\u001b[0m        \u001b[35m0.3882\u001b[0m  1.2698\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9971\u001b[0m       \u001b[32m0.0506\u001b[0m        \u001b[35m2.9935\u001b[0m  1.2866\n","      2        \u001b[36m2.9911\u001b[0m       \u001b[32m0.0558\u001b[0m        \u001b[35m2.9875\u001b[0m  1.2296\n","      3        \u001b[36m2.9845\u001b[0m       \u001b[32m0.1022\u001b[0m        \u001b[35m2.9800\u001b[0m  1.2434\n","      4        \u001b[36m2.9754\u001b[0m       \u001b[32m0.1584\u001b[0m        \u001b[35m2.9687\u001b[0m  1.2822\n","      5        \u001b[36m2.9609\u001b[0m       \u001b[32m0.2816\u001b[0m        \u001b[35m2.9498\u001b[0m  1.2554\n","      6        \u001b[36m2.9344\u001b[0m       \u001b[32m0.3233\u001b[0m        \u001b[35m2.9124\u001b[0m  1.2347\n","      7        \u001b[36m2.8760\u001b[0m       0.2873        \u001b[35m2.8230\u001b[0m  1.2592\n","      8        \u001b[36m2.7372\u001b[0m       0.2601        \u001b[35m2.6231\u001b[0m  1.2528\n","      9        \u001b[36m2.4933\u001b[0m       0.3177        \u001b[35m2.3569\u001b[0m  1.2611\n","     10        \u001b[36m2.2456\u001b[0m       \u001b[32m0.4185\u001b[0m        \u001b[35m2.1271\u001b[0m  1.2372\n","     11        \u001b[36m2.0164\u001b[0m       \u001b[32m0.5909\u001b[0m        \u001b[35m1.8903\u001b[0m  1.3677\n","     12        \u001b[36m1.7683\u001b[0m       \u001b[32m0.6157\u001b[0m        \u001b[35m1.6332\u001b[0m  1.2516\n","     13        \u001b[36m1.5068\u001b[0m       \u001b[32m0.6659\u001b[0m        \u001b[35m1.3735\u001b[0m  1.2703\n","     14        \u001b[36m1.2538\u001b[0m       \u001b[32m0.7099\u001b[0m        \u001b[35m1.1371\u001b[0m  1.2634\n","     15        \u001b[36m1.0293\u001b[0m       \u001b[32m0.7605\u001b[0m        \u001b[35m0.9319\u001b[0m  1.2983\n","     16        \u001b[36m0.8358\u001b[0m       \u001b[32m0.8060\u001b[0m        \u001b[35m0.7571\u001b[0m  1.2532\n","     17        \u001b[36m0.6773\u001b[0m       \u001b[32m0.8472\u001b[0m        \u001b[35m0.6165\u001b[0m  1.2457\n","     18        \u001b[36m0.5556\u001b[0m       \u001b[32m0.8772\u001b[0m        \u001b[35m0.5096\u001b[0m  1.2337\n","     19        \u001b[36m0.4657\u001b[0m       \u001b[32m0.9025\u001b[0m        \u001b[35m0.4313\u001b[0m  1.2786\n","     20        \u001b[36m0.4000\u001b[0m       \u001b[32m0.9147\u001b[0m        \u001b[35m0.3740\u001b[0m  1.2361\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9971\u001b[0m       \u001b[32m0.0511\u001b[0m        \u001b[35m2.9941\u001b[0m  1.2793\n","      2        \u001b[36m2.9926\u001b[0m       0.0511        \u001b[35m2.9896\u001b[0m  1.2676\n","      3        \u001b[36m2.9877\u001b[0m       0.0511        \u001b[35m2.9840\u001b[0m  1.2697\n","      4        \u001b[36m2.9813\u001b[0m       \u001b[32m0.0942\u001b[0m        \u001b[35m2.9766\u001b[0m  1.2515\n","      5        \u001b[36m2.9724\u001b[0m       \u001b[32m0.1289\u001b[0m        \u001b[35m2.9660\u001b[0m  1.2419\n","      6        \u001b[36m2.9589\u001b[0m       \u001b[32m0.3346\u001b[0m        \u001b[35m2.9488\u001b[0m  1.2695\n","      7        \u001b[36m2.9359\u001b[0m       \u001b[32m0.5145\u001b[0m        \u001b[35m2.9180\u001b[0m  1.2966\n","      8        \u001b[36m2.8921\u001b[0m       \u001b[32m0.5347\u001b[0m        \u001b[35m2.8557\u001b[0m  1.2602\n","      9        \u001b[36m2.7963\u001b[0m       0.5281        \u001b[35m2.7126\u001b[0m  1.2360\n","     10        \u001b[36m2.5830\u001b[0m       0.5286        \u001b[35m2.4219\u001b[0m  1.2670\n","     11        \u001b[36m2.2447\u001b[0m       \u001b[32m0.6584\u001b[0m        \u001b[35m2.0531\u001b[0m  1.2605\n","     12        \u001b[36m1.8600\u001b[0m       \u001b[32m0.7029\u001b[0m        \u001b[35m1.6550\u001b[0m  1.2461\n","     13        \u001b[36m1.4656\u001b[0m       \u001b[32m0.7601\u001b[0m        \u001b[35m1.2849\u001b[0m  1.2493\n","     14        \u001b[36m1.1363\u001b[0m       \u001b[32m0.7985\u001b[0m        \u001b[35m1.0121\u001b[0m  1.2678\n","     15        \u001b[36m0.9038\u001b[0m       \u001b[32m0.8154\u001b[0m        \u001b[35m0.8234\u001b[0m  1.3461\n","     16        \u001b[36m0.7362\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.6809\u001b[0m  1.2692\n","     17        \u001b[36m0.6066\u001b[0m       \u001b[32m0.8725\u001b[0m        \u001b[35m0.5670\u001b[0m  1.2540\n","     18        \u001b[36m0.5030\u001b[0m       \u001b[32m0.8993\u001b[0m        \u001b[35m0.4740\u001b[0m  1.2748\n","     19        \u001b[36m0.4196\u001b[0m       \u001b[32m0.9138\u001b[0m        \u001b[35m0.4007\u001b[0m  1.2374\n","     20        \u001b[36m0.3559\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.3470\u001b[0m  1.2454\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9978\u001b[0m       \u001b[32m0.0511\u001b[0m        \u001b[35m2.9951\u001b[0m  1.2633\n","      2        \u001b[36m2.9934\u001b[0m       0.0511        \u001b[35m2.9909\u001b[0m  1.3017\n","      3        \u001b[36m2.9889\u001b[0m       0.0511        \u001b[35m2.9860\u001b[0m  1.2516\n","      4        \u001b[36m2.9833\u001b[0m       \u001b[32m0.1382\u001b[0m        \u001b[35m2.9797\u001b[0m  1.2589\n","      5        \u001b[36m2.9755\u001b[0m       \u001b[32m0.2690\u001b[0m        \u001b[35m2.9700\u001b[0m  1.2514\n","      6        \u001b[36m2.9626\u001b[0m       \u001b[32m0.3608\u001b[0m        \u001b[35m2.9527\u001b[0m  1.2831\n","      7        \u001b[36m2.9378\u001b[0m       \u001b[32m0.4274\u001b[0m        \u001b[35m2.9181\u001b[0m  1.2632\n","      8        \u001b[36m2.8839\u001b[0m       0.2962        \u001b[35m2.8365\u001b[0m  1.2547\n","      9        \u001b[36m2.7529\u001b[0m       0.2418        \u001b[35m2.6460\u001b[0m  1.2548\n","     10        \u001b[36m2.5166\u001b[0m       0.2976        \u001b[35m2.3909\u001b[0m  1.2995\n","     11        \u001b[36m2.2752\u001b[0m       \u001b[32m0.4410\u001b[0m        \u001b[35m2.1691\u001b[0m  1.2684\n","     12        \u001b[36m2.0483\u001b[0m       \u001b[32m0.4892\u001b[0m        \u001b[35m1.9416\u001b[0m  1.2561\n","     13        \u001b[36m1.7980\u001b[0m       \u001b[32m0.5230\u001b[0m        \u001b[35m1.6901\u001b[0m  1.2762\n","     14        \u001b[36m1.5272\u001b[0m       \u001b[32m0.5740\u001b[0m        \u001b[35m1.4322\u001b[0m  1.2712\n","     15        \u001b[36m1.2673\u001b[0m       \u001b[32m0.6603\u001b[0m        \u001b[35m1.2015\u001b[0m  1.2609\n","     16        \u001b[36m1.0461\u001b[0m       \u001b[32m0.7043\u001b[0m        \u001b[35m1.0088\u001b[0m  1.2480\n","     17        \u001b[36m0.8632\u001b[0m       \u001b[32m0.7545\u001b[0m        \u001b[35m0.8449\u001b[0m  1.2533\n","     18        \u001b[36m0.7090\u001b[0m       \u001b[32m0.8088\u001b[0m        \u001b[35m0.7022\u001b[0m  1.3428\n","     19        \u001b[36m0.5802\u001b[0m       \u001b[32m0.8524\u001b[0m        \u001b[35m0.5833\u001b[0m  1.3714\n","     20        \u001b[36m0.4792\u001b[0m       \u001b[32m0.8913\u001b[0m        \u001b[35m0.4916\u001b[0m  1.3177\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9970\u001b[0m       \u001b[32m0.0506\u001b[0m        \u001b[35m2.9941\u001b[0m  1.2593\n","      2        \u001b[36m2.9923\u001b[0m       \u001b[32m0.1007\u001b[0m        \u001b[35m2.9894\u001b[0m  1.2564\n","      3        \u001b[36m2.9872\u001b[0m       \u001b[32m0.1715\u001b[0m        \u001b[35m2.9839\u001b[0m  1.2418\n","      4        \u001b[36m2.9808\u001b[0m       \u001b[32m0.3093\u001b[0m        \u001b[35m2.9763\u001b[0m  1.2349\n","      5        \u001b[36m2.9715\u001b[0m       \u001b[32m0.3852\u001b[0m        \u001b[35m2.9648\u001b[0m  1.2634\n","      6        \u001b[36m2.9564\u001b[0m       0.3721        \u001b[35m2.9451\u001b[0m  1.2449\n","      7        \u001b[36m2.9290\u001b[0m       0.3702        \u001b[35m2.9068\u001b[0m  1.2724\n","      8        \u001b[36m2.8706\u001b[0m       0.3304        \u001b[35m2.8197\u001b[0m  1.2668\n","      9        \u001b[36m2.7344\u001b[0m       0.2427        \u001b[35m2.6210\u001b[0m  1.2680\n","     10        \u001b[36m2.4818\u001b[0m       0.3566        \u001b[35m2.3321\u001b[0m  1.2518\n","     11        \u001b[36m2.1894\u001b[0m       \u001b[32m0.5923\u001b[0m        \u001b[35m2.0356\u001b[0m  1.2411\n","     12        \u001b[36m1.8837\u001b[0m       \u001b[32m0.6598\u001b[0m        \u001b[35m1.7182\u001b[0m  1.2826\n","     13        \u001b[36m1.5592\u001b[0m       \u001b[32m0.7221\u001b[0m        \u001b[35m1.3935\u001b[0m  1.3137\n","     14        \u001b[36m1.2481\u001b[0m       \u001b[32m0.7699\u001b[0m        \u001b[35m1.1109\u001b[0m  1.2701\n","     15        \u001b[36m0.9995\u001b[0m       \u001b[32m0.8135\u001b[0m        \u001b[35m0.8998\u001b[0m  1.2716\n","     16        \u001b[36m0.8162\u001b[0m       \u001b[32m0.8388\u001b[0m        \u001b[35m0.7422\u001b[0m  1.2498\n","     17        \u001b[36m0.6779\u001b[0m       \u001b[32m0.8585\u001b[0m        \u001b[35m0.6221\u001b[0m  1.2443\n","     18        \u001b[36m0.5720\u001b[0m       \u001b[32m0.8777\u001b[0m        \u001b[35m0.5297\u001b[0m  1.2467\n","     19        \u001b[36m0.4896\u001b[0m       \u001b[32m0.8960\u001b[0m        \u001b[35m0.4568\u001b[0m  1.2580\n","     20        \u001b[36m0.4237\u001b[0m       \u001b[32m0.9119\u001b[0m        \u001b[35m0.3980\u001b[0m  1.2740\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9981\u001b[0m       \u001b[32m0.0511\u001b[0m        \u001b[35m2.9948\u001b[0m  1.2652\n","      2        \u001b[36m2.9930\u001b[0m       0.0511        \u001b[35m2.9899\u001b[0m  1.2723\n","      3        \u001b[36m2.9878\u001b[0m       \u001b[32m0.0956\u001b[0m        \u001b[35m2.9842\u001b[0m  1.3264\n","      4        \u001b[36m2.9813\u001b[0m       \u001b[32m0.1706\u001b[0m        \u001b[35m2.9765\u001b[0m  1.2845\n","      5        \u001b[36m2.9720\u001b[0m       \u001b[32m0.3828\u001b[0m        \u001b[35m2.9652\u001b[0m  1.2416\n","      6        \u001b[36m2.9575\u001b[0m       \u001b[32m0.4222\u001b[0m        \u001b[35m2.9468\u001b[0m  1.2292\n","      7        \u001b[36m2.9328\u001b[0m       \u001b[32m0.5037\u001b[0m        \u001b[35m2.9136\u001b[0m  1.2380\n","      8        \u001b[36m2.8849\u001b[0m       0.4611        \u001b[35m2.8448\u001b[0m  1.2826\n","      9        \u001b[36m2.7769\u001b[0m       0.4011        \u001b[35m2.6809\u001b[0m  1.2571\n","     10        \u001b[36m2.5269\u001b[0m       0.3997        \u001b[35m2.3394\u001b[0m  1.2378\n","     11        \u001b[36m2.1486\u001b[0m       \u001b[32m0.6537\u001b[0m        \u001b[35m1.9614\u001b[0m  1.2532\n","     12        \u001b[36m1.7931\u001b[0m       \u001b[32m0.6823\u001b[0m        \u001b[35m1.6233\u001b[0m  1.2466\n","     13        \u001b[36m1.4620\u001b[0m       \u001b[32m0.7554\u001b[0m        \u001b[35m1.3061\u001b[0m  1.2534\n","     14        \u001b[36m1.1656\u001b[0m       \u001b[32m0.8266\u001b[0m        \u001b[35m1.0390\u001b[0m  1.2468\n","     15        \u001b[36m0.9249\u001b[0m       \u001b[32m0.8599\u001b[0m        \u001b[35m0.8281\u001b[0m  1.2381\n","     16        \u001b[36m0.7401\u001b[0m       \u001b[32m0.8852\u001b[0m        \u001b[35m0.6704\u001b[0m  1.3016\n","     17        \u001b[36m0.6033\u001b[0m       \u001b[32m0.9039\u001b[0m        \u001b[35m0.5540\u001b[0m  1.2444\n","     18        \u001b[36m0.5007\u001b[0m       \u001b[32m0.9217\u001b[0m        \u001b[35m0.4654\u001b[0m  1.2762\n","     19        \u001b[36m0.4217\u001b[0m       \u001b[32m0.9302\u001b[0m        \u001b[35m0.3972\u001b[0m  1.2518\n","     20        \u001b[36m0.3606\u001b[0m       \u001b[32m0.9410\u001b[0m        \u001b[35m0.3449\u001b[0m  1.2664\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9956\u001b[0m       \u001b[32m0.0506\u001b[0m        \u001b[35m2.9924\u001b[0m  1.2622\n","      2        \u001b[36m2.9901\u001b[0m       \u001b[32m0.0820\u001b[0m        \u001b[35m2.9865\u001b[0m  1.2484\n","      3        \u001b[36m2.9833\u001b[0m       \u001b[32m0.1429\u001b[0m        \u001b[35m2.9787\u001b[0m  1.2795\n","      4        \u001b[36m2.9740\u001b[0m       \u001b[32m0.2854\u001b[0m        \u001b[35m2.9678\u001b[0m  1.2534\n","      5        \u001b[36m2.9604\u001b[0m       \u001b[32m0.3613\u001b[0m        \u001b[35m2.9506\u001b[0m  1.2552\n","      6        \u001b[36m2.9373\u001b[0m       \u001b[32m0.4086\u001b[0m        \u001b[35m2.9198\u001b[0m  1.2590\n","      7        \u001b[36m2.8927\u001b[0m       0.3978        \u001b[35m2.8562\u001b[0m  1.3574\n","      8        \u001b[36m2.7925\u001b[0m       0.3927        \u001b[35m2.7050\u001b[0m  1.2723\n","      9        \u001b[36m2.5666\u001b[0m       0.3969        \u001b[35m2.4064\u001b[0m  1.2488\n","     10        \u001b[36m2.2381\u001b[0m       \u001b[32m0.5689\u001b[0m        \u001b[35m2.0793\u001b[0m  1.2531\n","     11        \u001b[36m1.9140\u001b[0m       \u001b[32m0.5708\u001b[0m        \u001b[35m1.7653\u001b[0m  1.2855\n","     12        \u001b[36m1.5904\u001b[0m       \u001b[32m0.6162\u001b[0m        \u001b[35m1.4505\u001b[0m  1.2647\n","     13        \u001b[36m1.2827\u001b[0m       \u001b[32m0.6668\u001b[0m        \u001b[35m1.1773\u001b[0m  1.2451\n","     14        \u001b[36m1.0344\u001b[0m       \u001b[32m0.6795\u001b[0m        \u001b[35m0.9712\u001b[0m  1.2566\n","     15        \u001b[36m0.8420\u001b[0m       \u001b[32m0.7498\u001b[0m        \u001b[35m0.8025\u001b[0m  1.2885\n","     16        \u001b[36m0.6815\u001b[0m       \u001b[32m0.8397\u001b[0m        \u001b[35m0.6547\u001b[0m  1.2446\n","     17        \u001b[36m0.5505\u001b[0m       \u001b[32m0.8730\u001b[0m        \u001b[35m0.5367\u001b[0m  1.2641\n","     18        \u001b[36m0.4544\u001b[0m       \u001b[32m0.8833\u001b[0m        \u001b[35m0.4527\u001b[0m  1.2423\n","     19        \u001b[36m0.3880\u001b[0m       \u001b[32m0.8950\u001b[0m        \u001b[35m0.3942\u001b[0m  1.3281\n","     20        \u001b[36m0.3410\u001b[0m       \u001b[32m0.9049\u001b[0m        \u001b[35m0.3510\u001b[0m  1.2468\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9964\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9924\u001b[0m  1.3437\n","      2        \u001b[36m2.9896\u001b[0m       \u001b[32m0.1664\u001b[0m        \u001b[35m2.9853\u001b[0m  1.2947\n","      3        \u001b[36m2.9815\u001b[0m       \u001b[32m0.2287\u001b[0m        \u001b[35m2.9757\u001b[0m  1.2757\n","      4        \u001b[36m2.9694\u001b[0m       \u001b[32m0.3814\u001b[0m        \u001b[35m2.9604\u001b[0m  1.2648\n","      5        \u001b[36m2.9485\u001b[0m       \u001b[32m0.4869\u001b[0m        \u001b[35m2.9317\u001b[0m  1.2556\n","      6        \u001b[36m2.9056\u001b[0m       0.3238        \u001b[35m2.8677\u001b[0m  1.2887\n","      7        \u001b[36m2.8029\u001b[0m       0.2226        \u001b[35m2.7117\u001b[0m  1.2677\n","      8        \u001b[36m2.5892\u001b[0m       0.2662        \u001b[35m2.4530\u001b[0m  1.2557\n","      9        \u001b[36m2.3360\u001b[0m       \u001b[32m0.5169\u001b[0m        \u001b[35m2.2158\u001b[0m  1.2480\n","     10        \u001b[36m2.1065\u001b[0m       \u001b[32m0.6668\u001b[0m        \u001b[35m1.9824\u001b[0m  1.2633\n","     11        \u001b[36m1.8521\u001b[0m       \u001b[32m0.6992\u001b[0m        \u001b[35m1.7065\u001b[0m  1.3095\n","     12        \u001b[36m1.5569\u001b[0m       \u001b[32m0.7399\u001b[0m        \u001b[35m1.4035\u001b[0m  1.2718\n","     13        \u001b[36m1.2599\u001b[0m       \u001b[32m0.8055\u001b[0m        \u001b[35m1.1285\u001b[0m  1.2334\n","     14        \u001b[36m1.0107\u001b[0m       \u001b[32m0.8440\u001b[0m        \u001b[35m0.9093\u001b[0m  1.2724\n","     15        \u001b[36m0.8140\u001b[0m       \u001b[32m0.8730\u001b[0m        \u001b[35m0.7352\u001b[0m  1.2476\n","     16        \u001b[36m0.6588\u001b[0m       \u001b[32m0.8908\u001b[0m        \u001b[35m0.5994\u001b[0m  1.2433\n","     17        \u001b[36m0.5407\u001b[0m       \u001b[32m0.9049\u001b[0m        \u001b[35m0.4988\u001b[0m  1.2849\n","     18        \u001b[36m0.4539\u001b[0m       \u001b[32m0.9175\u001b[0m        \u001b[35m0.4253\u001b[0m  1.2608\n","     19        \u001b[36m0.3905\u001b[0m       \u001b[32m0.9236\u001b[0m        \u001b[35m0.3714\u001b[0m  1.2540\n","     20        \u001b[36m0.3434\u001b[0m       \u001b[32m0.9297\u001b[0m        \u001b[35m0.3310\u001b[0m  1.2597\n","     21        \u001b[36m0.3076\u001b[0m       \u001b[32m0.9353\u001b[0m        \u001b[35m0.3001\u001b[0m  1.2452\n","     22        \u001b[36m0.2794\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m0.2757\u001b[0m  1.2934\n","     23        \u001b[36m0.2566\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m0.2558\u001b[0m  1.2493\n","     24        \u001b[36m0.2374\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.2390\u001b[0m  1.2646\n","     25        \u001b[36m0.2207\u001b[0m       \u001b[32m0.9522\u001b[0m        \u001b[35m0.2244\u001b[0m  1.2539\n","     26        \u001b[36m0.2060\u001b[0m       \u001b[32m0.9536\u001b[0m        \u001b[35m0.2115\u001b[0m  1.2780\n","     27        \u001b[36m0.1926\u001b[0m       \u001b[32m0.9564\u001b[0m        \u001b[35m0.1998\u001b[0m  1.2923\n","     28        \u001b[36m0.1804\u001b[0m       \u001b[32m0.9602\u001b[0m        \u001b[35m0.1893\u001b[0m  1.2584\n","     29        \u001b[36m0.1692\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1797\u001b[0m  1.2504\n","     30        \u001b[36m0.1589\u001b[0m       \u001b[32m0.9639\u001b[0m        \u001b[35m0.1712\u001b[0m  1.2707\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9973\u001b[0m       \u001b[32m0.0492\u001b[0m        \u001b[35m2.9937\u001b[0m  1.2452\n","      2        \u001b[36m2.9914\u001b[0m       0.0492        \u001b[35m2.9875\u001b[0m  1.2585\n","      3        \u001b[36m2.9846\u001b[0m       \u001b[32m0.1448\u001b[0m        \u001b[35m2.9797\u001b[0m  1.2726\n","      4        \u001b[36m2.9756\u001b[0m       \u001b[32m0.3032\u001b[0m        \u001b[35m2.9692\u001b[0m  1.2526\n","      5        \u001b[36m2.9626\u001b[0m       \u001b[32m0.4597\u001b[0m        \u001b[35m2.9532\u001b[0m  1.2903\n","      6        \u001b[36m2.9418\u001b[0m       \u001b[32m0.5267\u001b[0m        \u001b[35m2.9259\u001b[0m  1.2736\n","      7        \u001b[36m2.9043\u001b[0m       0.5037        \u001b[35m2.8748\u001b[0m  1.2618\n","      8        \u001b[36m2.8297\u001b[0m       0.4634        \u001b[35m2.7676\u001b[0m  1.2338\n","      9        \u001b[36m2.6698\u001b[0m       0.4288        \u001b[35m2.5405\u001b[0m  1.2445\n","     10        \u001b[36m2.3643\u001b[0m       0.4902        \u001b[35m2.1600\u001b[0m  1.2497\n","     11        \u001b[36m1.9493\u001b[0m       \u001b[32m0.6739\u001b[0m        \u001b[35m1.7326\u001b[0m  1.2675\n","     12        \u001b[36m1.5414\u001b[0m       \u001b[32m0.7596\u001b[0m        \u001b[35m1.3583\u001b[0m  1.2515\n","     13        \u001b[36m1.2109\u001b[0m       \u001b[32m0.8140\u001b[0m        \u001b[35m1.0805\u001b[0m  1.2448\n","     14        \u001b[36m0.9703\u001b[0m       \u001b[32m0.8496\u001b[0m        \u001b[35m0.8788\u001b[0m  1.2522\n","     15        \u001b[36m0.7879\u001b[0m       \u001b[32m0.8772\u001b[0m        \u001b[35m0.7195\u001b[0m  1.2988\n","     16        \u001b[36m0.6410\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.5901\u001b[0m  1.2458\n","     17        \u001b[36m0.5236\u001b[0m       \u001b[32m0.9058\u001b[0m        \u001b[35m0.4882\u001b[0m  1.2345\n","     18        \u001b[36m0.4336\u001b[0m       \u001b[32m0.9161\u001b[0m        \u001b[35m0.4120\u001b[0m  1.2494\n","     19        \u001b[36m0.3673\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.3566\u001b[0m  1.2419\n","     20        \u001b[36m0.3192\u001b[0m       \u001b[32m0.9297\u001b[0m        \u001b[35m0.3165\u001b[0m  1.2542\n","     21        \u001b[36m0.2841\u001b[0m       \u001b[32m0.9339\u001b[0m        \u001b[35m0.2869\u001b[0m  1.2521\n","     22        \u001b[36m0.2576\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m0.2641\u001b[0m  1.2633\n","     23        \u001b[36m0.2366\u001b[0m       \u001b[32m0.9470\u001b[0m        \u001b[35m0.2456\u001b[0m  1.3228\n","     24        \u001b[36m0.2192\u001b[0m       \u001b[32m0.9531\u001b[0m        \u001b[35m0.2300\u001b[0m  1.2599\n","     25        \u001b[36m0.2042\u001b[0m       \u001b[32m0.9550\u001b[0m        \u001b[35m0.2164\u001b[0m  1.2520\n","     26        \u001b[36m0.1908\u001b[0m       \u001b[32m0.9588\u001b[0m        \u001b[35m0.2042\u001b[0m  1.2655\n","     27        \u001b[36m0.1787\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1932\u001b[0m  1.2562\n","     28        \u001b[36m0.1676\u001b[0m       \u001b[32m0.9653\u001b[0m        \u001b[35m0.1833\u001b[0m  1.2606\n","     29        \u001b[36m0.1575\u001b[0m       \u001b[32m0.9681\u001b[0m        \u001b[35m0.1743\u001b[0m  1.2524\n","     30        \u001b[36m0.1482\u001b[0m       \u001b[32m0.9695\u001b[0m        \u001b[35m0.1663\u001b[0m  1.3012\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9970\u001b[0m       \u001b[32m0.0539\u001b[0m        \u001b[35m2.9944\u001b[0m  1.2585\n","      2        \u001b[36m2.9926\u001b[0m       \u001b[32m0.0965\u001b[0m        \u001b[35m2.9900\u001b[0m  1.2412\n","      3        \u001b[36m2.9880\u001b[0m       \u001b[32m0.1190\u001b[0m        \u001b[35m2.9849\u001b[0m  1.3032\n","      4        \u001b[36m2.9822\u001b[0m       \u001b[32m0.2798\u001b[0m        \u001b[35m2.9782\u001b[0m  1.2874\n","      5        \u001b[36m2.9743\u001b[0m       0.2666        \u001b[35m2.9688\u001b[0m  1.2617\n","      6        \u001b[36m2.9625\u001b[0m       \u001b[32m0.3051\u001b[0m        \u001b[35m2.9540\u001b[0m  1.2594\n","      7        \u001b[36m2.9430\u001b[0m       \u001b[32m0.3922\u001b[0m        \u001b[35m2.9285\u001b[0m  1.2377\n","      8        \u001b[36m2.9076\u001b[0m       \u001b[32m0.3974\u001b[0m        \u001b[35m2.8803\u001b[0m  1.2933\n","      9        \u001b[36m2.8371\u001b[0m       0.3472        \u001b[35m2.7787\u001b[0m  1.2367\n","     10        \u001b[36m2.6854\u001b[0m       0.3468        \u001b[35m2.5660\u001b[0m  1.2298\n","     11        \u001b[36m2.4082\u001b[0m       \u001b[32m0.4171\u001b[0m        \u001b[35m2.2344\u001b[0m  1.2529\n","     12        \u001b[36m2.0312\u001b[0m       \u001b[32m0.5792\u001b[0m        \u001b[35m1.8216\u001b[0m  1.2411\n","     13        \u001b[36m1.6064\u001b[0m       \u001b[32m0.6256\u001b[0m        \u001b[35m1.4315\u001b[0m  1.2322\n","     14        \u001b[36m1.2558\u001b[0m       \u001b[32m0.6776\u001b[0m        \u001b[35m1.1444\u001b[0m  1.2477\n","     15        \u001b[36m0.9924\u001b[0m       \u001b[32m0.7441\u001b[0m        \u001b[35m0.9299\u001b[0m  1.2437\n","     16        \u001b[36m0.7913\u001b[0m       \u001b[32m0.8201\u001b[0m        \u001b[35m0.7639\u001b[0m  1.2833\n","     17        \u001b[36m0.6364\u001b[0m       \u001b[32m0.8594\u001b[0m        \u001b[35m0.6306\u001b[0m  1.2509\n","     18        \u001b[36m0.5179\u001b[0m       \u001b[32m0.8885\u001b[0m        \u001b[35m0.5245\u001b[0m  1.2778\n","     19        \u001b[36m0.4286\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m0.4424\u001b[0m  1.2631\n","     20        \u001b[36m0.3620\u001b[0m       \u001b[32m0.9246\u001b[0m        \u001b[35m0.3800\u001b[0m  1.2641\n","     21        \u001b[36m0.3128\u001b[0m       \u001b[32m0.9344\u001b[0m        \u001b[35m0.3336\u001b[0m  1.2544\n","     22        \u001b[36m0.2760\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m0.2990\u001b[0m  1.2300\n","     23        \u001b[36m0.2476\u001b[0m       \u001b[32m0.9466\u001b[0m        \u001b[35m0.2724\u001b[0m  1.2329\n","     24        \u001b[36m0.2250\u001b[0m       \u001b[32m0.9503\u001b[0m        \u001b[35m0.2510\u001b[0m  1.2672\n","     25        \u001b[36m0.2061\u001b[0m       \u001b[32m0.9531\u001b[0m        \u001b[35m0.2335\u001b[0m  1.3147\n","     26        \u001b[36m0.1901\u001b[0m       \u001b[32m0.9569\u001b[0m        \u001b[35m0.2187\u001b[0m  1.2514\n","     27        \u001b[36m0.1762\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.2061\u001b[0m  1.2476\n","     28        \u001b[36m0.1641\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.1954\u001b[0m  1.3154\n","     29        \u001b[36m0.1536\u001b[0m       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1861\u001b[0m  1.2422\n","     30        \u001b[36m0.1443\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.1781\u001b[0m  1.2382\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9969\u001b[0m       \u001b[32m0.0492\u001b[0m        \u001b[35m2.9939\u001b[0m  1.3104\n","      2        \u001b[36m2.9919\u001b[0m       \u001b[32m0.0993\u001b[0m        \u001b[35m2.9887\u001b[0m  1.2234\n","      3        \u001b[36m2.9861\u001b[0m       \u001b[32m0.2127\u001b[0m        \u001b[35m2.9821\u001b[0m  1.2371\n","      4        \u001b[36m2.9785\u001b[0m       \u001b[32m0.3196\u001b[0m        \u001b[35m2.9732\u001b[0m  1.2408\n","      5        \u001b[36m2.9679\u001b[0m       \u001b[32m0.3805\u001b[0m        \u001b[35m2.9600\u001b[0m  1.2570\n","      6        \u001b[36m2.9510\u001b[0m       \u001b[32m0.3969\u001b[0m        \u001b[35m2.9383\u001b[0m  1.2445\n","      7        \u001b[36m2.9216\u001b[0m       \u001b[32m0.4236\u001b[0m        \u001b[35m2.8979\u001b[0m  1.2349\n","      8        \u001b[36m2.8624\u001b[0m       0.4180        \u001b[35m2.8115\u001b[0m  1.2445\n","      9        \u001b[36m2.7282\u001b[0m       0.3388        \u001b[35m2.6123\u001b[0m  1.3117\n","     10        \u001b[36m2.4593\u001b[0m       \u001b[32m0.4353\u001b[0m        \u001b[35m2.2824\u001b[0m  1.2629\n","     11        \u001b[36m2.1119\u001b[0m       \u001b[32m0.7259\u001b[0m        \u001b[35m1.9291\u001b[0m  1.2985\n","     12        \u001b[36m1.7714\u001b[0m       \u001b[32m0.7751\u001b[0m        \u001b[35m1.6053\u001b[0m  1.2545\n","     13        \u001b[36m1.4612\u001b[0m       \u001b[32m0.7849\u001b[0m        \u001b[35m1.3090\u001b[0m  1.2859\n","     14        \u001b[36m1.1803\u001b[0m       \u001b[32m0.8097\u001b[0m        \u001b[35m1.0536\u001b[0m  1.2698\n","     15        \u001b[36m0.9496\u001b[0m       \u001b[32m0.8482\u001b[0m        \u001b[35m0.8510\u001b[0m  1.2285\n","     16        \u001b[36m0.7668\u001b[0m       \u001b[32m0.8796\u001b[0m        \u001b[35m0.6883\u001b[0m  1.2389\n","     17        \u001b[36m0.6205\u001b[0m       \u001b[32m0.8960\u001b[0m        \u001b[35m0.5576\u001b[0m  1.2710\n","     18        \u001b[36m0.5043\u001b[0m       \u001b[32m0.9124\u001b[0m        \u001b[35m0.4561\u001b[0m  1.2379\n","     19        \u001b[36m0.4163\u001b[0m       \u001b[32m0.9288\u001b[0m        \u001b[35m0.3814\u001b[0m  1.3082\n","     20        \u001b[36m0.3524\u001b[0m       \u001b[32m0.9358\u001b[0m        \u001b[35m0.3279\u001b[0m  1.2644\n","     21        \u001b[36m0.3062\u001b[0m       \u001b[32m0.9456\u001b[0m        \u001b[35m0.2889\u001b[0m  1.2386\n","     22        \u001b[36m0.2718\u001b[0m       \u001b[32m0.9517\u001b[0m        \u001b[35m0.2597\u001b[0m  1.2522\n","     23        \u001b[36m0.2451\u001b[0m       \u001b[32m0.9555\u001b[0m        \u001b[35m0.2371\u001b[0m  1.2511\n","     24        \u001b[36m0.2236\u001b[0m       \u001b[32m0.9578\u001b[0m        \u001b[35m0.2190\u001b[0m  1.2485\n","     25        \u001b[36m0.2057\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.2039\u001b[0m  1.2810\n","     26        \u001b[36m0.1903\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1911\u001b[0m  1.2498\n","     27        \u001b[36m0.1769\u001b[0m       \u001b[32m0.9649\u001b[0m        \u001b[35m0.1800\u001b[0m  1.2583\n","     28        \u001b[36m0.1651\u001b[0m       \u001b[32m0.9681\u001b[0m        \u001b[35m0.1703\u001b[0m  1.2764\n","     29        \u001b[36m0.1546\u001b[0m       \u001b[32m0.9691\u001b[0m        \u001b[35m0.1619\u001b[0m  1.2482\n","     30        \u001b[36m0.1453\u001b[0m       \u001b[32m0.9705\u001b[0m        \u001b[35m0.1545\u001b[0m  1.2336\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9975\u001b[0m       \u001b[32m0.0506\u001b[0m        \u001b[35m2.9940\u001b[0m  1.2501\n","      2        \u001b[36m2.9922\u001b[0m       \u001b[32m0.0998\u001b[0m        \u001b[35m2.9886\u001b[0m  1.2924\n","      3        \u001b[36m2.9861\u001b[0m       \u001b[32m0.1485\u001b[0m        \u001b[35m2.9817\u001b[0m  1.2575\n","      4        \u001b[36m2.9781\u001b[0m       \u001b[32m0.2338\u001b[0m        \u001b[35m2.9723\u001b[0m  1.2860\n","      5        \u001b[36m2.9667\u001b[0m       \u001b[32m0.3397\u001b[0m        \u001b[35m2.9582\u001b[0m  1.2673\n","      6        \u001b[36m2.9486\u001b[0m       \u001b[32m0.4016\u001b[0m        \u001b[35m2.9350\u001b[0m  1.3447\n","      7        \u001b[36m2.9173\u001b[0m       0.3913        \u001b[35m2.8923\u001b[0m  1.3078\n","      8        \u001b[36m2.8550\u001b[0m       0.3885        \u001b[35m2.8025\u001b[0m  1.2535\n","      9        \u001b[36m2.7184\u001b[0m       \u001b[32m0.4208\u001b[0m        \u001b[35m2.6036\u001b[0m  1.2652\n","     10        \u001b[36m2.4461\u001b[0m       0.3852        \u001b[35m2.2609\u001b[0m  1.3206\n","     11        \u001b[36m2.0723\u001b[0m       \u001b[32m0.5722\u001b[0m        \u001b[35m1.8746\u001b[0m  1.2514\n","     12        \u001b[36m1.7134\u001b[0m       \u001b[32m0.6645\u001b[0m        \u001b[35m1.5530\u001b[0m  1.2742\n","     13        \u001b[36m1.4222\u001b[0m       \u001b[32m0.6874\u001b[0m        \u001b[35m1.2909\u001b[0m  1.2971\n","     14        \u001b[36m1.1760\u001b[0m       \u001b[32m0.7221\u001b[0m        \u001b[35m1.0708\u001b[0m  1.2674\n","     15        \u001b[36m0.9716\u001b[0m       \u001b[32m0.7760\u001b[0m        \u001b[35m0.8933\u001b[0m  1.2576\n","     16        \u001b[36m0.8054\u001b[0m       \u001b[32m0.8187\u001b[0m        \u001b[35m0.7454\u001b[0m  1.2467\n","     17        \u001b[36m0.6646\u001b[0m       \u001b[32m0.8683\u001b[0m        \u001b[35m0.6175\u001b[0m  1.2421\n","     18        \u001b[36m0.5449\u001b[0m       \u001b[32m0.9002\u001b[0m        \u001b[35m0.5094\u001b[0m  1.3062\n","     19        \u001b[36m0.4465\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.4221\u001b[0m  1.2592\n","     20        \u001b[36m0.3698\u001b[0m       \u001b[32m0.9377\u001b[0m        \u001b[35m0.3568\u001b[0m  1.2591\n","     21        \u001b[36m0.3138\u001b[0m       \u001b[32m0.9452\u001b[0m        \u001b[35m0.3110\u001b[0m  1.2439\n","     22        \u001b[36m0.2740\u001b[0m       \u001b[32m0.9489\u001b[0m        \u001b[35m0.2787\u001b[0m  1.2518\n","     23        \u001b[36m0.2452\u001b[0m       \u001b[32m0.9541\u001b[0m        \u001b[35m0.2547\u001b[0m  1.2546\n","     24        \u001b[36m0.2231\u001b[0m       \u001b[32m0.9560\u001b[0m        \u001b[35m0.2360\u001b[0m  1.2541\n","     25        \u001b[36m0.2054\u001b[0m       \u001b[32m0.9583\u001b[0m        \u001b[35m0.2206\u001b[0m  1.2460\n","     26        \u001b[36m0.1905\u001b[0m       \u001b[32m0.9611\u001b[0m        \u001b[35m0.2075\u001b[0m  1.3051\n","     27        \u001b[36m0.1776\u001b[0m       \u001b[32m0.9634\u001b[0m        \u001b[35m0.1961\u001b[0m  1.2507\n","     28        \u001b[36m0.1661\u001b[0m       \u001b[32m0.9672\u001b[0m        \u001b[35m0.1861\u001b[0m  1.2782\n","     29        \u001b[36m0.1559\u001b[0m       \u001b[32m0.9686\u001b[0m        \u001b[35m0.1772\u001b[0m  1.2720\n","     30        \u001b[36m0.1468\u001b[0m       \u001b[32m0.9700\u001b[0m        \u001b[35m0.1693\u001b[0m  1.2712\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9976\u001b[0m       \u001b[32m0.0820\u001b[0m        \u001b[35m2.9947\u001b[0m  1.2486\n","      2        \u001b[36m2.9929\u001b[0m       \u001b[32m0.1261\u001b[0m        \u001b[35m2.9902\u001b[0m  1.2491\n","      3        \u001b[36m2.9883\u001b[0m       \u001b[32m0.1462\u001b[0m        \u001b[35m2.9853\u001b[0m  1.2795\n","      4        \u001b[36m2.9826\u001b[0m       \u001b[32m0.1537\u001b[0m        \u001b[35m2.9786\u001b[0m  1.2984\n","      5        \u001b[36m2.9744\u001b[0m       \u001b[32m0.2441\u001b[0m        \u001b[35m2.9687\u001b[0m  1.2696\n","      6        \u001b[36m2.9618\u001b[0m       \u001b[32m0.2887\u001b[0m        \u001b[35m2.9527\u001b[0m  1.2674\n","      7        \u001b[36m2.9402\u001b[0m       \u001b[32m0.3163\u001b[0m        \u001b[35m2.9238\u001b[0m  1.2943\n","      8        \u001b[36m2.8985\u001b[0m       0.2676        \u001b[35m2.8646\u001b[0m  1.2833\n","      9        \u001b[36m2.8061\u001b[0m       0.2493        \u001b[35m2.7263\u001b[0m  1.2706\n","     10        \u001b[36m2.5976\u001b[0m       0.2605        \u001b[35m2.4442\u001b[0m  1.2250\n","     11        \u001b[36m2.2758\u001b[0m       \u001b[32m0.3749\u001b[0m        \u001b[35m2.1176\u001b[0m  1.3458\n","     12        \u001b[36m1.9751\u001b[0m       \u001b[32m0.5042\u001b[0m        \u001b[35m1.8538\u001b[0m  1.2515\n","     13        \u001b[36m1.7306\u001b[0m       \u001b[32m0.5267\u001b[0m        \u001b[35m1.6327\u001b[0m  1.2472\n","     14        \u001b[36m1.5078\u001b[0m       \u001b[32m0.5614\u001b[0m        \u001b[35m1.4142\u001b[0m  1.2409\n","     15        \u001b[36m1.2791\u001b[0m       \u001b[32m0.6232\u001b[0m        \u001b[35m1.1935\u001b[0m  1.2641\n","     16        \u001b[36m1.0632\u001b[0m       \u001b[32m0.6860\u001b[0m        \u001b[35m1.0008\u001b[0m  1.2412\n","     17        \u001b[36m0.8793\u001b[0m       \u001b[32m0.7498\u001b[0m        \u001b[35m0.8363\u001b[0m  1.2531\n","     18        \u001b[36m0.7214\u001b[0m       \u001b[32m0.8196\u001b[0m        \u001b[35m0.6893\u001b[0m  1.2421\n","     19        \u001b[36m0.5849\u001b[0m       \u001b[32m0.8749\u001b[0m        \u001b[35m0.5605\u001b[0m  1.2746\n","     20        \u001b[36m0.4722\u001b[0m       \u001b[32m0.9082\u001b[0m        \u001b[35m0.4558\u001b[0m  1.2709\n","     21        \u001b[36m0.3862\u001b[0m       \u001b[32m0.9246\u001b[0m        \u001b[35m0.3786\u001b[0m  1.2653\n","     22        \u001b[36m0.3254\u001b[0m       \u001b[32m0.9339\u001b[0m        \u001b[35m0.3255\u001b[0m  1.2543\n","     23        \u001b[36m0.2837\u001b[0m       \u001b[32m0.9438\u001b[0m        \u001b[35m0.2890\u001b[0m  1.2516\n","     24        \u001b[36m0.2542\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.2629\u001b[0m  1.2604\n","     25        \u001b[36m0.2323\u001b[0m       \u001b[32m0.9517\u001b[0m        \u001b[35m0.2431\u001b[0m  1.2557\n","     26        \u001b[36m0.2148\u001b[0m       \u001b[32m0.9541\u001b[0m        \u001b[35m0.2272\u001b[0m  1.2455\n","     27        \u001b[36m0.2003\u001b[0m       \u001b[32m0.9550\u001b[0m        \u001b[35m0.2138\u001b[0m  1.2667\n","     28        \u001b[36m0.1875\u001b[0m       \u001b[32m0.9616\u001b[0m        \u001b[35m0.2022\u001b[0m  1.3134\n","     29        \u001b[36m0.1761\u001b[0m       \u001b[32m0.9634\u001b[0m        \u001b[35m0.1918\u001b[0m  1.2324\n","     30        \u001b[36m0.1656\u001b[0m       \u001b[32m0.9653\u001b[0m        \u001b[35m0.1825\u001b[0m  1.2367\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9963\u001b[0m       \u001b[32m0.0506\u001b[0m        \u001b[35m2.9931\u001b[0m  1.2926\n","      2        \u001b[36m2.9912\u001b[0m       0.0506        \u001b[35m2.9880\u001b[0m  1.3048\n","      3        \u001b[36m2.9857\u001b[0m       \u001b[32m0.1143\u001b[0m        \u001b[35m2.9818\u001b[0m  1.2451\n","      4        \u001b[36m2.9785\u001b[0m       \u001b[32m0.3205\u001b[0m        \u001b[35m2.9731\u001b[0m  1.3051\n","      5        \u001b[36m2.9679\u001b[0m       \u001b[32m0.5530\u001b[0m        \u001b[35m2.9601\u001b[0m  1.2339\n","      6        \u001b[36m2.9512\u001b[0m       \u001b[32m0.6884\u001b[0m        \u001b[35m2.9383\u001b[0m  1.2388\n","      7        \u001b[36m2.9215\u001b[0m       \u001b[32m0.6992\u001b[0m        \u001b[35m2.8977\u001b[0m  1.2481\n","      8        \u001b[36m2.8624\u001b[0m       0.5637        \u001b[35m2.8119\u001b[0m  1.2268\n","      9        \u001b[36m2.7304\u001b[0m       0.4888        \u001b[35m2.6156\u001b[0m  1.2443\n","     10        \u001b[36m2.4564\u001b[0m       0.4920        \u001b[35m2.2638\u001b[0m  1.2357\n","     11        \u001b[36m2.0718\u001b[0m       0.6350        \u001b[35m1.8717\u001b[0m  1.2524\n","     12        \u001b[36m1.7103\u001b[0m       \u001b[32m0.7568\u001b[0m        \u001b[35m1.5475\u001b[0m  1.2748\n","     13        \u001b[36m1.4092\u001b[0m       \u001b[32m0.7863\u001b[0m        \u001b[35m1.2682\u001b[0m  1.2418\n","     14        \u001b[36m1.1469\u001b[0m       \u001b[32m0.8102\u001b[0m        \u001b[35m1.0280\u001b[0m  1.2536\n","     15        \u001b[36m0.9232\u001b[0m       \u001b[32m0.8505\u001b[0m        \u001b[35m0.8235\u001b[0m  1.2502\n","     16        \u001b[36m0.7343\u001b[0m       \u001b[32m0.8908\u001b[0m        \u001b[35m0.6533\u001b[0m  1.2637\n","     17        \u001b[36m0.5829\u001b[0m       \u001b[32m0.9124\u001b[0m        \u001b[35m0.5210\u001b[0m  1.2339\n","     18        \u001b[36m0.4692\u001b[0m       \u001b[32m0.9278\u001b[0m        \u001b[35m0.4237\u001b[0m  1.2543\n","     19        \u001b[36m0.3869\u001b[0m       \u001b[32m0.9363\u001b[0m        \u001b[35m0.3543\u001b[0m  1.2675\n","     20        \u001b[36m0.3284\u001b[0m       \u001b[32m0.9466\u001b[0m        \u001b[35m0.3056\u001b[0m  1.2669\n","     21        \u001b[36m0.2867\u001b[0m       \u001b[32m0.9513\u001b[0m        \u001b[35m0.2711\u001b[0m  1.2512\n","     22        \u001b[36m0.2563\u001b[0m       \u001b[32m0.9531\u001b[0m        \u001b[35m0.2459\u001b[0m  1.2509\n","     23        \u001b[36m0.2330\u001b[0m       \u001b[32m0.9560\u001b[0m        \u001b[35m0.2266\u001b[0m  1.2557\n","     24        \u001b[36m0.2143\u001b[0m       \u001b[32m0.9602\u001b[0m        \u001b[35m0.2110\u001b[0m  1.2606\n","     25        \u001b[36m0.1987\u001b[0m       \u001b[32m0.9639\u001b[0m        \u001b[35m0.1979\u001b[0m  1.2453\n","     26        \u001b[36m0.1851\u001b[0m       \u001b[32m0.9686\u001b[0m        \u001b[35m0.1866\u001b[0m  1.2606\n","     27        \u001b[36m0.1730\u001b[0m       \u001b[32m0.9695\u001b[0m        \u001b[35m0.1767\u001b[0m  1.3413\n","     28        \u001b[36m0.1623\u001b[0m       \u001b[32m0.9705\u001b[0m        \u001b[35m0.1680\u001b[0m  1.3198\n","     29        \u001b[36m0.1526\u001b[0m       \u001b[32m0.9714\u001b[0m        \u001b[35m0.1604\u001b[0m  1.2498\n","     30        \u001b[36m0.1439\u001b[0m       \u001b[32m0.9724\u001b[0m        \u001b[35m0.1537\u001b[0m  1.2727\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9971\u001b[0m       \u001b[32m0.0511\u001b[0m        \u001b[35m2.9942\u001b[0m  1.2852\n","      2        \u001b[36m2.9928\u001b[0m       \u001b[32m0.0961\u001b[0m        \u001b[35m2.9898\u001b[0m  1.2563\n","      3        \u001b[36m2.9878\u001b[0m       \u001b[32m0.1275\u001b[0m        \u001b[35m2.9840\u001b[0m  1.2706\n","      4        \u001b[36m2.9810\u001b[0m       \u001b[32m0.3247\u001b[0m        \u001b[35m2.9760\u001b[0m  1.2584\n","      5        \u001b[36m2.9713\u001b[0m       \u001b[32m0.4850\u001b[0m        \u001b[35m2.9641\u001b[0m  1.2825\n","      6        \u001b[36m2.9563\u001b[0m       \u001b[32m0.6682\u001b[0m        \u001b[35m2.9450\u001b[0m  1.2571\n","      7        \u001b[36m2.9309\u001b[0m       0.6078        \u001b[35m2.9112\u001b[0m  1.2593\n","      8        \u001b[36m2.8824\u001b[0m       0.4864        \u001b[35m2.8419\u001b[0m  1.2505\n","      9        \u001b[36m2.7746\u001b[0m       0.4719        \u001b[35m2.6801\u001b[0m  1.2611\n","     10        \u001b[36m2.5378\u001b[0m       0.4724        \u001b[35m2.3697\u001b[0m  1.2474\n","     11        \u001b[36m2.1993\u001b[0m       0.6228        \u001b[35m2.0245\u001b[0m  1.2413\n","     12        \u001b[36m1.8682\u001b[0m       \u001b[32m0.6851\u001b[0m        \u001b[35m1.7112\u001b[0m  1.2424\n","     13        \u001b[36m1.5717\u001b[0m       \u001b[32m0.7137\u001b[0m        \u001b[35m1.4293\u001b[0m  1.2973\n","     14        \u001b[36m1.2944\u001b[0m       \u001b[32m0.7465\u001b[0m        \u001b[35m1.1598\u001b[0m  1.2361\n","     15        \u001b[36m1.0360\u001b[0m       \u001b[32m0.8027\u001b[0m        \u001b[35m0.9264\u001b[0m  1.2580\n","     16        \u001b[36m0.8279\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.7500\u001b[0m  1.2420\n","     17        \u001b[36m0.6720\u001b[0m       \u001b[32m0.8819\u001b[0m        \u001b[35m0.6178\u001b[0m  1.2684\n","     18        \u001b[36m0.5526\u001b[0m       \u001b[32m0.9030\u001b[0m        \u001b[35m0.5148\u001b[0m  1.2591\n","     19        \u001b[36m0.4586\u001b[0m       \u001b[32m0.9203\u001b[0m        \u001b[35m0.4331\u001b[0m  1.2593\n","     20        \u001b[36m0.3849\u001b[0m       \u001b[32m0.9311\u001b[0m        \u001b[35m0.3702\u001b[0m  1.2505\n","     21        \u001b[36m0.3291\u001b[0m       \u001b[32m0.9377\u001b[0m        \u001b[35m0.3237\u001b[0m  1.3947\n","     22        \u001b[36m0.2879\u001b[0m       \u001b[32m0.9442\u001b[0m        \u001b[35m0.2895\u001b[0m  1.2987\n","     23        \u001b[36m0.2573\u001b[0m       \u001b[32m0.9499\u001b[0m        \u001b[35m0.2639\u001b[0m  1.2660\n","     24        \u001b[36m0.2338\u001b[0m       \u001b[32m0.9564\u001b[0m        \u001b[35m0.2439\u001b[0m  1.2454\n","     25        \u001b[36m0.2151\u001b[0m       \u001b[32m0.9583\u001b[0m        \u001b[35m0.2277\u001b[0m  1.2536\n","     26        \u001b[36m0.1995\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.2141\u001b[0m  1.2616\n","     27        \u001b[36m0.1861\u001b[0m       \u001b[32m0.9658\u001b[0m        \u001b[35m0.2022\u001b[0m  1.2755\n","     28        \u001b[36m0.1743\u001b[0m       \u001b[32m0.9672\u001b[0m        \u001b[35m0.1918\u001b[0m  1.2525\n","     29        \u001b[36m0.1636\u001b[0m       \u001b[32m0.9691\u001b[0m        \u001b[35m0.1825\u001b[0m  1.3080\n","     30        \u001b[36m0.1540\u001b[0m       \u001b[32m0.9700\u001b[0m        \u001b[35m0.1741\u001b[0m  1.4912\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9968\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9945\u001b[0m  1.2703\n","      2        \u001b[36m2.9932\u001b[0m       \u001b[32m0.0539\u001b[0m        \u001b[35m2.9908\u001b[0m  1.2396\n","      3        \u001b[36m2.9892\u001b[0m       \u001b[32m0.1195\u001b[0m        \u001b[35m2.9864\u001b[0m  1.2526\n","      4        \u001b[36m2.9842\u001b[0m       \u001b[32m0.1949\u001b[0m        \u001b[35m2.9808\u001b[0m  1.2539\n","      5        \u001b[36m2.9774\u001b[0m       \u001b[32m0.3022\u001b[0m        \u001b[35m2.9728\u001b[0m  1.2418\n","      6        \u001b[36m2.9673\u001b[0m       \u001b[32m0.3819\u001b[0m        \u001b[35m2.9600\u001b[0m  1.3032\n","      7        \u001b[36m2.9502\u001b[0m       \u001b[32m0.4213\u001b[0m        \u001b[35m2.9374\u001b[0m  1.2780\n","      8        \u001b[36m2.9188\u001b[0m       0.4002        \u001b[35m2.8950\u001b[0m  1.2610\n","      9        \u001b[36m2.8555\u001b[0m       \u001b[32m0.4231\u001b[0m        \u001b[35m2.8030\u001b[0m  1.2478\n","     10        \u001b[36m2.7104\u001b[0m       \u001b[32m0.4545\u001b[0m        \u001b[35m2.5896\u001b[0m  1.2487\n","     11        \u001b[36m2.4228\u001b[0m       \u001b[32m0.4873\u001b[0m        \u001b[35m2.2505\u001b[0m  1.2401\n","     12        \u001b[36m2.0809\u001b[0m       \u001b[32m0.5600\u001b[0m        \u001b[35m1.9274\u001b[0m  1.3283\n","     13        \u001b[36m1.7587\u001b[0m       \u001b[32m0.5979\u001b[0m        \u001b[35m1.6134\u001b[0m  1.2212\n","     14        \u001b[36m1.4387\u001b[0m       \u001b[32m0.6589\u001b[0m        \u001b[35m1.3133\u001b[0m  1.2940\n","     15        \u001b[36m1.1524\u001b[0m       \u001b[32m0.7277\u001b[0m        \u001b[35m1.0644\u001b[0m  1.3255\n","     16        \u001b[36m0.9159\u001b[0m       \u001b[32m0.7634\u001b[0m        \u001b[35m0.8603\u001b[0m  1.2337\n","     17        \u001b[36m0.7242\u001b[0m       \u001b[32m0.7882\u001b[0m        \u001b[35m0.6937\u001b[0m  1.2364\n","     18        \u001b[36m0.5752\u001b[0m       \u001b[32m0.8177\u001b[0m        \u001b[35m0.5626\u001b[0m  1.2536\n","     19        \u001b[36m0.4663\u001b[0m       \u001b[32m0.8683\u001b[0m        \u001b[35m0.4651\u001b[0m  1.2471\n","     20        \u001b[36m0.3891\u001b[0m       \u001b[32m0.9105\u001b[0m        \u001b[35m0.3940\u001b[0m  1.2537\n","     21        \u001b[36m0.3338\u001b[0m       \u001b[32m0.9311\u001b[0m        \u001b[35m0.3419\u001b[0m  1.2304\n","     22        \u001b[36m0.2934\u001b[0m       \u001b[32m0.9400\u001b[0m        \u001b[35m0.3038\u001b[0m  1.2750\n","     23        \u001b[36m0.2633\u001b[0m       \u001b[32m0.9475\u001b[0m        \u001b[35m0.2757\u001b[0m  1.2463\n","     24        \u001b[36m0.2403\u001b[0m       \u001b[32m0.9503\u001b[0m        \u001b[35m0.2543\u001b[0m  1.2393\n","     25        \u001b[36m0.2222\u001b[0m       \u001b[32m0.9522\u001b[0m        \u001b[35m0.2375\u001b[0m  1.2478\n","     26        \u001b[36m0.2075\u001b[0m       \u001b[32m0.9536\u001b[0m        \u001b[35m0.2237\u001b[0m  1.2465\n","     27        \u001b[36m0.1949\u001b[0m       \u001b[32m0.9550\u001b[0m        \u001b[35m0.2121\u001b[0m  1.2364\n","     28        \u001b[36m0.1839\u001b[0m       \u001b[32m0.9574\u001b[0m        \u001b[35m0.2020\u001b[0m  1.2547\n","     29        \u001b[36m0.1739\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.1930\u001b[0m  1.2660\n","     30        \u001b[36m0.1648\u001b[0m       \u001b[32m0.9611\u001b[0m        \u001b[35m0.1848\u001b[0m  1.2770\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9967\u001b[0m       \u001b[32m0.1078\u001b[0m        \u001b[35m2.9924\u001b[0m  1.8857\n","      2        \u001b[36m2.9892\u001b[0m       0.1003        \u001b[35m2.9844\u001b[0m  1.8786\n","      3        \u001b[36m2.9791\u001b[0m       \u001b[32m0.1181\u001b[0m        \u001b[35m2.9713\u001b[0m  1.8768\n","      4        \u001b[36m2.9595\u001b[0m       \u001b[32m0.1837\u001b[0m        \u001b[35m2.9419\u001b[0m  1.8778\n","      5        \u001b[36m2.9062\u001b[0m       \u001b[32m0.2687\u001b[0m        \u001b[35m2.8485\u001b[0m  1.9308\n","      6        \u001b[36m2.7214\u001b[0m       0.1878        \u001b[35m2.5480\u001b[0m  1.9158\n","      7        \u001b[36m2.3740\u001b[0m       \u001b[32m0.4878\u001b[0m        \u001b[35m2.2140\u001b[0m  1.8687\n","      8        \u001b[36m2.0596\u001b[0m       \u001b[32m0.7006\u001b[0m        \u001b[35m1.8826\u001b[0m  1.8591\n","      9        \u001b[36m1.6844\u001b[0m       \u001b[32m0.7272\u001b[0m        \u001b[35m1.4709\u001b[0m  1.9009\n","     10        \u001b[36m1.2718\u001b[0m       \u001b[32m0.8031\u001b[0m        \u001b[35m1.0794\u001b[0m  1.9069\n","     11        \u001b[36m0.9283\u001b[0m       \u001b[32m0.8750\u001b[0m        \u001b[35m0.7883\u001b[0m  1.8728\n","     12        \u001b[36m0.6746\u001b[0m       \u001b[32m0.9028\u001b[0m        \u001b[35m0.5722\u001b[0m  1.8515\n","     13        \u001b[36m0.4960\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.4306\u001b[0m  1.8748\n","     14        \u001b[36m0.3835\u001b[0m       \u001b[32m0.9403\u001b[0m        \u001b[35m0.3434\u001b[0m  1.8537\n","     15        \u001b[36m0.3129\u001b[0m       \u001b[32m0.9466\u001b[0m        \u001b[35m0.2880\u001b[0m  1.8892\n","     16        \u001b[36m0.2662\u001b[0m       \u001b[32m0.9534\u001b[0m        \u001b[35m0.2504\u001b[0m  1.8494\n","     17        \u001b[36m0.2331\u001b[0m       \u001b[32m0.9591\u001b[0m        \u001b[35m0.2232\u001b[0m  1.8775\n","     18        \u001b[36m0.2082\u001b[0m       \u001b[32m0.9656\u001b[0m        \u001b[35m0.2025\u001b[0m  1.8994\n","     19        \u001b[36m0.1884\u001b[0m       \u001b[32m0.9675\u001b[0m        \u001b[35m0.1860\u001b[0m  1.8836\n","     20        \u001b[36m0.1722\u001b[0m       \u001b[32m0.9712\u001b[0m        \u001b[35m0.1727\u001b[0m  1.8410\n","     21        \u001b[36m0.1587\u001b[0m       \u001b[32m0.9741\u001b[0m        \u001b[35m0.1619\u001b[0m  1.9153\n","     22        \u001b[36m0.1473\u001b[0m       \u001b[32m0.9747\u001b[0m        \u001b[35m0.1528\u001b[0m  1.8494\n","     23        \u001b[36m0.1376\u001b[0m       \u001b[32m0.9756\u001b[0m        \u001b[35m0.1453\u001b[0m  1.9342\n","     24        \u001b[36m0.1292\u001b[0m       \u001b[32m0.9766\u001b[0m        \u001b[35m0.1390\u001b[0m  1.8461\n","     25        \u001b[36m0.1218\u001b[0m       \u001b[32m0.9772\u001b[0m        \u001b[35m0.1337\u001b[0m  1.8436\n","     26        \u001b[36m0.1154\u001b[0m       \u001b[32m0.9781\u001b[0m        \u001b[35m0.1290\u001b[0m  1.9090\n","     27        \u001b[36m0.1096\u001b[0m       0.9781        \u001b[35m0.1251\u001b[0m  1.8911\n","     28        \u001b[36m0.1044\u001b[0m       \u001b[32m0.9788\u001b[0m        \u001b[35m0.1216\u001b[0m  1.8969\n","     29        \u001b[36m0.0997\u001b[0m       \u001b[32m0.9794\u001b[0m        \u001b[35m0.1185\u001b[0m  1.8350\n","     30        \u001b[36m0.0954\u001b[0m       0.9794        \u001b[35m0.1158\u001b[0m  1.8432\n","Best parameters: {'callbacks': [('EarlyStopping', <skorch.callbacks.training.EarlyStopping object at 0x7d114307a5c0>)], 'lr': 0.1, 'max_epochs': 30, 'module__input_size': 5000, 'module__nonlin': <function relu at 0x7d1176732cb0>, 'module__num_units': 200}\n","Best score: 0.9677499294399562\n"]}],"source":["# Create GridSearchCV object\n","gs = GridSearchCV(net_tfidf_gs, param_grid, refit=True, cv=3, scoring='accuracy')\n","\n","# Fit the GridSearchCV object\n","gs.fit(X_tfidf, y_tfidf)\n","\n","# Print the best parameters and score\n","print(\"Best parameters:\", gs.best_params_)\n","print(\"Best score:\", gs.best_score_)\n","\n","# You can now use the best estimator to make predictions\n","best_model = gs.best_estimator_"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T08:50:41.422656Z","iopub.status.busy":"2024-10-09T08:50:41.421487Z","iopub.status.idle":"2024-10-09T08:50:41.953042Z","shell.execute_reply":"2024-10-09T08:50:41.952003Z","shell.execute_reply.started":"2024-10-09T08:50:41.422607Z"},"id":"fH_fhHu82Fxh","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy with Best Model: 0.97175\n"]}],"source":["# Predict and get accuracy using best model\n","\n","y_pred_best = best_model.predict(X_test_tfidf)\n","test_accuracy_best = np.mean(y_pred_best == y_test_np)\n","print(f\"Test Accuracy with Best Model: {test_accuracy_best}\")"]},{"cell_type":"markdown","metadata":{"id":"cviv9PS-NSCq"},"source":["Note, you can also use `GridSearchCV` with `skorch`, but be aware that training a neural network takes much more time.\n","\n","Play around with 5 different sets of hyperparameters. For example, consider some of the following:\n","\n","- layer sizes\n","- activation functions\n","- regularizers\n","- early stopping\n","- vectorizer parameters\n","\n","Report your best hyperparameter combination. \\\\\n","📝❓ What is the effect of your modifcations on validation performance? Discuss potential reasons."]},{"cell_type":"markdown","metadata":{},"source":["### Best Parameters: \n","* Learning Rate: 0.1\n","* Max Epochs: 30\n","* Module Input Size: 5000\n","* Activation: ReLU\n","* Number of Units: 200\n","\n","### The effect of hyperparametrs is significant on the training. Some of the observations are as follows:\n","* Changing learning rate from 0.01 to 0.1 results in a massive improvement in the validation accuracy. This is seen when the validation accuracy improves from ~30% to nearly 97.1%. This may be because increasing the learning rate resulted in \"escaping\" the local minima and converge faster.\n","* Having more units in a layer does not necessarily mean a better accuracy. When the number of units increased from 200 to 300, the accuracy dropped instead of increasing. However, it increased when the number was changed from 100 to 200. This probably implies that 200 units provide sufficient complexity for the model to perform at its best and 300 just leads to overfitting. \n","* ReLU outperforms the other activation functions like tanh (not shown on grid search but tested independently). This may be because ReLU does not suffer from the vanishing gradient problem. \n","* Increasing max_features for the vectorizer (from 100 to 5000) leads to noticeable increase in accuracy from ~75% to ~97%. More features allowed our models to pick up on even more patterns in the text to make accurate predictions. \n","* Early stopping did not kick in at any point during the training. This means that the model accuracy kept changing throughout the training. This suggests that we can benefit from even more epochs or improving our stopping criteria.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FbxuaEDPrZSu"},"source":["☝ Note, during model development, if you run into the infamous CUDA out-of-memory (OOM) error, try clearing the GPU memory either with `torch.cuda.empty_cache()` or restarting the runtime."]},{"cell_type":"markdown","metadata":{"id":"Lr48VZEGcXAb"},"source":["\n","---\n","\n","📝❓ Write your lab report here addressing all questions in the notebook"]},{"cell_type":"markdown","metadata":{"id":"QFJ8eObYcyss"},"source":["# Lab Report\n","\n","## Introduction\n","\n","In this lab, we explored the use of neural networks for language classification using the `skorch` library. We experimented with different vectorizers and hyperparameters to improve the model's performance. The dataset consisted of text data in various languages, and the goal was to classify the text into one of the 20 languages.\n","\n","## Data Preparation\n","\n","We started by preparing the dataset, which involved:\n","- Downloading the dataset.\n","- Combining the training and testing data into dataframes.\n","- Filtering the data to include only the 20 selected languages.\n","- Splitting the data into training and testing sets.\n","- Reorganising the training and test datasets to 80:20 split.\n","- Encoding the labels using `LabelEncoder`.\n","\n","## Feature Extraction\n","\n","We experimented with different feature extraction techniques:\n","- **Count Vectorizer**: Extracted character-level bigrams with a maximum of 100 and 5000 features.\n","- **TF-IDF Vectorizer**: Extracted character-level n-grams (2 to 4) with a maximum of 5000 features.\n","\n","## Neural Network Architecture\n","\n","We did not try to improve the vanilla neural network provided in the code template (other than altering the number of units in the hidden layer). This showed how a simple MLP is capable of outperforming ML techniques introduced in part 1 of the assignment. \n","\n","## Experiments and Results\n","\n","### Initial Experiments\n","\n","1. **Count Vectorizer with 100 Features**:\n","    - Achieved a test accuracy of ~75%.\n","\n","2. **Count Vectorizer with 5000 Features**:\n","    - Improved test accuracy to ~98%.\n","\n","3. **TF-IDF Vectorizer**:\n","    - Achieved a test accuracy of ~97%.\n","\n","### Why choose `TF-IDF Vectoizer` over `Count Vectorizer` for our grid search?\n","- For our language classification task, the Count Vectorizer showed a slightly higher accuracy (98%) compared to TF-IDF (97%). This aligns with expectations for language identification, where the mere presence and frequency of specific character patterns or words are often more indicative of the language than their relative importance across documents.\n","- Although the Count Vectorizer showed marginally better performance, we decided to explore TF-IDF in our grid search to thoroughly investigate its potential benefits. This decision was made to ensure we weren't overlooking any advantages TF-IDF might offer in capturing subtle language distinctions, especially for languages with similar character distributions.\n","\n","### Hyperparameter Tuning\n","\n","We used `GridSearchCV` to find the best hyperparameters. The best parameters were:\n","- Learning Rate: 0.1\n","- Max Epochs: 30\n","- Module Input Size: 5000\n","- Activation: ReLU\n","- Number of Units: 200\n","\n","The best model achieved a test accuracy of ~97.1%.\n","\n","### Observations Summary\n","\n","- **Learning Rate**: Increasing the learning rate from 0.01 to 0.1 resulted in a significant improvement in validation accuracy.\n","- **Number of Units**: 200 units provided the best performance, while increasing to 300 units led to overfitting.\n","- **Activation Function**: ReLU outperformed other activation functions like tanh.\n","- **Vectorizer Features**: Increasing the maximum features for the vectorizer from 100 to 5000 led to a noticeable increase in accuracy.\n","- **Early Stopping**: Did not kick in, suggesting that more epochs or improved stopping criteria could be beneficial.\n","\n","## Conclusion\n","\n","The experiments demonstrated the importance of hyperparameter tuning and feature extraction in improving the performance of neural networks for language classification. The best model achieved a test accuracy of ~97.1%, highlighting the effectiveness of the chosen hyperparameters and vectorizer settings.\n","\n","---\n","\n","## Questions\n","\n","### What is the effect of your modifications on validation performance? Discuss potential reasons.\n","\n","* Changing learning rate from 0.01 to 0.1 results in a massive improvement in the validation accuracy. This is seen when the validation accuracy improves from ~30% to nearly 97.1%. This may be because increasing the learning rate resulted in \"escaping\" the local minima and converge faster.\n","* Having more units in a layer does not necessarily mean a better accuracy. When the number of units increased from 200 to 300, the accuracy dropped instead of increasing. However, it increased when the number was changed from 100 to 200. This probably implies that 200 units provide sufficient complexity for the model to perform at its best and 300 just leads to overfitting. \n","* ReLU outperforms the other activation functions like tanh (not shown on grid search but tested independently). This may be because ReLU does not suffer from the vanishing gradient problem. \n","* Increasing max_features for the vectorizer (from 100 to 5000) leads to noticeable increase in accuracy from ~75% to ~97%. More features allowed our models to pick up on even more patterns in the text to make accurate predictions. \n","* Early stopping did not kick in at any point during the training. This means that the model accuracy kept changing throughout the training. This suggests that we can benefit from even more epochs or improving our stopping criteria."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"vscode":{"interpreter":{"hash":"bd97b8bffa4d3737e84826bc3d37be3046061822757ce35137ab82ad4c5a2016"}}},"nbformat":4,"nbformat_minor":4}
