{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/Andrian0s/ML4NLP1-2024-Tutorial-Notebooks/blob/main/exercises/ex1/ex1_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"Q-2GcUhgB0S7"},"source":["# ML4NLP1\n","\n","## Starting Point for Exercise 1, part II\n","\n","\n","\n","This notebook is supposed to serve as a starting point and/or inspiration when starting exercise 1, part II.\n","\n","\n","\n","One of the goals of this exercise is o make you acquainted with **skorch**. You will probably need to consult the [documentation](https://skorch.readthedocs.io/en/stable/)."]},{"cell_type":"markdown","metadata":{"id":"V920LTuiq40d"},"source":["# Installing skorch and loading libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:32:03.130025Z","iopub.status.busy":"2024-10-11T23:32:03.129637Z","iopub.status.idle":"2024-10-11T23:32:03.136049Z","shell.execute_reply":"2024-10-11T23:32:03.135148Z","shell.execute_reply.started":"2024-10-11T23:32:03.129989Z"},"id":"utYcb97jq40t","trusted":true},"outputs":[],"source":["import subprocess\n","\n","\n","\n","# Installation on Google Colab\n","\n","try:\n","\n","    import google.colab\n","\n","    subprocess.run(['python', '-m', 'pip', 'install', 'skorch'])\n","\n","except ImportError:\n","\n","    pass"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:32:03.138221Z","iopub.status.busy":"2024-10-11T23:32:03.137878Z","iopub.status.idle":"2024-10-11T23:32:28.686837Z","shell.execute_reply":"2024-10-11T23:32:28.685576Z","shell.execute_reply.started":"2024-10-11T23:32:03.138187Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting skorch\n","  Downloading skorch-1.0.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.10/site-packages (from skorch) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from skorch) (1.2.2)\n","Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from skorch) (1.14.1)\n","Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from skorch) (0.9.0)\n","Requirement already satisfied: tqdm>=4.14.0 in /opt/conda/lib/python3.10/site-packages (from skorch) (4.66.4)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->skorch) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.0->skorch) (3.5.0)\n","Downloading skorch-1.0.0-py3-none-any.whl (239 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: skorch\n","Successfully installed skorch-1.0.0\n","Collecting gdown\n","  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\n","Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n","Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n","Installing collected packages: gdown\n","Successfully installed gdown-5.2.0\n"]}],"source":["!pip install skorch\n","\n","!pip install gdown"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:32:28.689146Z","iopub.status.busy":"2024-10-11T23:32:28.688801Z","iopub.status.idle":"2024-10-11T23:32:32.942507Z","shell.execute_reply":"2024-10-11T23:32:32.941686Z","shell.execute_reply.started":"2024-10-11T23:32:28.689112Z"},"id":"WZ3Y_KHvq40x","trusted":true},"outputs":[],"source":["import torch\n","\n","from torch import nn\n","\n","import torch.nn.functional as F\n","\n","from skorch import NeuralNetClassifier\n","\n","\n","\n","import pandas as pd\n","\n","import numpy as np\n","\n","import csv\n","\n","import re\n","\n","import string\n","\n","from collections import defaultdict\n","\n","\n","\n","# Set seed for reproducibility\n","\n","seed = 42\n","\n","np.random.seed(seed)\n","\n","torch.manual_seed(seed)\n","\n","torch.cuda.manual_seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"dAnY8yaDq400"},"source":["## Training a classifier and making predictions"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-11T23:32:32.944269Z","iopub.status.busy":"2024-10-11T23:32:32.943731Z","iopub.status.idle":"2024-10-11T23:32:58.544366Z","shell.execute_reply":"2024-10-11T23:32:58.543223Z","shell.execute_reply.started":"2024-10-11T23:32:32.944224Z"},"id":"zWjt9xGoswAC","outputId":"5e9f1bd0-c578-4591-bb31-a31a6626c971","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs\n","To: /kaggle/working/x_train.txt\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64.1M/64.1M [00:01<00:00, 40.2MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6\n","To: /kaggle/working/x_test.txt\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65.2M/65.2M [00:00<00:00, 70.4MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl\n","To: /kaggle/working/y_train.txt\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480k/480k [00:00<00:00, 108MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X\n","To: /kaggle/working/y_test.txt\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480k/480k [00:00<00:00, 98.2MB/s]\n"]}],"source":["#Â Download dataset\n","\n","!gdown 1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs #Â x_train\n","\n","!gdown 1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6 # x_test\n","\n","!gdown 1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl # y_train\n","\n","!gdown 1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X #Â y_test"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:32:58.548083Z","iopub.status.busy":"2024-10-11T23:32:58.547630Z","iopub.status.idle":"2024-10-11T23:33:00.159486Z","shell.execute_reply":"2024-10-11T23:33:00.158709Z","shell.execute_reply.started":"2024-10-11T23:32:58.548029Z"},"id":"-M6DgXdjtJyH","trusted":true},"outputs":[],"source":["with open(f'x_train.txt') as f:\n","\n","    x_train = f.read().splitlines()\n","\n","with open(f'y_train.txt') as f:\n","\n","    y_train = f.read().splitlines()\n","\n","with open(f'x_test.txt') as f:\n","\n","    x_test = f.read().splitlines()\n","\n","with open(f'y_test.txt') as f:\n","\n","    y_test = f.read().splitlines()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"execution":{"iopub.execute_input":"2024-10-11T23:33:00.160925Z","iopub.status.busy":"2024-10-11T23:33:00.160592Z","iopub.status.idle":"2024-10-11T23:33:02.342288Z","shell.execute_reply":"2024-10-11T23:33:02.341274Z","shell.execute_reply.started":"2024-10-11T23:33:00.160892Z"},"id":"oRqfDA9FuoX1","outputId":"23c71978-d23f-48e5-88ad-f36308461277","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Klement Gottwaldi surnukeha palsameeriti ning ...</td>\n","      <td>est</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sebes, Joseph; Pereira Thomas (1961) (pÃ¥ eng)....</td>\n","      <td>swe</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤¸à¥à¤µà¤¾à¤¤à¤¨à¥à¤¤à¥à¤°à¥à¤¯ à¤†à¤¨à¥à¤¦à¥‹à¤²à¤¨ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤à¤µà¤® à¤•à¥à¤·à¥‡...</td>\n","      <td>mai</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AprÃ¨s lo cort periÃ²de d'establiment a BasilÃ¨a,...</td>\n","      <td>oci</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>à¸–à¸™à¸™à¹€à¸ˆà¸£à¸´à¸à¸à¸£à¸¸à¸‡ (à¸­à¸±à¸à¸©à¸£à¹‚à¸£à¸¡à¸±à¸™: Thanon Charoen Krung...</td>\n","      <td>tha</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text label\n","0  Klement Gottwaldi surnukeha palsameeriti ning ...   est\n","1  Sebes, Joseph; Pereira Thomas (1961) (pÃ¥ eng)....   swe\n","2  à¤­à¤¾à¤°à¤¤à¥€à¤¯ à¤¸à¥à¤µà¤¾à¤¤à¤¨à¥à¤¤à¥à¤°à¥à¤¯ à¤†à¤¨à¥à¤¦à¥‹à¤²à¤¨ à¤°à¤¾à¤·à¥à¤Ÿà¥à¤°à¥€à¤¯ à¤à¤µà¤® à¤•à¥à¤·à¥‡...   mai\n","3  AprÃ¨s lo cort periÃ²de d'establiment a BasilÃ¨a,...   oci\n","4  à¸–à¸™à¸™à¹€à¸ˆà¸£à¸´à¸à¸à¸£à¸¸à¸‡ (à¸­à¸±à¸à¸©à¸£à¹‚à¸£à¸¡à¸±à¸™: Thanon Charoen Krung...   tha"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["#Â Combine x_train and y_train into one dataframe\n","\n","train_df = pd.DataFrame({'text': x_train, 'label': y_train})\n","\n","# Write train_df to csv with tab as separator\n","\n","train_df.to_csv('train_df.csv', index=False, sep='\\t')\n","\n","#Â Comibne x_test and y_test into one dataframe\n","\n","test_df = pd.DataFrame({'text': x_test, 'label': y_test})\n","\n","# Inspect the first 5 items in the train split\n","\n","train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"-s_6f3E7Kt0s"},"source":["### Data preparation\n","\n","\n","\n","Prepare your dataset for this experiment using the same method as you did in part 1.\n","\n","\n","\n","Get a subset of the train/test data that includes 20 languages. Include English, German, Dutch, Danish, Swedish, Norwegian, and Japanese, plus 13 additional languages of your choice based on the items in the list of labels.\n","\n","\n","\n","Don't forget to encode your labels using the adjusted code snippet from part 1!\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-11T23:33:02.344357Z","iopub.status.busy":"2024-10-11T23:33:02.343904Z","iopub.status.idle":"2024-10-11T23:33:02.753336Z","shell.execute_reply":"2024-10-11T23:33:02.752268Z","shell.execute_reply.started":"2024-10-11T23:33:02.344307Z"},"id":"PXpIOpjRxzTl","outputId":"f1c4f2eb-8422-465b-e988-3d02c9bc1f1f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['éŠ€è¡Œåˆ¸ã¯å¸å›½å›½åº«åŠã³ãƒ‰ã‚¤ãƒ„å¸å›½éŠ€è¡Œ(Reichsbank)ã‹ã‚‰ç™ºè¡Œã•ã‚Œã€å¸å›½ã®ã„ãã¤ã‹ã®æ§‹æˆå›½ã®éŠ€è¡Œã‹ã‚‰ã‚‚ç™ºè¡Œã•ã‚ŒãŸã€‚å¸å›½å›½åº«ç™ºè¡Œã®å¸å›½ç´™å¹£(Reichskassenschein)ã¯5ã€10ã€20ã€50ãƒãƒ«ã‚¯ãŒç™ºè¡Œã•ã‚ŒãŸä¸€æ–¹ã€ãƒ‰ã‚¤ãƒ„å¸å›½éŠ€è¡Œåˆ¸(Reichsbanknote)ã¯20ã€50ã€100ã€1000ãƒãƒ«ã‚¯ãŒç™ºè¡Œã•ã‚ŒãŸã€‚1914å¹´ä»¥é™ã«ç™ºè¡Œã•ã‚ŒãŸã“ã‚Œã‚‰ã®éŠ€è¡Œåˆ¸ã¯ãƒ‘ãƒ”ã‚¨ãƒ«ãƒãƒ«ã‚¯ã¨å‘¼ã°ã‚Œã‚‹ã€‚', 'ÙÙŠ Ø¹Ø§Ù… 2007ØŒ ÙƒØ±Ø¦ÙŠØ³ Ø£Ø³Ø§Ù‚ÙØ© Ùˆ ÙƒØ§Ø±Ø¯ÙŠÙ†Ø§Ù„ Ø¨ÙˆÙŠÙ†Ø³ Ø¢ÙŠØ±Ø³ØŒ Ù‚Ø¯Ù… Ø¨ÙŠØ±Ø¬ÙˆÙ„ÙŠÙˆ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù† Ø§Ù„Ù…Ø´ØªØ±Ùƒ Ø§Ù„ØµØ§Ø¯Ø± Ø¹Ù† Ø£Ø³Ø§Ù‚ÙØ© Ø£Ù…Ø±ÙŠÙƒØ§ Ø§Ù„Ù„Ø§ØªÙŠÙ†ÙŠØ© Ø§Ù„Ù…Ø³Ù…Ù‰ \"ÙˆØ«ÙŠÙ‚Ø© Ø£Ø¨Ø§Ø±ÙŠØ³ÙŠØ¯Ø§\" Ø¨Ø¹Ø¯ Ø¥Ù‚Ø±Ø§Ø±Ù‡ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø§Ø¨Ø§ Ø¨Ù†Ø¯ÙƒØª Ø§Ù„Ø³Ø§Ø¯Ø³ Ø¹Ø´Ø±. Ù†ØµØª Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø¹Ù„Ù‰ Ø¶Ø±ÙˆØ±Ø© Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ùˆ Ù‚Ø¨ÙˆÙ„ ØªØ¹Ø§Ù„ÙŠÙ… Ø§Ù„ÙƒÙ†ÙŠØ³Ø© Ø¶Ø¯ \"Ø¬Ø±Ø§Ø¦Ù… Ù†ÙƒØ±Ø§Ø¡\" Ù…Ø«Ù„ Ø§Ù„Ø¥Ø¬Ù‡Ø§Ø¶ ÙˆØ§Ù„Ù‚ØªÙ„ Ø§Ù„Ø±Ø­ÙŠÙ…: \"Ù†Ø£Ù…Ù„ Ø£Ù† Ø§Ù„Ù…Ø´Ø±Ø¹ÙŠÙ† ÙˆØ±Ø¤Ø³Ø§Ø¡ Ø§Ù„Ø­ÙƒÙˆÙ…Ø§ØªØŒ ÙˆØ§Ù„Ø¹Ø§Ù…Ù„ÙŠÙ† ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„ØµØ­Ø©ØŒ Ø³ÙŠØ¯Ø±ÙƒÙˆÙ† ÙƒØ±Ø§Ù…Ø© Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ø¥Ù†Ø³Ø§Ù†ÙŠØ© ÙˆØ£Ù‡Ù…ÙŠØ© Ø§Ù„Ø¹Ø§Ø¦Ù„Ø© ÙÙŠ Ø´Ø¹ÙˆØ¨Ù†Ø§ØŒ Ùˆ Ø³ÙŠØ¯Ø§ÙØ¹ÙˆÙ† Ø¹Ù† Ø­Ù…Ø§ÙŠØªÙ‡Ø§ Ù…Ù† Ø¬Ø±Ø§Ø¦Ù… Ù†ÙƒØ±Ø§Ø¡ Ù…Ø«Ù„ Ø§Ù„Ø¥Ø¬Ù‡Ø§Ø¶ ÙˆØ§Ù„Ù‚ØªÙ„ Ø§Ù„Ø±Ø­ÙŠÙ…ØŒ ÙˆÙ‡Ø°Ù‡ Ù‡ÙŠ Ù…Ø³Ø¤ÙˆÙ„ÙŠØªÙ‡Ù…. ÙˆÙ†Ø­Ù† Ù†Ù„Ø²Ù… Ø£Ù†ÙØ³Ù†Ø§ \"ØªÙ…Ø§Ø³Ùƒ Ø¥ÙØ®Ø§Ø±Ø³ØªÙŠ\"ØŒ Ø¨Ù…Ø§ Ù…Ø¹Ù†Ø§Ù‡ØŒ ÙŠØ¬Ø¨ Ø£Ù† Ù†ÙƒÙˆÙ† ÙˆØ§Ø¹ÙŠÙ† Ø¨Ø£Ù† Ø§Ù„Ù†Ø§Ø³ Ù„Ø§ ÙŠØ³ØªØ·ÙŠØ¹ÙˆÙ† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Ø¨Ø§Ù† Ø§Ù„Ù…Ù‚Ø¯Ø³ ÙˆÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ù†ÙØ³Ù‡ Ù‡Ù… ÙŠØ¹Ù…Ù„ÙˆÙ† Ø¶Ø¯ Ø§Ù„ÙˆØµØ§ÙŠØ§ØŒ ÙˆÙ„Ø§ Ø³ÙŠÙ…Ø§ Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙˆØ§ÙÙ‚ÙˆÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ù‡Ø§Ø¶ ÙˆØ§Ù„Ù‚ØªÙ„ Ø§Ù„Ø±Ø­ÙŠÙ…ØŒ ÙˆØºÙŠØ±Ù‡Ø§ Ù…Ù† Ø§Ù„Ø¬Ø±Ø§Ø¦Ù… Ø§Ù„Ø®Ø·ÙŠØ±Ø© Ø¶Ø¯ Ø§Ù„Ø­ÙŠØ§Ø© ÙˆØ§Ù„Ø¹Ø§Ø¦Ù„Ø©ØŒ ÙˆÙ‡Ùˆ ÙŠÙ†Ø·Ø¨Ù‚ Ø¨Ø´ÙƒÙ„ Ø®Ø§Øµ Ø¹Ù„Ù‰ Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© Ø§Ù„Ù…Ø´Ø±Ø¹ÙŠÙ† ÙˆØ§Ù„Ø­ÙƒØ§Ù…ØŒ ÙˆØ§Ù„Ø¹Ø§Ù…Ù„ÙŠÙ† ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„ØµØ­Ø©\". ÙˆÙ‚Ø¯ ÙˆØµÙ Ø§Ù„Ø­Ø±ÙƒØ© Ø§Ù„Ù…Ø¤ÙŠØ¯Ø© Ù„Ù„Ø¥Ø¬Ù‡Ø§Ø¶ Ø¨Ø§Ø¹ØªØ¨Ø§Ø±Ù‡ \"Ø«Ù‚Ø§ÙØ© Ø§Ù„Ù…ÙˆØª\"ØŒ Ùˆ ÙƒØ§Ù† ÙŠØ¹Ø§Ø±Ø¶ ØªÙˆØ²ÙŠØ¹ ÙˆØ³Ø§Ø¦Ù„ Ù…Ù†Ø¹ Ø§Ù„Ø­Ù…Ù„ Ù…Ø¬Ø§Ù†Ù‹Ø§ ÙÙŠ Ø§Ù„Ø£Ø±Ø¬Ù†ØªÙŠÙ†.', 'Luis Alberto SuÃ¡rez DÃ­az (s. 24. tammikuuta 1987 Salto, Uruguay) on uruguaylainen jalkapalloilija, joka pelaa hyÃ¶kkÃ¤Ã¤jÃ¤nÃ¤ tai oikeana laitalinkkinÃ¤ Barcelonassa ja edustaa myÃ¶s Uruguayn maajoukkuetta. SuÃ¡rez tunnetaan lempinimellÃ¤ El Pistolero (suom. revolverisankari).', \"Bij installatie zal een instantienaam en een aantal poortnummers worden bepaald. De instantienaam bestaat uit twee tekens en moet beginnen met een letter. Deze code zal gebruikt worden om te berekenen op welke poorten de Ingres Servers zal luisteren. Standaard zal er gebruikgemaakt worden van de de code 'll', welke zal luisteren naar de poorten 21064 tot 21071.\", '1951å¹´5æœˆ14æ—¥ï¼Œè”åˆå›½å¤§ä¼šé¢å¤–æªæ–½å§”å‘˜ä¼šé€šè¿‡äº†ç¾å›½æå‡ºçš„å¯¹ä¸­åäººæ°‘å…±å’Œå›½å’Œæœé²œæ°‘ä¸»ä¸»ä¹‰äººæ°‘å…±å’Œå›½å®è¡Œç¦è¿çš„ææ¡ˆã€‚5æœˆ18æ—¥è¯¥ææ¡ˆè¢«è”åˆå›½å¤§ä¼šè¡¨å†³é€šè¿‡ä¸ºè”åˆå›½å¤§ä¼š500å·å†³è®®â€œADDITIONAL MEASURES TO BE EMPLOYED TO MEET THE AGRESSION IN KOREAâ€ã€‚5æœˆ22æ—¥ï¼Œä¸­å›½æ”¿åºœå¤–äº¤éƒ¨å°±è”å¤§500å·å†³è®®å‘è¡¨å£°æ˜ï¼ŒæŒ‡å‡ºè¿™æ˜¯è”å¤§â€œåˆä¸€ç ´åè”åˆå›½å®ªç« ï¼Œä¾µè¶Šå®‰å…¨ç†äº‹ä¼šæƒé™å¹¶è“„æ„æ‰©å¤§ä¾µç•¥æˆ˜äº‰çš„éæ³•è¡ŒåŠ¨â€ã€‚43ä¸ªå›½å®¶æ¥å—è”å¤§500å·å†³è®®å¹¶åŠ ä»¥å®è¡Œã€‚ä¸­å›½ä»è¥¿æ–¹å›½å®¶çš„è¿›å£é¢ï¼Œ1952å¹´æ¯”1951å¹´ä¸‹è·Œäº†å››æˆã€‚1951å¹´5æœˆï¼Œæ”¿åŠ¡é™¢å‘å¸ƒå…è®¸å¯¹å¤–èµ„ä¼ä¸šå¾ç”¨æˆ–å¾è´­ã€‚']\n","['jpn', 'ara', 'fin', 'nld', 'zho']\n"]}],"source":["# TODO: Create your train/test subsets of languages\n","\n","# Note, make sure these are the same as what you used in Part 1!\n","\n","\n","\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","# TODO: Create your train/test subsets of languages\n","\n","language_filter = ['eng','deu','nld','dan','swe','nob','jpn', #basics\n","\n","                   'fra', 'spa', 'rus', 'por', 'ita', 'kor', 'ara', 'zho', 'hin', 'tam', 'tha', 'vie', 'fin' #additionals\n","\n","                   ]\n","\n","# Filter x and y based on the language filter\n","\n","filtered_x = [text for text,label in zip(x_train + x_test,y_train + y_test) if label in language_filter]\n","\n","filtered_y = [label for label in y_train + y_test if label in language_filter]\n","\n","\n","\n","# Split the train/test data into 8:2\n","\n","x_train,x_test,y_train,y_test = train_test_split(filtered_x,filtered_y,test_size = 0.2,random_state=42)\n","\n","\n","\n","#display\n","\n","print(x_train[:5])\n","\n","print(y_train[:5])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-11T23:33:02.755352Z","iopub.status.busy":"2024-10-11T23:33:02.754920Z","iopub.status.idle":"2024-10-11T23:33:02.794038Z","shell.execute_reply":"2024-10-11T23:33:02.792907Z","shell.execute_reply.started":"2024-10-11T23:33:02.755303Z"},"id":"vMp0gji4MCDl","outputId":"11406782-1d32-41ab-fc28-605994b5bdd9","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['ara' 'dan' 'deu' 'eng' 'fin' 'fra' 'hin' 'ita' 'jpn' 'kor' 'nld' 'nob'\n"," 'por' 'rus' 'spa' 'swe' 'tam' 'tha' 'vie' 'zho']\n","[ 8  0  4 ... 19 18  1]\n","[ 7 15 12 ...  1  1  0]\n"]}],"source":["# TODO: Use your adjusted code from part 1 to encode the labels again\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","\n","label_encoder = LabelEncoder().fit(y_train)\n","\n","y_train, y_test = label_encoder.transform(y_train), label_encoder.transform(y_test)\n","\n","print(label_encoder.classes_)\n","\n","print(y_train)\n","\n","print(y_test)"]},{"cell_type":"markdown","metadata":{"id":"iGBLxHU-LcVL"},"source":["### Feature Extraction"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:33:02.795812Z","iopub.status.busy":"2024-10-11T23:33:02.795447Z","iopub.status.idle":"2024-10-11T23:33:07.691198Z","shell.execute_reply":"2024-10-11T23:33:07.690424Z","shell.execute_reply.started":"2024-10-11T23:33:02.795759Z"},"id":"2-Ls0e0GQgMF","trusted":true},"outputs":[],"source":["#Â First, we extract some simple features as input for the neural network\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","\n","\n","vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2), max_features=100, binary=True)\n","\n","X = vectorizer.fit_transform(x_train)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:33:07.692620Z","iopub.status.busy":"2024-10-11T23:33:07.692318Z","iopub.status.idle":"2024-10-11T23:33:07.720626Z","shell.execute_reply":"2024-10-11T23:33:07.719909Z","shell.execute_reply.started":"2024-10-11T23:33:07.692589Z"},"id":"9EiRal_1Q0iJ","trusted":true},"outputs":[],"source":["# We need to change the datatype to make it play nice with pytorch\n","\n","X = X.astype(np.float32)\n","\n","y = y_train.astype(np.int64)"]},{"cell_type":"markdown","metadata":{"id":"oMFoiitJq407"},"source":["In the following, we define a vanilla neural network with two hidden layers. The output layer should have as many outputs as there are classes. In addition, it should have a nonlinearity function."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:33:07.723792Z","iopub.status.busy":"2024-10-11T23:33:07.723442Z","iopub.status.idle":"2024-10-11T23:33:07.731471Z","shell.execute_reply":"2024-10-11T23:33:07.730606Z","shell.execute_reply.started":"2024-10-11T23:33:07.723742Z"},"id":"7Q5EDIGQUUBy","trusted":true},"outputs":[],"source":["# TODO: In the following, you can find a small (almost) working example of a neural network.\n","\n","# Unfortunately, again, the cat messed up some of the code. Please fix the code such that it is executable. (Hint: the input and output sizes look a bit weird...)\n","\n","\n","\n","class ClassifierModule(nn.Module):\n","\n","    def __init__(\n","\n","        self,\n","\n","        num_units=200,\n","\n","        nonlin=F.relu,\n","\n","        num_classes=20,\n","\n","        input_size=100,\n","\n","    ):\n","\n","        super(ClassifierModule, self).__init__()\n","\n","        self.num_units = num_units\n","\n","        self.nonlin = nonlin\n","\n","\n","\n","        self.dense0 = nn.Linear(input_size, num_units)\n","\n","        self.nonlin = nonlin\n","\n","        self.dense1 = nn.Linear(num_units, 50)\n","\n","        self.output = nn.Linear(50, num_classes)\n","\n","\n","\n","    def forward(self, X, **kwargs):\n","\n","        X = self.nonlin(self.dense0(X))\n","\n","        X = F.relu(self.dense1(X))\n","\n","        X = self.output(X)\n","\n","        return X.squeeze(dim=1)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:33:07.733147Z","iopub.status.busy":"2024-10-11T23:33:07.732743Z","iopub.status.idle":"2024-10-11T23:33:07.772288Z","shell.execute_reply":"2024-10-11T23:33:07.771541Z","shell.execute_reply.started":"2024-10-11T23:33:07.733103Z"},"id":"wKnJECeQGpyI","trusted":true},"outputs":[],"source":["# Initalise the neural net classifier.\n","\n","net = NeuralNetClassifier(\n","\n","    ClassifierModule(\n","\n","        input_size=X.shape[1],\n","\n","        num_units=200,\n","\n","        num_classes=len(label_encoder.classes_),\n","\n","        nonlin=F.relu,\n","\n","    ),\n","\n","    max_epochs=20,\n","\n","    criterion=nn.CrossEntropyLoss(),\n","\n","    lr=0.1,\n","\n","    device='cuda',  # comment this to train with CPU\n","\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-11T23:33:07.773741Z","iopub.status.busy":"2024-10-11T23:33:07.773402Z","iopub.status.idle":"2024-10-11T23:33:44.094034Z","shell.execute_reply":"2024-10-11T23:33:44.093089Z","shell.execute_reply.started":"2024-10-11T23:33:07.773708Z"},"id":"QcNOd9yBSxys","outputId":"53b79f0e-c2fe-4bb0-e230-ee63200e3281","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7376\u001b[0m       \u001b[32m0.2303\u001b[0m        \u001b[35m2.4827\u001b[0m  1.9744\n","      2        \u001b[36m2.1024\u001b[0m       \u001b[32m0.4122\u001b[0m        \u001b[35m1.7188\u001b[0m  1.7499\n","      3        \u001b[36m1.5182\u001b[0m       \u001b[32m0.5319\u001b[0m        \u001b[35m1.3270\u001b[0m  1.7271\n","      4        \u001b[36m1.2503\u001b[0m       \u001b[32m0.6306\u001b[0m        \u001b[35m1.1424\u001b[0m  1.7992\n","      5        \u001b[36m1.0864\u001b[0m       \u001b[32m0.6506\u001b[0m        \u001b[35m1.0249\u001b[0m  1.6949\n","      6        \u001b[36m0.9856\u001b[0m       \u001b[32m0.6606\u001b[0m        \u001b[35m0.9579\u001b[0m  1.6832\n","      7        \u001b[36m0.9264\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.9192\u001b[0m  1.7867\n","      8        \u001b[36m0.8891\u001b[0m       \u001b[32m0.6753\u001b[0m        \u001b[35m0.8941\u001b[0m  1.7717\n","      9        \u001b[36m0.8632\u001b[0m       \u001b[32m0.6787\u001b[0m        \u001b[35m0.8764\u001b[0m  1.7162\n","     10        \u001b[36m0.8434\u001b[0m       \u001b[32m0.6822\u001b[0m        \u001b[35m0.8627\u001b[0m  1.7720\n","     11        \u001b[36m0.8275\u001b[0m       \u001b[32m0.6837\u001b[0m        \u001b[35m0.8523\u001b[0m  1.7142\n","     12        \u001b[36m0.8141\u001b[0m       \u001b[32m0.6875\u001b[0m        \u001b[35m0.8438\u001b[0m  1.7065\n","     13        \u001b[36m0.8027\u001b[0m       \u001b[32m0.6897\u001b[0m        \u001b[35m0.8368\u001b[0m  1.6811\n","     14        \u001b[36m0.7928\u001b[0m       \u001b[32m0.6925\u001b[0m        \u001b[35m0.8307\u001b[0m  1.7162\n","     15        \u001b[36m0.7841\u001b[0m       \u001b[32m0.6937\u001b[0m        \u001b[35m0.8263\u001b[0m  1.7428\n","     16        \u001b[36m0.7762\u001b[0m       \u001b[32m0.6953\u001b[0m        \u001b[35m0.8223\u001b[0m  1.6988\n","     17        \u001b[36m0.7692\u001b[0m       0.6953        \u001b[35m0.8198\u001b[0m  1.6831\n","     18        \u001b[36m0.7628\u001b[0m       0.6941        \u001b[35m0.8176\u001b[0m  1.7301\n","     19        \u001b[36m0.7569\u001b[0m       \u001b[32m0.6959\u001b[0m        \u001b[35m0.8157\u001b[0m  1.7779\n","     20        \u001b[36m0.7515\u001b[0m       \u001b[32m0.6969\u001b[0m        \u001b[35m0.8143\u001b[0m  1.8246\n"]},{"data":{"text/plain":["<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n","  module_=ClassifierModule(\n","    (dense0): Linear(in_features=100, out_features=200, bias=True)\n","    (dense1): Linear(in_features=200, out_features=50, bias=True)\n","    (output): Linear(in_features=50, out_features=20, bias=True)\n","  ),\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Train the classifier\n","\n","net.fit(X, y)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-11T23:33:44.095948Z","iopub.status.busy":"2024-10-11T23:33:44.095363Z","iopub.status.idle":"2024-10-11T23:33:45.765386Z","shell.execute_reply":"2024-10-11T23:33:45.764226Z","shell.execute_reply.started":"2024-10-11T23:33:44.095903Z"},"id":"7SWtTc1zjie8","outputId":"2d98581e-cbd7-4af8-ccd4-1320e41d8b48","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.682\n"]}],"source":["X_test = vectorizer.transform(x_test)\n","\n","X_test = X_test.astype(np.float32)\n","\n","y_test_np = np.array(y_test, dtype=np.int64)\n","\n","\n","\n","y_pred = net.predict(X_test)\n","\n","test_accuracy = np.mean(y_pred == y_test_np)\n","\n","print(f\"Test Accuracy: {test_accuracy}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Experimenting with a better count vectorizer"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:33:45.767309Z","iopub.status.busy":"2024-10-11T23:33:45.766871Z","iopub.status.idle":"2024-10-11T23:33:50.875490Z","shell.execute_reply":"2024-10-11T23:33:50.874693Z","shell.execute_reply.started":"2024-10-11T23:33:45.767257Z"},"trusted":true},"outputs":[],"source":["vectorizer_updated = CountVectorizer(analyzer='char', ngram_range=(2, 2), max_features=5000, binary=True)\n","\n","X_cv_updated = vectorizer_updated.fit_transform(x_train)\n","\n","X_cv_updated = X_cv_updated.astype(np.float32)\n","\n","y_cv_updted = y_train.astype(np.int64)\n","\n","\n","\n","net_cv_updated = NeuralNetClassifier(\n","\n","    ClassifierModule(\n","\n","        input_size=X_cv_updated.shape[1],\n","\n","        num_units=200,\n","\n","        num_classes=len(label_encoder.classes_),\n","\n","        nonlin=F.relu,\n","\n","    ),\n","\n","    max_epochs=20,\n","\n","    criterion=nn.CrossEntropyLoss(),\n","\n","    lr=0.1,\n","\n","    device='cuda',  # comment this to train with CPU\n","\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:33:50.877006Z","iopub.status.busy":"2024-10-11T23:33:50.876673Z","iopub.status.idle":"2024-10-11T23:34:29.519769Z","shell.execute_reply":"2024-10-11T23:34:29.518843Z","shell.execute_reply.started":"2024-10-11T23:33:50.876972Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.3122\u001b[0m       \u001b[32m0.6966\u001b[0m        \u001b[35m1.2376\u001b[0m  1.9263\n","      2        \u001b[36m0.7029\u001b[0m       \u001b[32m0.8925\u001b[0m        \u001b[35m0.3870\u001b[0m  1.8889\n","      3        \u001b[36m0.2740\u001b[0m       \u001b[32m0.9647\u001b[0m        \u001b[35m0.2131\u001b[0m  1.9559\n","      4        \u001b[36m0.1582\u001b[0m       \u001b[32m0.9731\u001b[0m        \u001b[35m0.1500\u001b[0m  1.9326\n","      5        \u001b[36m0.1123\u001b[0m       \u001b[32m0.9766\u001b[0m        \u001b[35m0.1245\u001b[0m  1.9341\n","      6        \u001b[36m0.0886\u001b[0m       \u001b[32m0.9781\u001b[0m        \u001b[35m0.1110\u001b[0m  1.9176\n","      7        \u001b[36m0.0732\u001b[0m       \u001b[32m0.9788\u001b[0m        \u001b[35m0.1026\u001b[0m  1.9376\n","      8        \u001b[36m0.0620\u001b[0m       \u001b[32m0.9794\u001b[0m        \u001b[35m0.0969\u001b[0m  1.9674\n","      9        \u001b[36m0.0534\u001b[0m       \u001b[32m0.9803\u001b[0m        \u001b[35m0.0927\u001b[0m  1.9149\n","     10        \u001b[36m0.0464\u001b[0m       \u001b[32m0.9809\u001b[0m        \u001b[35m0.0898\u001b[0m  1.9440\n","     11        \u001b[36m0.0406\u001b[0m       \u001b[32m0.9816\u001b[0m        \u001b[35m0.0876\u001b[0m  1.9457\n","     12        \u001b[36m0.0358\u001b[0m       0.9816        \u001b[35m0.0861\u001b[0m  1.9044\n","     13        \u001b[36m0.0316\u001b[0m       0.9812        \u001b[35m0.0850\u001b[0m  1.9995\n","     14        \u001b[36m0.0281\u001b[0m       0.9816        \u001b[35m0.0842\u001b[0m  1.9498\n","     15        \u001b[36m0.0250\u001b[0m       0.9816        \u001b[35m0.0836\u001b[0m  1.8980\n","     16        \u001b[36m0.0223\u001b[0m       \u001b[32m0.9819\u001b[0m        \u001b[35m0.0833\u001b[0m  1.8908\n","     17        \u001b[36m0.0199\u001b[0m       \u001b[32m0.9831\u001b[0m        \u001b[35m0.0831\u001b[0m  1.8921\n","     18        \u001b[36m0.0179\u001b[0m       0.9828        \u001b[35m0.0830\u001b[0m  1.9313\n","     19        \u001b[36m0.0161\u001b[0m       0.9825        0.0830  1.8906\n","     20        \u001b[36m0.0146\u001b[0m       0.9825        0.0831  1.9131\n"]},{"data":{"text/plain":["<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n","  module_=ClassifierModule(\n","    (dense0): Linear(in_features=5000, out_features=200, bias=True)\n","    (dense1): Linear(in_features=200, out_features=50, bias=True)\n","    (output): Linear(in_features=50, out_features=20, bias=True)\n","  ),\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["net_cv_updated.fit(X_cv_updated, y_cv_updted)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:34:29.521331Z","iopub.status.busy":"2024-10-11T23:34:29.521002Z","iopub.status.idle":"2024-10-11T23:34:31.418733Z","shell.execute_reply":"2024-10-11T23:34:31.417551Z","shell.execute_reply.started":"2024-10-11T23:34:29.521297Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.98075\n"]}],"source":["X_cv_updated_test = vectorizer_updated.transform(x_test)\n","\n","X_cv_updated_test = X_cv_updated_test.astype(np.float32)\n","\n","y_test_np = np.array(y_test, dtype=np.int64)\n","\n","\n","\n","y_cv_updated_pred = net_cv_updated.predict(X_cv_updated_test)\n","\n","test_cv_updated_accuracy = np.mean(y_cv_updated_pred == y_test_np)\n","\n","print(f\"Test Accuracy: {test_cv_updated_accuracy}\")"]},{"cell_type":"markdown","metadata":{"id":"JiovRi0liZ9c"},"source":["### Experimenting with TF-IDF vectorizer instead of count vectorizer"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-11T23:34:31.420925Z","iopub.status.busy":"2024-10-11T23:34:31.420362Z","iopub.status.idle":"2024-10-11T23:35:14.631714Z","shell.execute_reply":"2024-10-11T23:35:14.630674Z","shell.execute_reply.started":"2024-10-11T23:34:31.420874Z"},"id":"ojozp-muhd34","outputId":"074ca18d-4853-40f4-98f9-e7a1989ae56f","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9956\u001b[0m       \u001b[32m0.0509\u001b[0m        \u001b[35m2.9912\u001b[0m  1.9132\n","      2        \u001b[36m2.9870\u001b[0m       \u001b[32m0.1506\u001b[0m        \u001b[35m2.9810\u001b[0m  1.8943\n","      3        \u001b[36m2.9729\u001b[0m       \u001b[32m0.2853\u001b[0m        \u001b[35m2.9608\u001b[0m  1.8978\n","      4        \u001b[36m2.9367\u001b[0m       \u001b[32m0.4203\u001b[0m        \u001b[35m2.8967\u001b[0m  1.8823\n","      5        \u001b[36m2.7900\u001b[0m       0.2347        \u001b[35m2.6222\u001b[0m  1.9340\n","      6        \u001b[36m2.4308\u001b[0m       0.3503        \u001b[35m2.2732\u001b[0m  1.9807\n","      7        \u001b[36m2.1525\u001b[0m       \u001b[32m0.6381\u001b[0m        \u001b[35m2.0182\u001b[0m  1.9009\n","      8        \u001b[36m1.8529\u001b[0m       \u001b[32m0.7141\u001b[0m        \u001b[35m1.6706\u001b[0m  1.8926\n","      9        \u001b[36m1.4840\u001b[0m       \u001b[32m0.7234\u001b[0m        \u001b[35m1.3078\u001b[0m  1.8834\n","     10        \u001b[36m1.1609\u001b[0m       \u001b[32m0.7422\u001b[0m        \u001b[35m1.0385\u001b[0m  1.9115\n","     11        \u001b[36m0.9309\u001b[0m       \u001b[32m0.7953\u001b[0m        \u001b[35m0.8462\u001b[0m  1.8606\n","     12        \u001b[36m0.7571\u001b[0m       \u001b[32m0.8653\u001b[0m        \u001b[35m0.6860\u001b[0m  1.8747\n","     13        \u001b[36m0.6040\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m0.5400\u001b[0m  1.8755\n","     14        \u001b[36m0.4709\u001b[0m       \u001b[32m0.9297\u001b[0m        \u001b[35m0.4230\u001b[0m  1.9304\n","     15        \u001b[36m0.3704\u001b[0m       \u001b[32m0.9400\u001b[0m        \u001b[35m0.3425\u001b[0m  1.8627\n","     16        \u001b[36m0.3023\u001b[0m       \u001b[32m0.9453\u001b[0m        \u001b[35m0.2903\u001b[0m  1.9076\n","     17        \u001b[36m0.2573\u001b[0m       \u001b[32m0.9484\u001b[0m        \u001b[35m0.2559\u001b[0m  1.8644\n","     18        \u001b[36m0.2264\u001b[0m       \u001b[32m0.9509\u001b[0m        \u001b[35m0.2321\u001b[0m  1.9210\n","     19        \u001b[36m0.2039\u001b[0m       \u001b[32m0.9556\u001b[0m        \u001b[35m0.2146\u001b[0m  1.8869\n","     20        \u001b[36m0.1867\u001b[0m       \u001b[32m0.9575\u001b[0m        \u001b[35m0.2011\u001b[0m  1.8922\n"]},{"data":{"text/plain":["<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n","  module_=ClassifierModule(\n","    (dense0): Linear(in_features=5000, out_features=200, bias=True)\n","    (dense1): Linear(in_features=200, out_features=50, bias=True)\n","    (output): Linear(in_features=50, out_features=20, bias=True)\n","  ),\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","\n","\n","# Use TF-IDF vectorizer for better feature representation\n","\n","vectorizer_tfidf = TfidfVectorizer(analyzer='char', ngram_range=(2,2), max_features=5000, use_idf=True) # Increased ngram range and max_features\n","\n","X_tfidf = vectorizer_tfidf.fit_transform(x_train)\n","\n","X_tfidf = X_tfidf.astype(np.float32)\n","\n","y_tfidf = y_train.astype(np.int64)\n","\n","\n","\n","\n","\n","# Initalise the neural net classifier.\n","\n","net_tfid = NeuralNetClassifier(\n","\n","    ClassifierModule(\n","\n","        input_size=X_tfidf.shape[1],\n","\n","        num_units=200,\n","\n","        num_classes=len(label_encoder.classes_),\n","\n","        nonlin=F.relu,\n","\n","    ),\n","\n","    max_epochs=20,\n","\n","    criterion=nn.CrossEntropyLoss(),\n","\n","    lr=0.1,\n","\n","    device='cuda',  # comment this to train with CPU\n","\n",")\n","\n","\n","\n","# Train the classifier\n","\n","net_tfid.fit(X_tfidf, y_tfidf)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-11T23:35:14.633547Z","iopub.status.busy":"2024-10-11T23:35:14.633096Z","iopub.status.idle":"2024-10-11T23:35:16.553952Z","shell.execute_reply":"2024-10-11T23:35:16.552856Z","shell.execute_reply.started":"2024-10-11T23:35:14.633487Z"},"id":"Q3jbEf64jtGR","outputId":"64623d2b-f5b3-4629-eb71-2b64feb8f115","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy with TF-IDF: 0.95775\n"]}],"source":["X_test_tfidf = vectorizer_tfidf.transform(x_test)\n","\n","X_test_tfidf = X_test_tfidf.astype(np.float32)\n","\n","y_test_np = np.array(y_test, dtype=np.int64)\n","\n","\n","\n","y_pred_tfidf = net_tfid.predict(X_test_tfidf)\n","\n","test_accuracy_tfidf = np.mean(y_pred_tfidf == y_test_np)\n","\n","print(f\"Test Accuracy with TF-IDF: {test_accuracy_tfidf}\")\n"]},{"cell_type":"markdown","metadata":{"id":"cviv9PS-NSCq"},"source":["Note, you can also use `GridSearchCV` with `skorch`, but be aware that training a neural network takes much more time.\n","\n","\n","\n","Play around with 5 different sets of hyperparameters. For example, consider some of the following:\n","\n","\n","\n","- layer sizes\n","\n","- activation functions\n","\n","- regularizers\n","\n","- early stopping\n","\n","- vectorizer parameters\n","\n","\n","\n","Report your best hyperparameter combination. \\\\\n","\n","ğŸ“â“ What is the effect of your modifcations on validation performance? Discuss potential reasons."]},{"cell_type":"markdown","metadata":{"id":"FbxuaEDPrZSu"},"source":["â˜ Note, during model development, if you run into the infamous CUDA out-of-memory (OOM) error, try clearing the GPU memory either with `torch.cuda.empty_cache()` or restarting the runtime."]},{"cell_type":"markdown","metadata":{},"source":["## Grid Search for best hyper parameters with Count Vectorizer"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:35:16.556299Z","iopub.status.busy":"2024-10-11T23:35:16.555880Z","iopub.status.idle":"2024-10-11T23:35:16.573585Z","shell.execute_reply":"2024-10-11T23:35:16.572663Z","shell.execute_reply.started":"2024-10-11T23:35:16.556252Z"},"id":"BCwaMlVkifDx","trusted":true},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","from skorch.callbacks import EarlyStopping\n","\n","\n","\n","# Define the parameter grid for GridSearchCV\n","\n","param_grid = {\n","\n","    'module__num_units': [100, 200, 300],\n","\n","    'module__nonlin': [F.relu],\n","\n","    'module__input_size': [X_cv_updated.shape[1]],\n","\n","    'lr': [0.01, 0.1],\n","\n","    'max_epochs': [20, 30],\n","\n","    'callbacks': [[('EarlyStopping', EarlyStopping(patience=patience))] for patience in [5]]\n","\n","}\n","\n","\n","\n","net_cv_gs = NeuralNetClassifier(\n","\n","    ClassifierModule(\n","\n","        input_size=X_cv_updated.shape[1],\n","\n","        num_units=200,\n","\n","        num_classes=len(label_encoder.classes_),\n","\n","        nonlin=F.relu,\n","\n","    ),\n","\n","    max_epochs=20,\n","\n","    criterion=nn.CrossEntropyLoss(),\n","\n","    lr=0.1,\n","\n","    device='cuda',  # comment this to train with CPU\n","\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-11T23:35:16.575820Z","iopub.status.busy":"2024-10-11T23:35:16.574861Z","iopub.status.idle":"2024-10-11T23:54:42.703397Z","shell.execute_reply":"2024-10-11T23:54:42.702365Z","shell.execute_reply.started":"2024-10-11T23:35:16.575768Z"},"id":"uP_UIB_OnHZC","outputId":"8bf71086-f01e-4b54-cf91-a45a495e8914","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9801\u001b[0m       \u001b[32m0.1012\u001b[0m        \u001b[35m2.9618\u001b[0m  1.2616\n","      2        \u001b[36m2.9412\u001b[0m       \u001b[32m0.1598\u001b[0m        \u001b[35m2.9182\u001b[0m  1.3189\n","      3        \u001b[36m2.8886\u001b[0m       \u001b[32m0.2835\u001b[0m        \u001b[35m2.8548\u001b[0m  1.2777\n","      4        \u001b[36m2.8119\u001b[0m       \u001b[32m0.4025\u001b[0m        \u001b[35m2.7636\u001b[0m  1.2515\n","      5        \u001b[36m2.7086\u001b[0m       \u001b[32m0.5492\u001b[0m        \u001b[35m2.6499\u001b[0m  1.2733\n","      6        \u001b[36m2.5905\u001b[0m       \u001b[32m0.7216\u001b[0m        \u001b[35m2.5287\u001b[0m  1.2417\n","      7        \u001b[36m2.4651\u001b[0m       \u001b[32m0.7610\u001b[0m        \u001b[35m2.3966\u001b[0m  1.2796\n","      8        \u001b[36m2.3203\u001b[0m       \u001b[32m0.7784\u001b[0m        \u001b[35m2.2389\u001b[0m  1.2790\n","      9        \u001b[36m2.1493\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m2.0583\u001b[0m  1.2683\n","     10        \u001b[36m1.9621\u001b[0m       \u001b[32m0.7990\u001b[0m        \u001b[35m1.8685\u001b[0m  1.2782\n","     11        \u001b[36m1.7709\u001b[0m       \u001b[32m0.8140\u001b[0m        \u001b[35m1.6792\u001b[0m  1.2573\n","     12        \u001b[36m1.5869\u001b[0m       \u001b[32m0.8318\u001b[0m        \u001b[35m1.5034\u001b[0m  1.2456\n","     13        \u001b[36m1.4215\u001b[0m       \u001b[32m0.8477\u001b[0m        \u001b[35m1.3489\u001b[0m  1.2542\n","     14        \u001b[36m1.2771\u001b[0m       \u001b[32m0.8590\u001b[0m        \u001b[35m1.2139\u001b[0m  1.2554\n","     15        \u001b[36m1.1504\u001b[0m       \u001b[32m0.8716\u001b[0m        \u001b[35m1.0954\u001b[0m  1.2830\n","     16        \u001b[36m1.0390\u001b[0m       \u001b[32m0.8824\u001b[0m        \u001b[35m0.9916\u001b[0m  1.2584\n","     17        \u001b[36m0.9412\u001b[0m       \u001b[32m0.8988\u001b[0m        \u001b[35m0.9007\u001b[0m  1.2523\n","     18        \u001b[36m0.8550\u001b[0m       \u001b[32m0.9180\u001b[0m        \u001b[35m0.8204\u001b[0m  1.2666\n","     19        \u001b[36m0.7782\u001b[0m       \u001b[32m0.9316\u001b[0m        \u001b[35m0.7487\u001b[0m  1.2629\n","     20        \u001b[36m0.7096\u001b[0m       \u001b[32m0.9353\u001b[0m        \u001b[35m0.6845\u001b[0m  1.2562\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9850\u001b[0m       \u001b[32m0.0492\u001b[0m        \u001b[35m2.9670\u001b[0m  1.2765\n","      2        \u001b[36m2.9452\u001b[0m       \u001b[32m0.0501\u001b[0m        \u001b[35m2.9213\u001b[0m  1.2924\n","      3        \u001b[36m2.8919\u001b[0m       \u001b[32m0.0754\u001b[0m        \u001b[35m2.8601\u001b[0m  1.2587\n","      4        \u001b[36m2.8205\u001b[0m       \u001b[32m0.1331\u001b[0m        \u001b[35m2.7788\u001b[0m  1.2531\n","      5        \u001b[36m2.7296\u001b[0m       \u001b[32m0.2179\u001b[0m        \u001b[35m2.6798\u001b[0m  1.2626\n","      6        \u001b[36m2.6238\u001b[0m       \u001b[32m0.4269\u001b[0m        \u001b[35m2.5687\u001b[0m  1.2892\n","      7        \u001b[36m2.5051\u001b[0m       \u001b[32m0.5722\u001b[0m        \u001b[35m2.4431\u001b[0m  1.3099\n","      8        \u001b[36m2.3671\u001b[0m       \u001b[32m0.6781\u001b[0m        \u001b[35m2.2944\u001b[0m  1.2633\n","      9        \u001b[36m2.2052\u001b[0m       \u001b[32m0.7427\u001b[0m        \u001b[35m2.1241\u001b[0m  1.2431\n","     10        \u001b[36m2.0290\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m1.9461\u001b[0m  1.2913\n","     11        \u001b[36m1.8509\u001b[0m       \u001b[32m0.7826\u001b[0m        \u001b[35m1.7702\u001b[0m  1.2477\n","     12        \u001b[36m1.6762\u001b[0m       \u001b[32m0.8154\u001b[0m        \u001b[35m1.6001\u001b[0m  1.2580\n","     13        \u001b[36m1.5085\u001b[0m       \u001b[32m0.8772\u001b[0m        \u001b[35m1.4401\u001b[0m  1.2607\n","     14        \u001b[36m1.3544\u001b[0m       \u001b[32m0.8866\u001b[0m        \u001b[35m1.2970\u001b[0m  1.2529\n","     15        \u001b[36m1.2182\u001b[0m       \u001b[32m0.8894\u001b[0m        \u001b[35m1.1714\u001b[0m  1.2549\n","     16        \u001b[36m1.0986\u001b[0m       0.8880        \u001b[35m1.0611\u001b[0m  1.2498\n","     17        \u001b[36m0.9934\u001b[0m       \u001b[32m0.8922\u001b[0m        \u001b[35m0.9643\u001b[0m  1.2538\n","     18        \u001b[36m0.9010\u001b[0m       \u001b[32m0.8988\u001b[0m        \u001b[35m0.8794\u001b[0m  1.2692\n","     19        \u001b[36m0.8196\u001b[0m       \u001b[32m0.9063\u001b[0m        \u001b[35m0.8045\u001b[0m  1.2617\n","     20        \u001b[36m0.7474\u001b[0m       \u001b[32m0.9222\u001b[0m        \u001b[35m0.7379\u001b[0m  1.2636\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9847\u001b[0m       \u001b[32m0.0492\u001b[0m        \u001b[35m2.9690\u001b[0m  1.2639\n","      2        \u001b[36m2.9531\u001b[0m       \u001b[32m0.0942\u001b[0m        \u001b[35m2.9351\u001b[0m  1.2800\n","      3        \u001b[36m2.9141\u001b[0m       \u001b[32m0.1462\u001b[0m        \u001b[35m2.8895\u001b[0m  1.2452\n","      4        \u001b[36m2.8594\u001b[0m       \u001b[32m0.1898\u001b[0m        \u001b[35m2.8245\u001b[0m  1.2515\n","      5        \u001b[36m2.7837\u001b[0m       \u001b[32m0.2549\u001b[0m        \u001b[35m2.7389\u001b[0m  1.2904\n","      6        \u001b[36m2.6903\u001b[0m       \u001b[32m0.3622\u001b[0m        \u001b[35m2.6400\u001b[0m  1.2799\n","      7        \u001b[36m2.5872\u001b[0m       \u001b[32m0.4311\u001b[0m        \u001b[35m2.5339\u001b[0m  1.2332\n","      8        \u001b[36m2.4737\u001b[0m       \u001b[32m0.4794\u001b[0m        \u001b[35m2.4134\u001b[0m  1.2533\n","      9        \u001b[36m2.3390\u001b[0m       \u001b[32m0.5825\u001b[0m        \u001b[35m2.2656\u001b[0m  1.2401\n","     10        \u001b[36m2.1727\u001b[0m       \u001b[32m0.6359\u001b[0m        \u001b[35m2.0844\u001b[0m  1.2468\n","     11        \u001b[36m1.9763\u001b[0m       \u001b[32m0.6645\u001b[0m        \u001b[35m1.8799\u001b[0m  1.3347\n","     12        \u001b[36m1.7693\u001b[0m       \u001b[32m0.7146\u001b[0m        \u001b[35m1.6789\u001b[0m  1.2618\n","     13        \u001b[36m1.5781\u001b[0m       \u001b[32m0.7573\u001b[0m        \u001b[35m1.5029\u001b[0m  1.2745\n","     14        \u001b[36m1.4135\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m1.3533\u001b[0m  1.2583\n","     15        \u001b[36m1.2722\u001b[0m       \u001b[32m0.8191\u001b[0m        \u001b[35m1.2239\u001b[0m  1.2556\n","     16        \u001b[36m1.1480\u001b[0m       \u001b[32m0.8491\u001b[0m        \u001b[35m1.1091\u001b[0m  1.2581\n","     17        \u001b[36m1.0367\u001b[0m       \u001b[32m0.8636\u001b[0m        \u001b[35m1.0053\u001b[0m  1.2591\n","     18        \u001b[36m0.9359\u001b[0m       \u001b[32m0.8641\u001b[0m        \u001b[35m0.9114\u001b[0m  1.2480\n","     19        \u001b[36m0.8453\u001b[0m       \u001b[32m0.8707\u001b[0m        \u001b[35m0.8275\u001b[0m  1.2423\n","     20        \u001b[36m0.7650\u001b[0m       \u001b[32m0.8749\u001b[0m        \u001b[35m0.7534\u001b[0m  1.2499\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9858\u001b[0m       \u001b[32m0.0520\u001b[0m        \u001b[35m2.9725\u001b[0m  1.3015\n","      2        \u001b[36m2.9566\u001b[0m       \u001b[32m0.0989\u001b[0m        \u001b[35m2.9396\u001b[0m  1.2480\n","      3        \u001b[36m2.9176\u001b[0m       \u001b[32m0.1931\u001b[0m        \u001b[35m2.8934\u001b[0m  1.2594\n","      4        \u001b[36m2.8620\u001b[0m       \u001b[32m0.2737\u001b[0m        \u001b[35m2.8277\u001b[0m  1.2473\n","      5        \u001b[36m2.7861\u001b[0m       \u001b[32m0.3266\u001b[0m        \u001b[35m2.7418\u001b[0m  1.2451\n","      6        \u001b[36m2.6926\u001b[0m       \u001b[32m0.3814\u001b[0m        \u001b[35m2.6414\u001b[0m  1.2525\n","      7        \u001b[36m2.5871\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m2.5309\u001b[0m  1.2648\n","      8        \u001b[36m2.4698\u001b[0m       \u001b[32m0.6396\u001b[0m        \u001b[35m2.4058\u001b[0m  1.2458\n","      9        \u001b[36m2.3331\u001b[0m       \u001b[32m0.7052\u001b[0m        \u001b[35m2.2590\u001b[0m  1.2920\n","     10        \u001b[36m2.1769\u001b[0m       \u001b[32m0.7451\u001b[0m        \u001b[35m2.0967\u001b[0m  1.2608\n","     11        \u001b[36m2.0122\u001b[0m       \u001b[32m0.7652\u001b[0m        \u001b[35m1.9307\u001b[0m  1.2625\n","     12        \u001b[36m1.8467\u001b[0m       \u001b[32m0.7798\u001b[0m        \u001b[35m1.7644\u001b[0m  1.2632\n","     13        \u001b[36m1.6785\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m1.5936\u001b[0m  1.2536\n","     14        \u001b[36m1.5085\u001b[0m       \u001b[32m0.8411\u001b[0m        \u001b[35m1.4256\u001b[0m  1.2388\n","     15        \u001b[36m1.3464\u001b[0m       \u001b[32m0.8721\u001b[0m        \u001b[35m1.2715\u001b[0m  1.3110\n","     16        \u001b[36m1.2026\u001b[0m       \u001b[32m0.8894\u001b[0m        \u001b[35m1.1390\u001b[0m  1.2859\n","     17        \u001b[36m1.0803\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m1.0278\u001b[0m  1.2243\n","     18        \u001b[36m0.9776\u001b[0m       \u001b[32m0.9030\u001b[0m        \u001b[35m0.9343\u001b[0m  1.2399\n","     19        \u001b[36m0.8904\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.8542\u001b[0m  1.2536\n","     20        \u001b[36m0.8146\u001b[0m       \u001b[32m0.9058\u001b[0m        \u001b[35m0.7836\u001b[0m  1.2566\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9913\u001b[0m       \u001b[32m0.0909\u001b[0m        \u001b[35m2.9817\u001b[0m  1.2550\n","      2        \u001b[36m2.9701\u001b[0m       \u001b[32m0.1518\u001b[0m        \u001b[35m2.9579\u001b[0m  1.2438\n","      3        \u001b[36m2.9410\u001b[0m       \u001b[32m0.3580\u001b[0m        \u001b[35m2.9247\u001b[0m  1.2499\n","      4        \u001b[36m2.9011\u001b[0m       \u001b[32m0.5426\u001b[0m        \u001b[35m2.8787\u001b[0m  1.2666\n","      5        \u001b[36m2.8450\u001b[0m       0.5234        \u001b[35m2.8130\u001b[0m  1.2494\n","      6        \u001b[36m2.7641\u001b[0m       0.4799        \u001b[35m2.7173\u001b[0m  1.2472\n","      7        \u001b[36m2.6464\u001b[0m       0.4686        \u001b[35m2.5802\u001b[0m  1.2340\n","      8        \u001b[36m2.4878\u001b[0m       0.5220        \u001b[35m2.4065\u001b[0m  1.2550\n","      9        \u001b[36m2.3007\u001b[0m       \u001b[32m0.6078\u001b[0m        \u001b[35m2.2125\u001b[0m  1.2441\n","     10        \u001b[36m2.1018\u001b[0m       \u001b[32m0.6781\u001b[0m        \u001b[35m2.0143\u001b[0m  1.2480\n","     11        \u001b[36m1.9057\u001b[0m       \u001b[32m0.7563\u001b[0m        \u001b[35m1.8244\u001b[0m  1.2273\n","     12        \u001b[36m1.7249\u001b[0m       \u001b[32m0.7737\u001b[0m        \u001b[35m1.6535\u001b[0m  1.2663\n","     13        \u001b[36m1.5629\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m1.5012\u001b[0m  1.2504\n","     14        \u001b[36m1.4185\u001b[0m       \u001b[32m0.8196\u001b[0m        \u001b[35m1.3658\u001b[0m  1.2537\n","     15        \u001b[36m1.2893\u001b[0m       \u001b[32m0.8608\u001b[0m        \u001b[35m1.2444\u001b[0m  1.2337\n","     16        \u001b[36m1.1726\u001b[0m       \u001b[32m0.8918\u001b[0m        \u001b[35m1.1340\u001b[0m  1.2302\n","     17        \u001b[36m1.0656\u001b[0m       \u001b[32m0.9138\u001b[0m        \u001b[35m1.0324\u001b[0m  1.2417\n","     18        \u001b[36m0.9669\u001b[0m       \u001b[32m0.9227\u001b[0m        \u001b[35m0.9389\u001b[0m  1.2338\n","     19        \u001b[36m0.8763\u001b[0m       \u001b[32m0.9325\u001b[0m        \u001b[35m0.8540\u001b[0m  1.2457\n","     20        \u001b[36m0.7948\u001b[0m       \u001b[32m0.9410\u001b[0m        \u001b[35m0.7783\u001b[0m  1.3342\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9886\u001b[0m       \u001b[32m0.0918\u001b[0m        \u001b[35m2.9781\u001b[0m  1.2649\n","      2        \u001b[36m2.9667\u001b[0m       \u001b[32m0.1481\u001b[0m        \u001b[35m2.9540\u001b[0m  1.2594\n","      3        \u001b[36m2.9384\u001b[0m       \u001b[32m0.2198\u001b[0m        \u001b[35m2.9215\u001b[0m  1.2441\n","      4        \u001b[36m2.8997\u001b[0m       \u001b[32m0.3130\u001b[0m        \u001b[35m2.8769\u001b[0m  1.2487\n","      5        \u001b[36m2.8451\u001b[0m       \u001b[32m0.4292\u001b[0m        \u001b[35m2.8123\u001b[0m  1.2513\n","      6        \u001b[36m2.7653\u001b[0m       \u001b[32m0.4831\u001b[0m        \u001b[35m2.7174\u001b[0m  1.2438\n","      7        \u001b[36m2.6508\u001b[0m       \u001b[32m0.5033\u001b[0m        \u001b[35m2.5853\u001b[0m  1.2779\n","      8        \u001b[36m2.5013\u001b[0m       \u001b[32m0.5178\u001b[0m        \u001b[35m2.4245\u001b[0m  1.2321\n","      9        \u001b[36m2.3345\u001b[0m       \u001b[32m0.6439\u001b[0m        \u001b[35m2.2578\u001b[0m  1.2370\n","     10        \u001b[36m2.1678\u001b[0m       \u001b[32m0.7395\u001b[0m        \u001b[35m2.0926\u001b[0m  1.2456\n","     11        \u001b[36m1.9988\u001b[0m       \u001b[32m0.7793\u001b[0m        \u001b[35m1.9215\u001b[0m  1.2309\n","     12        \u001b[36m1.8237\u001b[0m       \u001b[32m0.7868\u001b[0m        \u001b[35m1.7463\u001b[0m  1.2370\n","     13        \u001b[36m1.6484\u001b[0m       \u001b[32m0.8022\u001b[0m        \u001b[35m1.5757\u001b[0m  1.2434\n","     14        \u001b[36m1.4812\u001b[0m       \u001b[32m0.8238\u001b[0m        \u001b[35m1.4176\u001b[0m  1.2286\n","     15        \u001b[36m1.3294\u001b[0m       \u001b[32m0.8365\u001b[0m        \u001b[35m1.2779\u001b[0m  1.2739\n","     16        \u001b[36m1.1964\u001b[0m       \u001b[32m0.8477\u001b[0m        \u001b[35m1.1561\u001b[0m  1.2543\n","     17        \u001b[36m1.0798\u001b[0m       \u001b[32m0.8622\u001b[0m        \u001b[35m1.0492\u001b[0m  1.2365\n","     18        \u001b[36m0.9776\u001b[0m       \u001b[32m0.8739\u001b[0m        \u001b[35m0.9551\u001b[0m  1.2450\n","     19        \u001b[36m0.8877\u001b[0m       \u001b[32m0.8889\u001b[0m        \u001b[35m0.8719\u001b[0m  1.2480\n","     20        \u001b[36m0.8083\u001b[0m       \u001b[32m0.9072\u001b[0m        \u001b[35m0.7976\u001b[0m  1.2606\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9869\u001b[0m       \u001b[32m0.0923\u001b[0m        \u001b[35m2.9743\u001b[0m  1.3135\n","      2        \u001b[36m2.9596\u001b[0m       \u001b[32m0.1954\u001b[0m        \u001b[35m2.9438\u001b[0m  1.3615\n","      3        \u001b[36m2.9233\u001b[0m       \u001b[32m0.2868\u001b[0m        \u001b[35m2.9018\u001b[0m  1.3204\n","      4        \u001b[36m2.8716\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m2.8390\u001b[0m  1.2975\n","      5        \u001b[36m2.7932\u001b[0m       \u001b[32m0.3843\u001b[0m        \u001b[35m2.7449\u001b[0m  1.2578\n","      6        \u001b[36m2.6817\u001b[0m       \u001b[32m0.5037\u001b[0m        \u001b[35m2.6179\u001b[0m  1.2563\n","      7        \u001b[36m2.5428\u001b[0m       \u001b[32m0.5834\u001b[0m        \u001b[35m2.4708\u001b[0m  1.2546\n","      8        \u001b[36m2.3897\u001b[0m       \u001b[32m0.6532\u001b[0m        \u001b[35m2.3139\u001b[0m  1.2370\n","      9        \u001b[36m2.2301\u001b[0m       \u001b[32m0.6701\u001b[0m        \u001b[35m2.1526\u001b[0m  1.2619\n","     10        \u001b[36m2.0681\u001b[0m       \u001b[32m0.7067\u001b[0m        \u001b[35m1.9878\u001b[0m  1.2821\n","     11        \u001b[36m1.9007\u001b[0m       \u001b[32m0.7413\u001b[0m        \u001b[35m1.8160\u001b[0m  1.2697\n","     12        \u001b[36m1.7281\u001b[0m       \u001b[32m0.7769\u001b[0m        \u001b[35m1.6441\u001b[0m  1.2772\n","     13        \u001b[36m1.5612\u001b[0m       \u001b[32m0.8243\u001b[0m        \u001b[35m1.4843\u001b[0m  1.2603\n","     14        \u001b[36m1.4096\u001b[0m       \u001b[32m0.8482\u001b[0m        \u001b[35m1.3421\u001b[0m  1.3014\n","     15        \u001b[36m1.2758\u001b[0m       \u001b[32m0.8819\u001b[0m        \u001b[35m1.2168\u001b[0m  1.2707\n","     16        \u001b[36m1.1577\u001b[0m       \u001b[32m0.8993\u001b[0m        \u001b[35m1.1056\u001b[0m  1.2436\n","     17        \u001b[36m1.0522\u001b[0m       \u001b[32m0.9016\u001b[0m        \u001b[35m1.0051\u001b[0m  1.2421\n","     18        \u001b[36m0.9559\u001b[0m       \u001b[32m0.9035\u001b[0m        \u001b[35m0.9136\u001b[0m  1.2821\n","     19        \u001b[36m0.8688\u001b[0m       \u001b[32m0.9049\u001b[0m        \u001b[35m0.8312\u001b[0m  1.2471\n","     20        \u001b[36m0.7904\u001b[0m       \u001b[32m0.9105\u001b[0m        \u001b[35m0.7577\u001b[0m  1.2276\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9848\u001b[0m       \u001b[32m0.1514\u001b[0m        \u001b[35m2.9714\u001b[0m  1.2812\n","      2        \u001b[36m2.9556\u001b[0m       \u001b[32m0.1968\u001b[0m        \u001b[35m2.9394\u001b[0m  1.2465\n","      3        \u001b[36m2.9174\u001b[0m       \u001b[32m0.2826\u001b[0m        \u001b[35m2.8952\u001b[0m  1.2188\n","      4        \u001b[36m2.8631\u001b[0m       \u001b[32m0.3327\u001b[0m        \u001b[35m2.8312\u001b[0m  1.2367\n","      5        \u001b[36m2.7854\u001b[0m       \u001b[32m0.3632\u001b[0m        \u001b[35m2.7411\u001b[0m  1.2446\n","      6        \u001b[36m2.6800\u001b[0m       \u001b[32m0.3847\u001b[0m        \u001b[35m2.6230\u001b[0m  1.2581\n","      7        \u001b[36m2.5474\u001b[0m       \u001b[32m0.4747\u001b[0m        \u001b[35m2.4800\u001b[0m  1.2690\n","      8        \u001b[36m2.3930\u001b[0m       \u001b[32m0.6237\u001b[0m        \u001b[35m2.3193\u001b[0m  1.3473\n","      9        \u001b[36m2.2232\u001b[0m       \u001b[32m0.6809\u001b[0m        \u001b[35m2.1440\u001b[0m  1.2717\n","     10        \u001b[36m2.0374\u001b[0m       \u001b[32m0.7193\u001b[0m        \u001b[35m1.9520\u001b[0m  1.2383\n","     11        \u001b[36m1.8396\u001b[0m       \u001b[32m0.7587\u001b[0m        \u001b[35m1.7558\u001b[0m  1.2501\n","     12        \u001b[36m1.6491\u001b[0m       \u001b[32m0.7816\u001b[0m        \u001b[35m1.5763\u001b[0m  1.2424\n","     13        \u001b[36m1.4813\u001b[0m       \u001b[32m0.8074\u001b[0m        \u001b[35m1.4220\u001b[0m  1.2760\n","     14        \u001b[36m1.3378\u001b[0m       \u001b[32m0.8229\u001b[0m        \u001b[35m1.2903\u001b[0m  1.2437\n","     15        \u001b[36m1.2139\u001b[0m       \u001b[32m0.8650\u001b[0m        \u001b[35m1.1753\u001b[0m  1.2307\n","     16        \u001b[36m1.1041\u001b[0m       \u001b[32m0.8791\u001b[0m        \u001b[35m1.0724\u001b[0m  1.2413\n","     17        \u001b[36m1.0048\u001b[0m       \u001b[32m0.8875\u001b[0m        \u001b[35m0.9790\u001b[0m  1.2329\n","     18        \u001b[36m0.9146\u001b[0m       \u001b[32m0.8922\u001b[0m        \u001b[35m0.8945\u001b[0m  1.2385\n","     19        \u001b[36m0.8332\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.8185\u001b[0m  1.2302\n","     20        \u001b[36m0.7600\u001b[0m       \u001b[32m0.8960\u001b[0m        \u001b[35m0.7504\u001b[0m  1.2411\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9854\u001b[0m       \u001b[32m0.0914\u001b[0m        \u001b[35m2.9708\u001b[0m  1.2630\n","      2        \u001b[36m2.9551\u001b[0m       \u001b[32m0.2081\u001b[0m        \u001b[35m2.9384\u001b[0m  1.2353\n","      3        \u001b[36m2.9169\u001b[0m       \u001b[32m0.3013\u001b[0m        \u001b[35m2.8945\u001b[0m  1.2493\n","      4        \u001b[36m2.8644\u001b[0m       \u001b[32m0.3861\u001b[0m        \u001b[35m2.8336\u001b[0m  1.2402\n","      5        \u001b[36m2.7912\u001b[0m       \u001b[32m0.4428\u001b[0m        \u001b[35m2.7488\u001b[0m  1.2336\n","      6        \u001b[36m2.6914\u001b[0m       \u001b[32m0.4555\u001b[0m        \u001b[35m2.6357\u001b[0m  1.2271\n","      7        \u001b[36m2.5613\u001b[0m       \u001b[32m0.4681\u001b[0m        \u001b[35m2.4911\u001b[0m  1.2354\n","      8        \u001b[36m2.3998\u001b[0m       \u001b[32m0.4813\u001b[0m        \u001b[35m2.3167\u001b[0m  1.2369\n","      9        \u001b[36m2.2130\u001b[0m       \u001b[32m0.5370\u001b[0m        \u001b[35m2.1222\u001b[0m  1.2681\n","     10        \u001b[36m2.0132\u001b[0m       \u001b[32m0.6312\u001b[0m        \u001b[35m1.9223\u001b[0m  1.2382\n","     11        \u001b[36m1.8173\u001b[0m       \u001b[32m0.6781\u001b[0m        \u001b[35m1.7344\u001b[0m  1.2300\n","     12        \u001b[36m1.6377\u001b[0m       \u001b[32m0.7062\u001b[0m        \u001b[35m1.5648\u001b[0m  1.2940\n","     13        \u001b[36m1.4757\u001b[0m       \u001b[32m0.7329\u001b[0m        \u001b[35m1.4134\u001b[0m  1.3072\n","     14        \u001b[36m1.3303\u001b[0m       \u001b[32m0.7507\u001b[0m        \u001b[35m1.2784\u001b[0m  1.2277\n","     15        \u001b[36m1.2004\u001b[0m       \u001b[32m0.7680\u001b[0m        \u001b[35m1.1581\u001b[0m  1.2492\n","     16        \u001b[36m1.0844\u001b[0m       \u001b[32m0.7849\u001b[0m        \u001b[35m1.0511\u001b[0m  1.2338\n","     17        \u001b[36m0.9816\u001b[0m       \u001b[32m0.7999\u001b[0m        \u001b[35m0.9563\u001b[0m  1.2623\n","     18        \u001b[36m0.8907\u001b[0m       \u001b[32m0.8261\u001b[0m        \u001b[35m0.8724\u001b[0m  1.2415\n","     19        \u001b[36m0.8102\u001b[0m       \u001b[32m0.8636\u001b[0m        \u001b[35m0.7978\u001b[0m  1.2391\n","     20        \u001b[36m0.7388\u001b[0m       \u001b[32m0.8847\u001b[0m        \u001b[35m0.7313\u001b[0m  1.2472\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9899\u001b[0m       \u001b[32m0.0989\u001b[0m        \u001b[35m2.9799\u001b[0m  1.2509\n","      2        \u001b[36m2.9678\u001b[0m       \u001b[32m0.1251\u001b[0m        \u001b[35m2.9555\u001b[0m  1.2322\n","      3        \u001b[36m2.9387\u001b[0m       \u001b[32m0.1462\u001b[0m        \u001b[35m2.9215\u001b[0m  1.2411\n","      4        \u001b[36m2.8972\u001b[0m       \u001b[32m0.1659\u001b[0m        \u001b[35m2.8716\u001b[0m  1.2629\n","      5        \u001b[36m2.8366\u001b[0m       \u001b[32m0.2427\u001b[0m        \u001b[35m2.7998\u001b[0m  1.2428\n","      6        \u001b[36m2.7507\u001b[0m       \u001b[32m0.2938\u001b[0m        \u001b[35m2.6993\u001b[0m  1.2338\n","      7        \u001b[36m2.6338\u001b[0m       \u001b[32m0.3669\u001b[0m        \u001b[35m2.5673\u001b[0m  1.2419\n","      8        \u001b[36m2.4883\u001b[0m       \u001b[32m0.4672\u001b[0m        \u001b[35m2.4114\u001b[0m  1.2367\n","      9        \u001b[36m2.3256\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m2.2443\u001b[0m  1.2331\n","     10        \u001b[36m2.1564\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m2.0722\u001b[0m  1.2253\n","     11        \u001b[36m1.9831\u001b[0m       \u001b[32m0.7376\u001b[0m        \u001b[35m1.8971\u001b[0m  1.2272\n","     12        \u001b[36m1.8079\u001b[0m       \u001b[32m0.7666\u001b[0m        \u001b[35m1.7221\u001b[0m  1.2721\n","     13        \u001b[36m1.6347\u001b[0m       \u001b[32m0.8121\u001b[0m        \u001b[35m1.5527\u001b[0m  1.2418\n","     14        \u001b[36m1.4692\u001b[0m       \u001b[32m0.8327\u001b[0m        \u001b[35m1.3932\u001b[0m  1.2332\n","     15        \u001b[36m1.3168\u001b[0m       \u001b[32m0.8613\u001b[0m        \u001b[35m1.2486\u001b[0m  1.2385\n","     16        \u001b[36m1.1804\u001b[0m       \u001b[32m0.8650\u001b[0m        \u001b[35m1.1200\u001b[0m  1.2213\n","     17        \u001b[36m1.0597\u001b[0m       \u001b[32m0.8674\u001b[0m        \u001b[35m1.0071\u001b[0m  1.2978\n","     18        \u001b[36m0.9537\u001b[0m       \u001b[32m0.8786\u001b[0m        \u001b[35m0.9085\u001b[0m  1.2686\n","     19        \u001b[36m0.8610\u001b[0m       \u001b[32m0.8988\u001b[0m        \u001b[35m0.8225\u001b[0m  1.2305\n","     20        \u001b[36m0.7800\u001b[0m       \u001b[32m0.9110\u001b[0m        \u001b[35m0.7475\u001b[0m  1.2612\n","     21        \u001b[36m0.7092\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m0.6819\u001b[0m  1.2535\n","     22        \u001b[36m0.6470\u001b[0m       \u001b[32m0.9171\u001b[0m        \u001b[35m0.6244\u001b[0m  1.2344\n","     23        \u001b[36m0.5925\u001b[0m       \u001b[32m0.9203\u001b[0m        \u001b[35m0.5739\u001b[0m  1.2245\n","     24        \u001b[36m0.5447\u001b[0m       \u001b[32m0.9227\u001b[0m        \u001b[35m0.5295\u001b[0m  1.2169\n","     25        \u001b[36m0.5026\u001b[0m       \u001b[32m0.9246\u001b[0m        \u001b[35m0.4905\u001b[0m  1.2272\n","     26        \u001b[36m0.4656\u001b[0m       \u001b[32m0.9255\u001b[0m        \u001b[35m0.4560\u001b[0m  1.2303\n","     27        \u001b[36m0.4330\u001b[0m       \u001b[32m0.9269\u001b[0m        \u001b[35m0.4256\u001b[0m  1.2199\n","     28        \u001b[36m0.4042\u001b[0m       \u001b[32m0.9288\u001b[0m        \u001b[35m0.3988\u001b[0m  1.2492\n","     29        \u001b[36m0.3787\u001b[0m       \u001b[32m0.9297\u001b[0m        \u001b[35m0.3750\u001b[0m  1.2292\n","     30        \u001b[36m0.3560\u001b[0m       \u001b[32m0.9316\u001b[0m        \u001b[35m0.3538\u001b[0m  1.2241\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9870\u001b[0m       \u001b[32m0.2118\u001b[0m        \u001b[35m2.9751\u001b[0m  1.2313\n","      2        \u001b[36m2.9614\u001b[0m       \u001b[32m0.3116\u001b[0m        \u001b[35m2.9482\u001b[0m  1.2245\n","      3        \u001b[36m2.9295\u001b[0m       \u001b[32m0.3744\u001b[0m        \u001b[35m2.9119\u001b[0m  1.2368\n","      4        \u001b[36m2.8846\u001b[0m       0.3674        \u001b[35m2.8581\u001b[0m  1.2392\n","      5        \u001b[36m2.8161\u001b[0m       0.3168        \u001b[35m2.7760\u001b[0m  1.2542\n","      6        \u001b[36m2.7188\u001b[0m       0.3341        \u001b[35m2.6665\u001b[0m  1.2682\n","      7        \u001b[36m2.5969\u001b[0m       \u001b[32m0.4499\u001b[0m        \u001b[35m2.5372\u001b[0m  1.2391\n","      8        \u001b[36m2.4595\u001b[0m       \u001b[32m0.5726\u001b[0m        \u001b[35m2.3962\u001b[0m  1.2382\n","      9        \u001b[36m2.3126\u001b[0m       \u001b[32m0.6359\u001b[0m        \u001b[35m2.2462\u001b[0m  1.2812\n","     10        \u001b[36m2.1558\u001b[0m       \u001b[32m0.6715\u001b[0m        \u001b[35m2.0847\u001b[0m  1.2619\n","     11        \u001b[36m1.9879\u001b[0m       \u001b[32m0.7245\u001b[0m        \u001b[35m1.9134\u001b[0m  1.2711\n","     12        \u001b[36m1.8147\u001b[0m       \u001b[32m0.7638\u001b[0m        \u001b[35m1.7410\u001b[0m  1.3089\n","     13        \u001b[36m1.6454\u001b[0m       \u001b[32m0.8144\u001b[0m        \u001b[35m1.5774\u001b[0m  1.2671\n","     14        \u001b[36m1.4896\u001b[0m       \u001b[32m0.8561\u001b[0m        \u001b[35m1.4302\u001b[0m  1.2964\n","     15        \u001b[36m1.3504\u001b[0m       \u001b[32m0.8702\u001b[0m        \u001b[35m1.2991\u001b[0m  1.2392\n","     16        \u001b[36m1.2259\u001b[0m       \u001b[32m0.8782\u001b[0m        \u001b[35m1.1818\u001b[0m  1.2670\n","     17        \u001b[36m1.1132\u001b[0m       \u001b[32m0.8852\u001b[0m        \u001b[35m1.0756\u001b[0m  1.2484\n","     18        \u001b[36m1.0105\u001b[0m       \u001b[32m0.8889\u001b[0m        \u001b[35m0.9792\u001b[0m  1.2651\n","     19        \u001b[36m0.9172\u001b[0m       \u001b[32m0.8927\u001b[0m        \u001b[35m0.8919\u001b[0m  1.2332\n","     20        \u001b[36m0.8327\u001b[0m       \u001b[32m0.8950\u001b[0m        \u001b[35m0.8133\u001b[0m  1.2400\n","     21        \u001b[36m0.7565\u001b[0m       \u001b[32m0.8988\u001b[0m        \u001b[35m0.7427\u001b[0m  1.2526\n","     22        \u001b[36m0.6883\u001b[0m       \u001b[32m0.9025\u001b[0m        \u001b[35m0.6794\u001b[0m  1.2711\n","     23        \u001b[36m0.6273\u001b[0m       \u001b[32m0.9077\u001b[0m        \u001b[35m0.6231\u001b[0m  1.2761\n","     24        \u001b[36m0.5733\u001b[0m       \u001b[32m0.9128\u001b[0m        \u001b[35m0.5733\u001b[0m  1.2400\n","     25        \u001b[36m0.5256\u001b[0m       \u001b[32m0.9166\u001b[0m        \u001b[35m0.5295\u001b[0m  1.2407\n","     26        \u001b[36m0.4838\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m0.4910\u001b[0m  1.2565\n","     27        \u001b[36m0.4471\u001b[0m       \u001b[32m0.9213\u001b[0m        \u001b[35m0.4571\u001b[0m  1.2470\n","     28        \u001b[36m0.4149\u001b[0m       \u001b[32m0.9297\u001b[0m        \u001b[35m0.4274\u001b[0m  1.2386\n","     29        \u001b[36m0.3866\u001b[0m       \u001b[32m0.9381\u001b[0m        \u001b[35m0.4012\u001b[0m  1.2619\n","     30        \u001b[36m0.3615\u001b[0m       \u001b[32m0.9485\u001b[0m        \u001b[35m0.3780\u001b[0m  1.2567\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9894\u001b[0m       \u001b[32m0.0614\u001b[0m        \u001b[35m2.9754\u001b[0m  1.2448\n","      2        \u001b[36m2.9582\u001b[0m       \u001b[32m0.1495\u001b[0m        \u001b[35m2.9377\u001b[0m  1.2347\n","      3        \u001b[36m2.9106\u001b[0m       \u001b[32m0.2573\u001b[0m        \u001b[35m2.8792\u001b[0m  1.2376\n","      4        \u001b[36m2.8391\u001b[0m       \u001b[32m0.3229\u001b[0m        \u001b[35m2.7945\u001b[0m  1.2393\n","      5        \u001b[36m2.7406\u001b[0m       \u001b[32m0.3786\u001b[0m        \u001b[35m2.6846\u001b[0m  1.2361\n","      6        \u001b[36m2.6208\u001b[0m       \u001b[32m0.4513\u001b[0m        \u001b[35m2.5592\u001b[0m  1.2896\n","      7        \u001b[36m2.4876\u001b[0m       \u001b[32m0.5033\u001b[0m        \u001b[35m2.4224\u001b[0m  1.3093\n","      8        \u001b[36m2.3414\u001b[0m       \u001b[32m0.5595\u001b[0m        \u001b[35m2.2709\u001b[0m  1.2585\n","      9        \u001b[36m2.1802\u001b[0m       \u001b[32m0.5918\u001b[0m        \u001b[35m2.1054\u001b[0m  1.2312\n","     10        \u001b[36m2.0091\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m1.9334\u001b[0m  1.2342\n","     11        \u001b[36m1.8362\u001b[0m       \u001b[32m0.6439\u001b[0m        \u001b[35m1.7643\u001b[0m  1.2381\n","     12        \u001b[36m1.6714\u001b[0m       \u001b[32m0.6865\u001b[0m        \u001b[35m1.6084\u001b[0m  1.2431\n","     13        \u001b[36m1.5226\u001b[0m       \u001b[32m0.7306\u001b[0m        \u001b[35m1.4713\u001b[0m  1.2217\n","     14        \u001b[36m1.3923\u001b[0m       \u001b[32m0.7671\u001b[0m        \u001b[35m1.3525\u001b[0m  1.2243\n","     15        \u001b[36m1.2784\u001b[0m       \u001b[32m0.8083\u001b[0m        \u001b[35m1.2485\u001b[0m  1.2491\n","     16        \u001b[36m1.1776\u001b[0m       \u001b[32m0.8393\u001b[0m        \u001b[35m1.1554\u001b[0m  1.2414\n","     17        \u001b[36m1.0854\u001b[0m       \u001b[32m0.8543\u001b[0m        \u001b[35m1.0682\u001b[0m  1.2296\n","     18        \u001b[36m0.9974\u001b[0m       \u001b[32m0.8683\u001b[0m        \u001b[35m0.9839\u001b[0m  1.2385\n","     19        \u001b[36m0.9132\u001b[0m       \u001b[32m0.8843\u001b[0m        \u001b[35m0.9041\u001b[0m  1.2464\n","     20        \u001b[36m0.8344\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.8296\u001b[0m  1.2178\n","     21        \u001b[36m0.7617\u001b[0m       \u001b[32m0.9128\u001b[0m        \u001b[35m0.7611\u001b[0m  1.2249\n","     22        \u001b[36m0.6954\u001b[0m       \u001b[32m0.9255\u001b[0m        \u001b[35m0.6983\u001b[0m  1.2243\n","     23        \u001b[36m0.6350\u001b[0m       \u001b[32m0.9353\u001b[0m        \u001b[35m0.6410\u001b[0m  1.2684\n","     24        \u001b[36m0.5802\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m0.5889\u001b[0m  1.2253\n","     25        \u001b[36m0.5308\u001b[0m       \u001b[32m0.9442\u001b[0m        \u001b[35m0.5420\u001b[0m  1.2139\n","     26        \u001b[36m0.4867\u001b[0m       \u001b[32m0.9466\u001b[0m        \u001b[35m0.5002\u001b[0m  1.2324\n","     27        \u001b[36m0.4477\u001b[0m       \u001b[32m0.9499\u001b[0m        \u001b[35m0.4634\u001b[0m  1.2187\n","     28        \u001b[36m0.4134\u001b[0m       \u001b[32m0.9527\u001b[0m        \u001b[35m0.4309\u001b[0m  1.2147\n","     29        \u001b[36m0.3833\u001b[0m       \u001b[32m0.9578\u001b[0m        \u001b[35m0.4025\u001b[0m  1.2396\n","     30        \u001b[36m0.3568\u001b[0m       \u001b[32m0.9588\u001b[0m        \u001b[35m0.3776\u001b[0m  1.2241\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9871\u001b[0m       \u001b[32m0.0675\u001b[0m        \u001b[35m2.9750\u001b[0m  1.3296\n","      2        \u001b[36m2.9600\u001b[0m       \u001b[32m0.1012\u001b[0m        \u001b[35m2.9444\u001b[0m  1.2331\n","      3        \u001b[36m2.9234\u001b[0m       \u001b[32m0.1959\u001b[0m        \u001b[35m2.9017\u001b[0m  1.2230\n","      4        \u001b[36m2.8718\u001b[0m       \u001b[32m0.3219\u001b[0m        \u001b[35m2.8406\u001b[0m  1.2161\n","      5        \u001b[36m2.7978\u001b[0m       \u001b[32m0.5028\u001b[0m        \u001b[35m2.7530\u001b[0m  1.2454\n","      6        \u001b[36m2.6947\u001b[0m       \u001b[32m0.5187\u001b[0m        \u001b[35m2.6353\u001b[0m  1.2330\n","      7        \u001b[36m2.5641\u001b[0m       \u001b[32m0.5258\u001b[0m        \u001b[35m2.4931\u001b[0m  1.2115\n","      8        \u001b[36m2.4098\u001b[0m       \u001b[32m0.5792\u001b[0m        \u001b[35m2.3260\u001b[0m  1.2361\n","      9        \u001b[36m2.2253\u001b[0m       \u001b[32m0.6771\u001b[0m        \u001b[35m2.1256\u001b[0m  1.2655\n","     10        \u001b[36m2.0131\u001b[0m       \u001b[32m0.7498\u001b[0m        \u001b[35m1.9074\u001b[0m  1.2223\n","     11        \u001b[36m1.7986\u001b[0m       \u001b[32m0.7854\u001b[0m        \u001b[35m1.7012\u001b[0m  1.2206\n","     12        \u001b[36m1.6080\u001b[0m       \u001b[32m0.7971\u001b[0m        \u001b[35m1.5269\u001b[0m  1.2125\n","     13        \u001b[36m1.4509\u001b[0m       \u001b[32m0.8327\u001b[0m        \u001b[35m1.3847\u001b[0m  1.2322\n","     14        \u001b[36m1.3222\u001b[0m       \u001b[32m0.8814\u001b[0m        \u001b[35m1.2663\u001b[0m  1.2135\n","     15        \u001b[36m1.2127\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m1.1631\u001b[0m  1.2292\n","     16        \u001b[36m1.1147\u001b[0m       \u001b[32m0.8993\u001b[0m        \u001b[35m1.0689\u001b[0m  1.2378\n","     17        \u001b[36m1.0236\u001b[0m       \u001b[32m0.9002\u001b[0m        \u001b[35m0.9806\u001b[0m  1.2380\n","     18        \u001b[36m0.9378\u001b[0m       \u001b[32m0.9039\u001b[0m        \u001b[35m0.8979\u001b[0m  1.2156\n","     19        \u001b[36m0.8577\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.8217\u001b[0m  1.2171\n","     20        \u001b[36m0.7842\u001b[0m       \u001b[32m0.9077\u001b[0m        \u001b[35m0.7524\u001b[0m  1.2246\n","     21        \u001b[36m0.7173\u001b[0m       \u001b[32m0.9119\u001b[0m        \u001b[35m0.6896\u001b[0m  1.2350\n","     22        \u001b[36m0.6568\u001b[0m       \u001b[32m0.9147\u001b[0m        \u001b[35m0.6329\u001b[0m  1.2221\n","     23        \u001b[36m0.6023\u001b[0m       \u001b[32m0.9171\u001b[0m        \u001b[35m0.5819\u001b[0m  1.2357\n","     24        \u001b[36m0.5536\u001b[0m       \u001b[32m0.9208\u001b[0m        \u001b[35m0.5363\u001b[0m  1.2350\n","     25        \u001b[36m0.5102\u001b[0m       \u001b[32m0.9241\u001b[0m        \u001b[35m0.4958\u001b[0m  1.3022\n","     26        \u001b[36m0.4718\u001b[0m       \u001b[32m0.9335\u001b[0m        \u001b[35m0.4599\u001b[0m  1.2539\n","     27        \u001b[36m0.4377\u001b[0m       \u001b[32m0.9447\u001b[0m        \u001b[35m0.4281\u001b[0m  1.3230\n","     28        \u001b[36m0.4076\u001b[0m       \u001b[32m0.9578\u001b[0m        \u001b[35m0.3999\u001b[0m  1.2150\n","     29        \u001b[36m0.3807\u001b[0m       \u001b[32m0.9649\u001b[0m        \u001b[35m0.3748\u001b[0m  1.2469\n","     30        \u001b[36m0.3568\u001b[0m       \u001b[32m0.9672\u001b[0m        \u001b[35m0.3523\u001b[0m  1.2219\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9882\u001b[0m       \u001b[32m0.1139\u001b[0m        \u001b[35m2.9764\u001b[0m  1.2222\n","      2        \u001b[36m2.9635\u001b[0m       \u001b[32m0.2156\u001b[0m        \u001b[35m2.9504\u001b[0m  1.2515\n","      3        \u001b[36m2.9327\u001b[0m       \u001b[32m0.3440\u001b[0m        \u001b[35m2.9154\u001b[0m  1.2153\n","      4        \u001b[36m2.8902\u001b[0m       \u001b[32m0.4260\u001b[0m        \u001b[35m2.8656\u001b[0m  1.2151\n","      5        \u001b[36m2.8285\u001b[0m       \u001b[32m0.4564\u001b[0m        \u001b[35m2.7923\u001b[0m  1.2175\n","      6        \u001b[36m2.7382\u001b[0m       \u001b[32m0.4597\u001b[0m        \u001b[35m2.6855\u001b[0m  1.2053\n","      7        \u001b[36m2.6096\u001b[0m       \u001b[32m0.4822\u001b[0m        \u001b[35m2.5380\u001b[0m  1.2179\n","      8        \u001b[36m2.4411\u001b[0m       \u001b[32m0.5445\u001b[0m        \u001b[35m2.3539\u001b[0m  1.2261\n","      9        \u001b[36m2.2411\u001b[0m       \u001b[32m0.6813\u001b[0m        \u001b[35m2.1463\u001b[0m  1.2132\n","     10        \u001b[36m2.0315\u001b[0m       \u001b[32m0.7404\u001b[0m        \u001b[35m1.9424\u001b[0m  1.2719\n","     11        \u001b[36m1.8365\u001b[0m       \u001b[32m0.7690\u001b[0m        \u001b[35m1.7583\u001b[0m  1.2146\n","     12        \u001b[36m1.6617\u001b[0m       \u001b[32m0.7896\u001b[0m        \u001b[35m1.5925\u001b[0m  1.2162\n","     13        \u001b[36m1.5025\u001b[0m       \u001b[32m0.8308\u001b[0m        \u001b[35m1.4412\u001b[0m  1.2512\n","     14        \u001b[36m1.3563\u001b[0m       \u001b[32m0.8622\u001b[0m        \u001b[35m1.3029\u001b[0m  1.2199\n","     15        \u001b[36m1.2224\u001b[0m       \u001b[32m0.8768\u001b[0m        \u001b[35m1.1770\u001b[0m  1.2129\n","     16        \u001b[36m1.1009\u001b[0m       \u001b[32m0.8857\u001b[0m        \u001b[35m1.0637\u001b[0m  1.2068\n","     17        \u001b[36m0.9923\u001b[0m       \u001b[32m0.8927\u001b[0m        \u001b[35m0.9634\u001b[0m  1.2124\n","     18        \u001b[36m0.8967\u001b[0m       \u001b[32m0.8978\u001b[0m        \u001b[35m0.8754\u001b[0m  1.2140\n","     19        \u001b[36m0.8128\u001b[0m       \u001b[32m0.9016\u001b[0m        \u001b[35m0.7981\u001b[0m  1.2439\n","     20        \u001b[36m0.7390\u001b[0m       \u001b[32m0.9039\u001b[0m        \u001b[35m0.7298\u001b[0m  1.2183\n","     21        \u001b[36m0.6738\u001b[0m       0.9030        \u001b[35m0.6694\u001b[0m  1.2301\n","     22        \u001b[36m0.6161\u001b[0m       \u001b[32m0.9067\u001b[0m        \u001b[35m0.6159\u001b[0m  1.2821\n","     23        \u001b[36m0.5651\u001b[0m       \u001b[32m0.9114\u001b[0m        \u001b[35m0.5686\u001b[0m  1.2363\n","     24        \u001b[36m0.5201\u001b[0m       \u001b[32m0.9138\u001b[0m        \u001b[35m0.5268\u001b[0m  1.2207\n","     25        \u001b[36m0.4805\u001b[0m       \u001b[32m0.9180\u001b[0m        \u001b[35m0.4900\u001b[0m  1.2278\n","     26        \u001b[36m0.4456\u001b[0m       \u001b[32m0.9213\u001b[0m        \u001b[35m0.4576\u001b[0m  1.2230\n","     27        \u001b[36m0.4149\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.4291\u001b[0m  1.2358\n","     28        \u001b[36m0.3878\u001b[0m       \u001b[32m0.9330\u001b[0m        \u001b[35m0.4038\u001b[0m  1.2434\n","     29        \u001b[36m0.3637\u001b[0m       \u001b[32m0.9485\u001b[0m        \u001b[35m0.3812\u001b[0m  1.2588\n","     30        \u001b[36m0.3422\u001b[0m       \u001b[32m0.9592\u001b[0m        \u001b[35m0.3610\u001b[0m  1.2352\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9928\u001b[0m       \u001b[32m0.0815\u001b[0m        \u001b[35m2.9850\u001b[0m  1.2099\n","      2        \u001b[36m2.9771\u001b[0m       \u001b[32m0.1195\u001b[0m        \u001b[35m2.9668\u001b[0m  1.2334\n","      3        \u001b[36m2.9554\u001b[0m       \u001b[32m0.1542\u001b[0m        \u001b[35m2.9414\u001b[0m  1.2192\n","      4        \u001b[36m2.9244\u001b[0m       \u001b[32m0.2840\u001b[0m        \u001b[35m2.9041\u001b[0m  1.2519\n","      5        \u001b[36m2.8780\u001b[0m       \u001b[32m0.4185\u001b[0m        \u001b[35m2.8469\u001b[0m  1.2429\n","      6        \u001b[36m2.8081\u001b[0m       \u001b[32m0.4649\u001b[0m        \u001b[35m2.7635\u001b[0m  1.2279\n","      7        \u001b[36m2.7097\u001b[0m       \u001b[32m0.4827\u001b[0m        \u001b[35m2.6518\u001b[0m  1.2399\n","      8        \u001b[36m2.5864\u001b[0m       \u001b[32m0.5501\u001b[0m        \u001b[35m2.5214\u001b[0m  1.2273\n","      9        \u001b[36m2.4456\u001b[0m       \u001b[32m0.6017\u001b[0m        \u001b[35m2.3739\u001b[0m  1.2104\n","     10        \u001b[36m2.2830\u001b[0m       \u001b[32m0.6687\u001b[0m        \u001b[35m2.2019\u001b[0m  1.2156\n","     11        \u001b[36m2.0983\u001b[0m       \u001b[32m0.7095\u001b[0m        \u001b[35m2.0126\u001b[0m  1.2325\n","     12        \u001b[36m1.9053\u001b[0m       \u001b[32m0.7385\u001b[0m        \u001b[35m1.8226\u001b[0m  1.2453\n","     13        \u001b[36m1.7194\u001b[0m       \u001b[32m0.7573\u001b[0m        \u001b[35m1.6457\u001b[0m  1.2309\n","     14        \u001b[36m1.5489\u001b[0m       \u001b[32m0.7746\u001b[0m        \u001b[35m1.4848\u001b[0m  1.2150\n","     15        \u001b[36m1.3942\u001b[0m       \u001b[32m0.7802\u001b[0m        \u001b[35m1.3403\u001b[0m  1.2135\n","     16        \u001b[36m1.2565\u001b[0m       \u001b[32m0.7816\u001b[0m        \u001b[35m1.2131\u001b[0m  1.2364\n","     17        \u001b[36m1.1350\u001b[0m       \u001b[32m0.7905\u001b[0m        \u001b[35m1.1008\u001b[0m  1.2982\n","     18        \u001b[36m1.0276\u001b[0m       \u001b[32m0.7999\u001b[0m        \u001b[35m1.0017\u001b[0m  1.2223\n","     19        \u001b[36m0.9333\u001b[0m       \u001b[32m0.8140\u001b[0m        \u001b[35m0.9148\u001b[0m  1.2235\n","     20        \u001b[36m0.8510\u001b[0m       \u001b[32m0.8449\u001b[0m        \u001b[35m0.8388\u001b[0m  1.2469\n","     21        \u001b[36m0.7792\u001b[0m       \u001b[32m0.8791\u001b[0m        \u001b[35m0.7720\u001b[0m  1.2294\n","     22        \u001b[36m0.7161\u001b[0m       \u001b[32m0.8885\u001b[0m        \u001b[35m0.7128\u001b[0m  1.2301\n","     23        \u001b[36m0.6601\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.6597\u001b[0m  1.2269\n","     24        \u001b[36m0.6099\u001b[0m       \u001b[32m0.9011\u001b[0m        \u001b[35m0.6119\u001b[0m  1.2126\n","     25        \u001b[36m0.5648\u001b[0m       \u001b[32m0.9077\u001b[0m        \u001b[35m0.5688\u001b[0m  1.2667\n","     26        \u001b[36m0.5241\u001b[0m       \u001b[32m0.9082\u001b[0m        \u001b[35m0.5299\u001b[0m  1.2101\n","     27        \u001b[36m0.4874\u001b[0m       \u001b[32m0.9128\u001b[0m        \u001b[35m0.4947\u001b[0m  1.2264\n","     28        \u001b[36m0.4542\u001b[0m       \u001b[32m0.9180\u001b[0m        \u001b[35m0.4630\u001b[0m  1.2681\n","     29        \u001b[36m0.4243\u001b[0m       \u001b[32m0.9246\u001b[0m        \u001b[35m0.4343\u001b[0m  1.2236\n","     30        \u001b[36m0.3973\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m0.4085\u001b[0m  1.2272\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9901\u001b[0m       \u001b[32m0.1635\u001b[0m        \u001b[35m2.9767\u001b[0m  1.2441\n","      2        \u001b[36m2.9603\u001b[0m       \u001b[32m0.2409\u001b[0m        \u001b[35m2.9412\u001b[0m  1.2236\n","      3        \u001b[36m2.9173\u001b[0m       \u001b[32m0.2545\u001b[0m        \u001b[35m2.8891\u001b[0m  1.2368\n","      4        \u001b[36m2.8538\u001b[0m       \u001b[32m0.2816\u001b[0m        \u001b[35m2.8123\u001b[0m  1.2428\n","      5        \u001b[36m2.7638\u001b[0m       \u001b[32m0.3243\u001b[0m        \u001b[35m2.7088\u001b[0m  1.2232\n","      6        \u001b[36m2.6524\u001b[0m       \u001b[32m0.4466\u001b[0m        \u001b[35m2.5915\u001b[0m  1.2509\n","      7        \u001b[36m2.5323\u001b[0m       \u001b[32m0.5825\u001b[0m        \u001b[35m2.4678\u001b[0m  1.2669\n","      8        \u001b[36m2.4016\u001b[0m       \u001b[32m0.6710\u001b[0m        \u001b[35m2.3296\u001b[0m  1.2402\n","      9        \u001b[36m2.2530\u001b[0m       \u001b[32m0.7226\u001b[0m        \u001b[35m2.1714\u001b[0m  1.2417\n","     10        \u001b[36m2.0838\u001b[0m       \u001b[32m0.7502\u001b[0m        \u001b[35m1.9926\u001b[0m  1.2456\n","     11        \u001b[36m1.8988\u001b[0m       \u001b[32m0.7680\u001b[0m        \u001b[35m1.8033\u001b[0m  1.3183\n","     12        \u001b[36m1.7102\u001b[0m       \u001b[32m0.7938\u001b[0m        \u001b[35m1.6179\u001b[0m  1.2817\n","     13        \u001b[36m1.5313\u001b[0m       \u001b[32m0.8168\u001b[0m        \u001b[35m1.4470\u001b[0m  1.2447\n","     14        \u001b[36m1.3690\u001b[0m       \u001b[32m0.8322\u001b[0m        \u001b[35m1.2937\u001b[0m  1.2603\n","     15        \u001b[36m1.2243\u001b[0m       \u001b[32m0.8397\u001b[0m        \u001b[35m1.1570\u001b[0m  1.2417\n","     16        \u001b[36m1.0952\u001b[0m       \u001b[32m0.8491\u001b[0m        \u001b[35m1.0353\u001b[0m  1.2405\n","     17        \u001b[36m0.9815\u001b[0m       \u001b[32m0.8538\u001b[0m        \u001b[35m0.9299\u001b[0m  1.2480\n","     18        \u001b[36m0.8837\u001b[0m       \u001b[32m0.8585\u001b[0m        \u001b[35m0.8399\u001b[0m  1.2400\n","     19        \u001b[36m0.8002\u001b[0m       \u001b[32m0.8627\u001b[0m        \u001b[35m0.7632\u001b[0m  1.2354\n","     20        \u001b[36m0.7288\u001b[0m       \u001b[32m0.8702\u001b[0m        \u001b[35m0.6975\u001b[0m  1.2381\n","     21        \u001b[36m0.6674\u001b[0m       \u001b[32m0.8861\u001b[0m        \u001b[35m0.6408\u001b[0m  1.2526\n","     22        \u001b[36m0.6142\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.5914\u001b[0m  1.2395\n","     23        \u001b[36m0.5676\u001b[0m       \u001b[32m0.9400\u001b[0m        \u001b[35m0.5480\u001b[0m  1.2341\n","     24        \u001b[36m0.5264\u001b[0m       0.9391        \u001b[35m0.5094\u001b[0m  1.2400\n","     25        \u001b[36m0.4898\u001b[0m       0.9339        \u001b[35m0.4749\u001b[0m  1.2386\n","     26        \u001b[36m0.4569\u001b[0m       0.9330        \u001b[35m0.4439\u001b[0m  1.2192\n","     27        \u001b[36m0.4274\u001b[0m       0.9335        \u001b[35m0.4160\u001b[0m  1.2251\n","     28        \u001b[36m0.4008\u001b[0m       0.9344        \u001b[35m0.3909\u001b[0m  1.2314\n","     29        \u001b[36m0.3767\u001b[0m       0.9381        \u001b[35m0.3682\u001b[0m  1.2243\n","     30        \u001b[36m0.3550\u001b[0m       \u001b[32m0.9410\u001b[0m        \u001b[35m0.3477\u001b[0m  1.2508\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9874\u001b[0m       \u001b[32m0.1275\u001b[0m        \u001b[35m2.9766\u001b[0m  1.2230\n","      2        \u001b[36m2.9633\u001b[0m       \u001b[32m0.1500\u001b[0m        \u001b[35m2.9491\u001b[0m  1.2314\n","      3        \u001b[36m2.9301\u001b[0m       \u001b[32m0.1912\u001b[0m        \u001b[35m2.9113\u001b[0m  1.2283\n","      4        \u001b[36m2.8846\u001b[0m       \u001b[32m0.2521\u001b[0m        \u001b[35m2.8588\u001b[0m  1.2476\n","      5        \u001b[36m2.8209\u001b[0m       \u001b[32m0.3163\u001b[0m        \u001b[35m2.7845\u001b[0m  1.2131\n","      6        \u001b[36m2.7321\u001b[0m       \u001b[32m0.4072\u001b[0m        \u001b[35m2.6829\u001b[0m  1.3203\n","      7        \u001b[36m2.6160\u001b[0m       \u001b[32m0.4995\u001b[0m        \u001b[35m2.5554\u001b[0m  1.2765\n","      8        \u001b[36m2.4768\u001b[0m       \u001b[32m0.6251\u001b[0m        \u001b[35m2.4075\u001b[0m  1.2244\n","      9        \u001b[36m2.3168\u001b[0m       \u001b[32m0.6963\u001b[0m        \u001b[35m2.2380\u001b[0m  1.2346\n","     10        \u001b[36m2.1336\u001b[0m       \u001b[32m0.7296\u001b[0m        \u001b[35m2.0457\u001b[0m  1.2322\n","     11        \u001b[36m1.9306\u001b[0m       \u001b[32m0.7877\u001b[0m        \u001b[35m1.8392\u001b[0m  1.2234\n","     12        \u001b[36m1.7223\u001b[0m       \u001b[32m0.8257\u001b[0m        \u001b[35m1.6374\u001b[0m  1.2260\n","     13        \u001b[36m1.5301\u001b[0m       \u001b[32m0.8608\u001b[0m        \u001b[35m1.4607\u001b[0m  1.2313\n","     14        \u001b[36m1.3682\u001b[0m       \u001b[32m0.8768\u001b[0m        \u001b[35m1.3155\u001b[0m  1.2284\n","     15        \u001b[36m1.2354\u001b[0m       \u001b[32m0.8833\u001b[0m        \u001b[35m1.1949\u001b[0m  1.2710\n","     16        \u001b[36m1.1221\u001b[0m       \u001b[32m0.8880\u001b[0m        \u001b[35m1.0893\u001b[0m  1.2315\n","     17        \u001b[36m1.0207\u001b[0m       \u001b[32m0.8908\u001b[0m        \u001b[35m0.9935\u001b[0m  1.2249\n","     18        \u001b[36m0.9278\u001b[0m       \u001b[32m0.8969\u001b[0m        \u001b[35m0.9058\u001b[0m  1.2416\n","     19        \u001b[36m0.8431\u001b[0m       \u001b[32m0.8988\u001b[0m        \u001b[35m0.8265\u001b[0m  1.2331\n","     20        \u001b[36m0.7667\u001b[0m       \u001b[32m0.9011\u001b[0m        \u001b[35m0.7554\u001b[0m  1.2259\n","     21        \u001b[36m0.6984\u001b[0m       \u001b[32m0.9039\u001b[0m        \u001b[35m0.6918\u001b[0m  1.2280\n","     22        \u001b[36m0.6373\u001b[0m       \u001b[32m0.9072\u001b[0m        \u001b[35m0.6350\u001b[0m  1.2138\n","     23        \u001b[36m0.5828\u001b[0m       \u001b[32m0.9082\u001b[0m        \u001b[35m0.5844\u001b[0m  1.2596\n","     24        \u001b[36m0.5344\u001b[0m       \u001b[32m0.9114\u001b[0m        \u001b[35m0.5396\u001b[0m  1.2262\n","     25        \u001b[36m0.4916\u001b[0m       \u001b[32m0.9133\u001b[0m        \u001b[35m0.4999\u001b[0m  1.2257\n","     26        \u001b[36m0.4540\u001b[0m       \u001b[32m0.9171\u001b[0m        \u001b[35m0.4652\u001b[0m  1.2166\n","     27        \u001b[36m0.4210\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m0.4347\u001b[0m  1.2200\n","     28        \u001b[36m0.3922\u001b[0m       \u001b[32m0.9217\u001b[0m        \u001b[35m0.4079\u001b[0m  1.2418\n","     29        \u001b[36m0.3668\u001b[0m       \u001b[32m0.9264\u001b[0m        \u001b[35m0.3843\u001b[0m  1.2259\n","     30        \u001b[36m0.3443\u001b[0m       \u001b[32m0.9330\u001b[0m        \u001b[35m0.3633\u001b[0m  1.2335\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.9874\u001b[0m       \u001b[32m0.0834\u001b[0m        \u001b[35m2.9738\u001b[0m  1.3341\n","      2        \u001b[36m2.9576\u001b[0m       \u001b[32m0.2067\u001b[0m        \u001b[35m2.9387\u001b[0m  1.2659\n","      3        \u001b[36m2.9156\u001b[0m       \u001b[32m0.3102\u001b[0m        \u001b[35m2.8894\u001b[0m  1.2385\n","      4        \u001b[36m2.8564\u001b[0m       \u001b[32m0.4025\u001b[0m        \u001b[35m2.8191\u001b[0m  1.2512\n","      5        \u001b[36m2.7718\u001b[0m       \u001b[32m0.4574\u001b[0m        \u001b[35m2.7201\u001b[0m  1.2437\n","      6        \u001b[36m2.6581\u001b[0m       \u001b[32m0.5019\u001b[0m        \u001b[35m2.5949\u001b[0m  1.2308\n","      7        \u001b[36m2.5200\u001b[0m       \u001b[32m0.5305\u001b[0m        \u001b[35m2.4480\u001b[0m  1.2299\n","      8        \u001b[36m2.3601\u001b[0m       \u001b[32m0.6012\u001b[0m        \u001b[35m2.2804\u001b[0m  1.2263\n","      9        \u001b[36m2.1831\u001b[0m       0.6007        \u001b[35m2.1017\u001b[0m  1.2531\n","     10        \u001b[36m2.0060\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m1.9310\u001b[0m  1.2304\n","     11        \u001b[36m1.8414\u001b[0m       \u001b[32m0.6471\u001b[0m        \u001b[35m1.7730\u001b[0m  1.2515\n","     12        \u001b[36m1.6879\u001b[0m       \u001b[32m0.6748\u001b[0m        \u001b[35m1.6245\u001b[0m  1.2387\n","     13        \u001b[36m1.5421\u001b[0m       \u001b[32m0.7048\u001b[0m        \u001b[35m1.4839\u001b[0m  1.2325\n","     14        \u001b[36m1.4038\u001b[0m       \u001b[32m0.7512\u001b[0m        \u001b[35m1.3522\u001b[0m  1.2387\n","     15        \u001b[36m1.2747\u001b[0m       \u001b[32m0.7849\u001b[0m        \u001b[35m1.2309\u001b[0m  1.2421\n","     16        \u001b[36m1.1563\u001b[0m       \u001b[32m0.8121\u001b[0m        \u001b[35m1.1208\u001b[0m  1.2393\n","     17        \u001b[36m1.0497\u001b[0m       \u001b[32m0.8355\u001b[0m        \u001b[35m1.0224\u001b[0m  1.2568\n","     18        \u001b[36m0.9549\u001b[0m       \u001b[32m0.8510\u001b[0m        \u001b[35m0.9351\u001b[0m  1.2275\n","     19        \u001b[36m0.8710\u001b[0m       \u001b[32m0.8650\u001b[0m        \u001b[35m0.8575\u001b[0m  1.2286\n","     20        \u001b[36m0.7959\u001b[0m       \u001b[32m0.8744\u001b[0m        \u001b[35m0.7876\u001b[0m  1.2554\n","     21        \u001b[36m0.7288\u001b[0m       \u001b[32m0.8880\u001b[0m        \u001b[35m0.7251\u001b[0m  1.2302\n","     22        \u001b[36m0.6689\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.6689\u001b[0m  1.2281\n","     23        \u001b[36m0.6152\u001b[0m       \u001b[32m0.8993\u001b[0m        \u001b[35m0.6183\u001b[0m  1.2192\n","     24        \u001b[36m0.5671\u001b[0m       \u001b[32m0.9044\u001b[0m        \u001b[35m0.5730\u001b[0m  1.2226\n","     25        \u001b[36m0.5240\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m0.5323\u001b[0m  1.2522\n","     26        \u001b[36m0.4855\u001b[0m       \u001b[32m0.9138\u001b[0m        \u001b[35m0.4959\u001b[0m  1.2776\n","     27        \u001b[36m0.4511\u001b[0m       \u001b[32m0.9236\u001b[0m        \u001b[35m0.4632\u001b[0m  1.2476\n","     28        \u001b[36m0.4203\u001b[0m       \u001b[32m0.9339\u001b[0m        \u001b[35m0.4339\u001b[0m  1.2265\n","     29        \u001b[36m0.3927\u001b[0m       \u001b[32m0.9456\u001b[0m        \u001b[35m0.4075\u001b[0m  1.2257\n","     30        \u001b[36m0.3677\u001b[0m       \u001b[32m0.9522\u001b[0m        \u001b[35m0.3837\u001b[0m  1.2159\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6940\u001b[0m       \u001b[32m0.5455\u001b[0m        \u001b[35m2.0323\u001b[0m  1.2374\n","      2        \u001b[36m1.3249\u001b[0m       \u001b[32m0.7146\u001b[0m        \u001b[35m0.8899\u001b[0m  1.2618\n","      3        \u001b[36m0.5957\u001b[0m       \u001b[32m0.9058\u001b[0m        \u001b[35m0.4323\u001b[0m  1.2126\n","      4        \u001b[36m0.3093\u001b[0m       \u001b[32m0.9503\u001b[0m        \u001b[35m0.2492\u001b[0m  1.2341\n","      5        \u001b[36m0.2002\u001b[0m       \u001b[32m0.9667\u001b[0m        \u001b[35m0.1787\u001b[0m  1.2222\n","      6        \u001b[36m0.1446\u001b[0m       \u001b[32m0.9761\u001b[0m        \u001b[35m0.1385\u001b[0m  1.2359\n","      7        \u001b[36m0.1124\u001b[0m       \u001b[32m0.9784\u001b[0m        \u001b[35m0.1178\u001b[0m  1.2521\n","      8        \u001b[36m0.0922\u001b[0m       \u001b[32m0.9799\u001b[0m        \u001b[35m0.1064\u001b[0m  1.2782\n","      9        \u001b[36m0.0780\u001b[0m       \u001b[32m0.9803\u001b[0m        \u001b[35m0.0989\u001b[0m  1.2567\n","     10        \u001b[36m0.0671\u001b[0m       \u001b[32m0.9813\u001b[0m        \u001b[35m0.0935\u001b[0m  1.2648\n","     11        \u001b[36m0.0583\u001b[0m       \u001b[32m0.9827\u001b[0m        \u001b[35m0.0893\u001b[0m  1.2095\n","     12        \u001b[36m0.0509\u001b[0m       0.9817        \u001b[35m0.0861\u001b[0m  1.2209\n","     13        \u001b[36m0.0446\u001b[0m       0.9822        \u001b[35m0.0835\u001b[0m  1.2208\n","     14        \u001b[36m0.0392\u001b[0m       0.9822        \u001b[35m0.0814\u001b[0m  1.2226\n","     15        \u001b[36m0.0346\u001b[0m       0.9827        \u001b[35m0.0797\u001b[0m  1.2305\n","     16        \u001b[36m0.0306\u001b[0m       \u001b[32m0.9836\u001b[0m        \u001b[35m0.0784\u001b[0m  1.2099\n","     17        \u001b[36m0.0272\u001b[0m       \u001b[32m0.9841\u001b[0m        \u001b[35m0.0774\u001b[0m  1.2160\n","     18        \u001b[36m0.0243\u001b[0m       0.9836        \u001b[35m0.0766\u001b[0m  1.2405\n","     19        \u001b[36m0.0217\u001b[0m       0.9836        \u001b[35m0.0760\u001b[0m  1.2395\n","     20        \u001b[36m0.0196\u001b[0m       0.9836        \u001b[35m0.0756\u001b[0m  1.2228\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6479\u001b[0m       \u001b[32m0.5722\u001b[0m        \u001b[35m2.0316\u001b[0m  1.2965\n","      2        \u001b[36m1.3495\u001b[0m       \u001b[32m0.7577\u001b[0m        \u001b[35m0.8579\u001b[0m  1.2204\n","      3        \u001b[36m0.5896\u001b[0m       \u001b[32m0.9400\u001b[0m        \u001b[35m0.4011\u001b[0m  1.2283\n","      4        \u001b[36m0.2887\u001b[0m       \u001b[32m0.9705\u001b[0m        \u001b[35m0.2341\u001b[0m  1.2333\n","      5        \u001b[36m0.1767\u001b[0m       \u001b[32m0.9728\u001b[0m        \u001b[35m0.1742\u001b[0m  1.2185\n","      6        \u001b[36m0.1284\u001b[0m       \u001b[32m0.9752\u001b[0m        \u001b[35m0.1459\u001b[0m  1.2581\n","      7        \u001b[36m0.1021\u001b[0m       \u001b[32m0.9766\u001b[0m        \u001b[35m0.1304\u001b[0m  1.2282\n","      8        \u001b[36m0.0847\u001b[0m       \u001b[32m0.9784\u001b[0m        \u001b[35m0.1209\u001b[0m  1.2221\n","      9        \u001b[36m0.0720\u001b[0m       0.9775        \u001b[35m0.1148\u001b[0m  1.2427\n","     10        \u001b[36m0.0621\u001b[0m       0.9770        \u001b[35m0.1106\u001b[0m  1.2201\n","     11        \u001b[36m0.0539\u001b[0m       0.9780        \u001b[35m0.1077\u001b[0m  1.2218\n","     12        \u001b[36m0.0472\u001b[0m       0.9775        \u001b[35m0.1055\u001b[0m  1.2273\n","     13        \u001b[36m0.0416\u001b[0m       0.9780        \u001b[35m0.1039\u001b[0m  1.2394\n","     14        \u001b[36m0.0367\u001b[0m       0.9780        \u001b[35m0.1027\u001b[0m  1.2662\n","     15        \u001b[36m0.0326\u001b[0m       \u001b[32m0.9799\u001b[0m        \u001b[35m0.1019\u001b[0m  1.2166\n","     16        \u001b[36m0.0291\u001b[0m       0.9799        \u001b[35m0.1013\u001b[0m  1.2317\n","     17        \u001b[36m0.0260\u001b[0m       0.9799        \u001b[35m0.1010\u001b[0m  1.2305\n","     18        \u001b[36m0.0234\u001b[0m       0.9799        \u001b[35m0.1008\u001b[0m  1.2594\n","     19        \u001b[36m0.0211\u001b[0m       0.9794        0.1009  1.2631\n","     20        \u001b[36m0.0190\u001b[0m       0.9784        0.1010  1.2743\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6801\u001b[0m       \u001b[32m0.4316\u001b[0m        \u001b[35m2.1561\u001b[0m  1.2653\n","      2        \u001b[36m1.3559\u001b[0m       \u001b[32m0.7559\u001b[0m        \u001b[35m0.9418\u001b[0m  1.2391\n","      3        \u001b[36m0.5612\u001b[0m       \u001b[32m0.8636\u001b[0m        \u001b[35m0.4440\u001b[0m  1.2374\n","      4        \u001b[36m0.2956\u001b[0m       \u001b[32m0.9541\u001b[0m        \u001b[35m0.2676\u001b[0m  1.2355\n","      5        \u001b[36m0.1907\u001b[0m       \u001b[32m0.9644\u001b[0m        \u001b[35m0.1939\u001b[0m  1.3002\n","      6        \u001b[36m0.1396\u001b[0m       \u001b[32m0.9691\u001b[0m        \u001b[35m0.1584\u001b[0m  1.3048\n","      7        \u001b[36m0.1101\u001b[0m       \u001b[32m0.9728\u001b[0m        \u001b[35m0.1386\u001b[0m  1.2367\n","      8        \u001b[36m0.0909\u001b[0m       \u001b[32m0.9742\u001b[0m        \u001b[35m0.1263\u001b[0m  1.2454\n","      9        \u001b[36m0.0772\u001b[0m       \u001b[32m0.9747\u001b[0m        \u001b[35m0.1183\u001b[0m  1.3010\n","     10        \u001b[36m0.0666\u001b[0m       0.9747        \u001b[35m0.1127\u001b[0m  1.2614\n","     11        \u001b[36m0.0581\u001b[0m       \u001b[32m0.9752\u001b[0m        \u001b[35m0.1087\u001b[0m  1.2454\n","     12        \u001b[36m0.0510\u001b[0m       0.9742        \u001b[35m0.1057\u001b[0m  1.2480\n","     13        \u001b[36m0.0452\u001b[0m       0.9742        \u001b[35m0.1036\u001b[0m  1.2435\n","     14        \u001b[36m0.0402\u001b[0m       \u001b[32m0.9761\u001b[0m        \u001b[35m0.1020\u001b[0m  1.2652\n","     15        \u001b[36m0.0359\u001b[0m       \u001b[32m0.9770\u001b[0m        \u001b[35m0.1008\u001b[0m  1.2387\n","     16        \u001b[36m0.0322\u001b[0m       0.9770        \u001b[35m0.1000\u001b[0m  1.2574\n","     17        \u001b[36m0.0290\u001b[0m       \u001b[32m0.9775\u001b[0m        \u001b[35m0.0994\u001b[0m  1.2727\n","     18        \u001b[36m0.0262\u001b[0m       0.9770        \u001b[35m0.0989\u001b[0m  1.2804\n","     19        \u001b[36m0.0237\u001b[0m       0.9770        \u001b[35m0.0986\u001b[0m  1.2373\n","     20        \u001b[36m0.0216\u001b[0m       0.9770        \u001b[35m0.0985\u001b[0m  1.2493\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6632\u001b[0m       \u001b[32m0.4963\u001b[0m        \u001b[35m2.0725\u001b[0m  1.2437\n","      2        \u001b[36m1.3750\u001b[0m       \u001b[32m0.7591\u001b[0m        \u001b[35m0.8692\u001b[0m  1.2420\n","      3        \u001b[36m0.5569\u001b[0m       \u001b[32m0.9278\u001b[0m        \u001b[35m0.3723\u001b[0m  1.2275\n","      4        \u001b[36m0.2922\u001b[0m       \u001b[32m0.9653\u001b[0m        \u001b[35m0.2241\u001b[0m  1.2246\n","      5        \u001b[36m0.1895\u001b[0m       \u001b[32m0.9770\u001b[0m        \u001b[35m0.1571\u001b[0m  1.2680\n","      6        \u001b[36m0.1349\u001b[0m       \u001b[32m0.9808\u001b[0m        \u001b[35m0.1245\u001b[0m  1.2685\n","      7        \u001b[36m0.1050\u001b[0m       0.9808        \u001b[35m0.1076\u001b[0m  1.2321\n","      8        \u001b[36m0.0861\u001b[0m       \u001b[32m0.9817\u001b[0m        \u001b[35m0.0974\u001b[0m  1.2266\n","      9        \u001b[36m0.0727\u001b[0m       \u001b[32m0.9822\u001b[0m        \u001b[35m0.0905\u001b[0m  1.2388\n","     10        \u001b[36m0.0623\u001b[0m       \u001b[32m0.9827\u001b[0m        \u001b[35m0.0856\u001b[0m  1.3049\n","     11        \u001b[36m0.0540\u001b[0m       0.9827        \u001b[35m0.0819\u001b[0m  1.2535\n","     12        \u001b[36m0.0471\u001b[0m       0.9827        \u001b[35m0.0791\u001b[0m  1.2429\n","     13        \u001b[36m0.0413\u001b[0m       \u001b[32m0.9831\u001b[0m        \u001b[35m0.0768\u001b[0m  1.2642\n","     14        \u001b[36m0.0364\u001b[0m       0.9831        \u001b[35m0.0750\u001b[0m  1.2330\n","     15        \u001b[36m0.0321\u001b[0m       \u001b[32m0.9836\u001b[0m        \u001b[35m0.0735\u001b[0m  1.2344\n","     16        \u001b[36m0.0285\u001b[0m       0.9836        \u001b[35m0.0723\u001b[0m  1.2361\n","     17        \u001b[36m0.0254\u001b[0m       \u001b[32m0.9841\u001b[0m        \u001b[35m0.0713\u001b[0m  1.2468\n","     18        \u001b[36m0.0227\u001b[0m       0.9841        \u001b[35m0.0705\u001b[0m  1.2648\n","     19        \u001b[36m0.0203\u001b[0m       0.9841        \u001b[35m0.0699\u001b[0m  1.2342\n","     20        \u001b[36m0.0183\u001b[0m       0.9841        \u001b[35m0.0694\u001b[0m  1.2396\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7181\u001b[0m       \u001b[32m0.5586\u001b[0m        \u001b[35m2.1535\u001b[0m  1.2483\n","      2        \u001b[36m1.3856\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m0.9145\u001b[0m  1.2394\n","      3        \u001b[36m0.6030\u001b[0m       \u001b[32m0.9096\u001b[0m        \u001b[35m0.4008\u001b[0m  1.2432\n","      4        \u001b[36m0.3113\u001b[0m       \u001b[32m0.9691\u001b[0m        \u001b[35m0.2532\u001b[0m  1.2454\n","      5        \u001b[36m0.1979\u001b[0m       \u001b[32m0.9747\u001b[0m        \u001b[35m0.1875\u001b[0m  1.2227\n","      6        \u001b[36m0.1399\u001b[0m       \u001b[32m0.9756\u001b[0m        \u001b[35m0.1533\u001b[0m  1.2405\n","      7        \u001b[36m0.1085\u001b[0m       \u001b[32m0.9775\u001b[0m        \u001b[35m0.1347\u001b[0m  1.2494\n","      8        \u001b[36m0.0888\u001b[0m       \u001b[32m0.9789\u001b[0m        \u001b[35m0.1236\u001b[0m  1.2630\n","      9        \u001b[36m0.0750\u001b[0m       \u001b[32m0.9794\u001b[0m        \u001b[35m0.1164\u001b[0m  1.2389\n","     10        \u001b[36m0.0644\u001b[0m       0.9789        \u001b[35m0.1114\u001b[0m  1.2352\n","     11        \u001b[36m0.0560\u001b[0m       0.9789        \u001b[35m0.1077\u001b[0m  1.2271\n","     12        \u001b[36m0.0492\u001b[0m       0.9789        \u001b[35m0.1048\u001b[0m  1.2318\n","     13        \u001b[36m0.0435\u001b[0m       0.9794        \u001b[35m0.1026\u001b[0m  1.2422\n","     14        \u001b[36m0.0386\u001b[0m       0.9789        \u001b[35m0.1009\u001b[0m  1.2667\n","     15        \u001b[36m0.0345\u001b[0m       0.9784        \u001b[35m0.0996\u001b[0m  1.3002\n","     16        \u001b[36m0.0310\u001b[0m       0.9784        \u001b[35m0.0986\u001b[0m  1.2938\n","     17        \u001b[36m0.0279\u001b[0m       0.9780        \u001b[35m0.0980\u001b[0m  1.2300\n","     18        \u001b[36m0.0252\u001b[0m       0.9780        \u001b[35m0.0977\u001b[0m  1.2282\n","     19        \u001b[36m0.0228\u001b[0m       0.9780        \u001b[35m0.0975\u001b[0m  1.2551\n","     20        \u001b[36m0.0207\u001b[0m       0.9770        \u001b[35m0.0975\u001b[0m  1.2387\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7190\u001b[0m       \u001b[32m0.4531\u001b[0m        \u001b[35m2.1342\u001b[0m  1.2457\n","      2        \u001b[36m1.3764\u001b[0m       \u001b[32m0.7249\u001b[0m        \u001b[35m0.9878\u001b[0m  1.2141\n","      3        \u001b[36m0.5859\u001b[0m       \u001b[32m0.8777\u001b[0m        \u001b[35m0.4646\u001b[0m  1.2606\n","      4        \u001b[36m0.3057\u001b[0m       \u001b[32m0.9560\u001b[0m        \u001b[35m0.2709\u001b[0m  1.2462\n","      5        \u001b[36m0.1915\u001b[0m       \u001b[32m0.9700\u001b[0m        \u001b[35m0.1930\u001b[0m  1.2471\n","      6        \u001b[36m0.1377\u001b[0m       \u001b[32m0.9705\u001b[0m        \u001b[35m0.1585\u001b[0m  1.2401\n","      7        \u001b[36m0.1083\u001b[0m       \u001b[32m0.9733\u001b[0m        \u001b[35m0.1399\u001b[0m  1.2275\n","      8        \u001b[36m0.0892\u001b[0m       0.9733        \u001b[35m0.1274\u001b[0m  1.2189\n","      9        \u001b[36m0.0753\u001b[0m       \u001b[32m0.9756\u001b[0m        \u001b[35m0.1185\u001b[0m  1.2574\n","     10        \u001b[36m0.0647\u001b[0m       0.9756        \u001b[35m0.1119\u001b[0m  1.2232\n","     11        \u001b[36m0.0561\u001b[0m       \u001b[32m0.9766\u001b[0m        \u001b[35m0.1072\u001b[0m  1.2539\n","     12        \u001b[36m0.0491\u001b[0m       0.9761        \u001b[35m0.1039\u001b[0m  1.2279\n","     13        \u001b[36m0.0431\u001b[0m       0.9766        \u001b[35m0.1015\u001b[0m  1.2352\n","     14        \u001b[36m0.0381\u001b[0m       \u001b[32m0.9770\u001b[0m        \u001b[35m0.0999\u001b[0m  1.2223\n","     15        \u001b[36m0.0337\u001b[0m       0.9766        \u001b[35m0.0988\u001b[0m  1.2205\n","     16        \u001b[36m0.0299\u001b[0m       0.9766        \u001b[35m0.0981\u001b[0m  1.2378\n","     17        \u001b[36m0.0267\u001b[0m       0.9766        \u001b[35m0.0976\u001b[0m  1.2267\n","     18        \u001b[36m0.0239\u001b[0m       0.9770        \u001b[35m0.0974\u001b[0m  1.2442\n","     19        \u001b[36m0.0215\u001b[0m       \u001b[32m0.9775\u001b[0m        \u001b[35m0.0974\u001b[0m  1.3241\n","     20        \u001b[36m0.0194\u001b[0m       0.9775        0.0974  1.2917\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6838\u001b[0m       \u001b[32m0.5023\u001b[0m        \u001b[35m2.0488\u001b[0m  1.2561\n","      2        \u001b[36m1.3617\u001b[0m       \u001b[32m0.7118\u001b[0m        \u001b[35m0.8882\u001b[0m  1.2477\n","      3        \u001b[36m0.6089\u001b[0m       \u001b[32m0.9021\u001b[0m        \u001b[35m0.4210\u001b[0m  1.2426\n","      4        \u001b[36m0.3246\u001b[0m       \u001b[32m0.9686\u001b[0m        \u001b[35m0.2522\u001b[0m  1.2428\n","      5        \u001b[36m0.2114\u001b[0m       \u001b[32m0.9728\u001b[0m        \u001b[35m0.1810\u001b[0m  1.2377\n","      6        \u001b[36m0.1488\u001b[0m       \u001b[32m0.9766\u001b[0m        \u001b[35m0.1404\u001b[0m  1.2451\n","      7        \u001b[36m0.1134\u001b[0m       0.9766        \u001b[35m0.1188\u001b[0m  1.2661\n","      8        \u001b[36m0.0917\u001b[0m       \u001b[32m0.9784\u001b[0m        \u001b[35m0.1066\u001b[0m  1.2339\n","      9        \u001b[36m0.0767\u001b[0m       0.9784        \u001b[35m0.0991\u001b[0m  1.2443\n","     10        \u001b[36m0.0653\u001b[0m       0.9784        \u001b[35m0.0939\u001b[0m  1.2425\n","     11        \u001b[36m0.0562\u001b[0m       \u001b[32m0.9794\u001b[0m        \u001b[35m0.0901\u001b[0m  1.2278\n","     12        \u001b[36m0.0488\u001b[0m       \u001b[32m0.9799\u001b[0m        \u001b[35m0.0871\u001b[0m  1.2599\n","     13        \u001b[36m0.0426\u001b[0m       \u001b[32m0.9803\u001b[0m        \u001b[35m0.0847\u001b[0m  1.2186\n","     14        \u001b[36m0.0374\u001b[0m       0.9803        \u001b[35m0.0828\u001b[0m  1.2227\n","     15        \u001b[36m0.0329\u001b[0m       0.9799        \u001b[35m0.0813\u001b[0m  1.2582\n","     16        \u001b[36m0.0291\u001b[0m       0.9803        \u001b[35m0.0800\u001b[0m  1.2292\n","     17        \u001b[36m0.0258\u001b[0m       0.9794        \u001b[35m0.0790\u001b[0m  1.2281\n","     18        \u001b[36m0.0230\u001b[0m       0.9794        \u001b[35m0.0782\u001b[0m  1.2282\n","     19        \u001b[36m0.0206\u001b[0m       0.9799        \u001b[35m0.0775\u001b[0m  1.2357\n","     20        \u001b[36m0.0185\u001b[0m       0.9803        \u001b[35m0.0770\u001b[0m  1.2157\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7097\u001b[0m       \u001b[32m0.5253\u001b[0m        \u001b[35m2.0800\u001b[0m  1.2234\n","      2        \u001b[36m1.3401\u001b[0m       \u001b[32m0.7395\u001b[0m        \u001b[35m0.8655\u001b[0m  1.2702\n","      3        \u001b[36m0.6030\u001b[0m       \u001b[32m0.9264\u001b[0m        \u001b[35m0.4043\u001b[0m  1.2961\n","      4        \u001b[36m0.3110\u001b[0m       \u001b[32m0.9658\u001b[0m        \u001b[35m0.2513\u001b[0m  1.2634\n","      5        \u001b[36m0.1949\u001b[0m       \u001b[32m0.9728\u001b[0m        \u001b[35m0.1859\u001b[0m  1.2421\n","      6        \u001b[36m0.1394\u001b[0m       \u001b[32m0.9742\u001b[0m        \u001b[35m0.1523\u001b[0m  1.2279\n","      7        \u001b[36m0.1085\u001b[0m       \u001b[32m0.9761\u001b[0m        \u001b[35m0.1336\u001b[0m  1.2577\n","      8        \u001b[36m0.0887\u001b[0m       0.9761        \u001b[35m0.1223\u001b[0m  1.2686\n","      9        \u001b[36m0.0745\u001b[0m       \u001b[32m0.9770\u001b[0m        \u001b[35m0.1151\u001b[0m  1.2415\n","     10        \u001b[36m0.0637\u001b[0m       \u001b[32m0.9780\u001b[0m        \u001b[35m0.1101\u001b[0m  1.2536\n","     11        \u001b[36m0.0551\u001b[0m       \u001b[32m0.9789\u001b[0m        \u001b[35m0.1064\u001b[0m  1.2389\n","     12        \u001b[36m0.0481\u001b[0m       0.9780        \u001b[35m0.1035\u001b[0m  1.2639\n","     13        \u001b[36m0.0423\u001b[0m       0.9784        \u001b[35m0.1011\u001b[0m  1.2443\n","     14        \u001b[36m0.0374\u001b[0m       0.9775        \u001b[35m0.0990\u001b[0m  1.2709\n","     15        \u001b[36m0.0332\u001b[0m       0.9775        \u001b[35m0.0975\u001b[0m  1.2739\n","     16        \u001b[36m0.0296\u001b[0m       0.9770        \u001b[35m0.0963\u001b[0m  1.2662\n","     17        \u001b[36m0.0265\u001b[0m       0.9770        \u001b[35m0.0954\u001b[0m  1.2446\n","     18        \u001b[36m0.0238\u001b[0m       0.9775        \u001b[35m0.0948\u001b[0m  1.3121\n","     19        \u001b[36m0.0214\u001b[0m       0.9775        \u001b[35m0.0944\u001b[0m  1.2893\n","     20        \u001b[36m0.0193\u001b[0m       0.9770        \u001b[35m0.0942\u001b[0m  1.2690\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6350\u001b[0m       \u001b[32m0.4480\u001b[0m        \u001b[35m2.0007\u001b[0m  1.2576\n","      2        \u001b[36m1.2867\u001b[0m       \u001b[32m0.7376\u001b[0m        \u001b[35m0.9557\u001b[0m  1.2420\n","      3        \u001b[36m0.5882\u001b[0m       \u001b[32m0.8449\u001b[0m        \u001b[35m0.4736\u001b[0m  1.2453\n","      4        \u001b[36m0.3227\u001b[0m       \u001b[32m0.9583\u001b[0m        \u001b[35m0.2879\u001b[0m  1.2219\n","      5        \u001b[36m0.2136\u001b[0m       \u001b[32m0.9630\u001b[0m        \u001b[35m0.2096\u001b[0m  1.2441\n","      6        \u001b[36m0.1520\u001b[0m       \u001b[32m0.9709\u001b[0m        \u001b[35m0.1652\u001b[0m  1.2529\n","      7        \u001b[36m0.1166\u001b[0m       \u001b[32m0.9714\u001b[0m        \u001b[35m0.1436\u001b[0m  1.2464\n","      8        \u001b[36m0.0943\u001b[0m       \u001b[32m0.9728\u001b[0m        \u001b[35m0.1300\u001b[0m  1.3000\n","      9        \u001b[36m0.0789\u001b[0m       \u001b[32m0.9742\u001b[0m        \u001b[35m0.1206\u001b[0m  1.2605\n","     10        \u001b[36m0.0673\u001b[0m       \u001b[32m0.9756\u001b[0m        \u001b[35m0.1134\u001b[0m  1.2285\n","     11        \u001b[36m0.0583\u001b[0m       \u001b[32m0.9766\u001b[0m        \u001b[35m0.1079\u001b[0m  1.2456\n","     12        \u001b[36m0.0510\u001b[0m       \u001b[32m0.9775\u001b[0m        \u001b[35m0.1035\u001b[0m  1.2427\n","     13        \u001b[36m0.0448\u001b[0m       \u001b[32m0.9784\u001b[0m        \u001b[35m0.1002\u001b[0m  1.2489\n","     14        \u001b[36m0.0397\u001b[0m       0.9784        \u001b[35m0.0977\u001b[0m  1.2457\n","     15        \u001b[36m0.0352\u001b[0m       0.9784        \u001b[35m0.0959\u001b[0m  1.2513\n","     16        \u001b[36m0.0314\u001b[0m       0.9780        \u001b[35m0.0945\u001b[0m  1.2283\n","     17        \u001b[36m0.0281\u001b[0m       0.9780        \u001b[35m0.0935\u001b[0m  1.2291\n","     18        \u001b[36m0.0252\u001b[0m       0.9784        \u001b[35m0.0929\u001b[0m  1.2414\n","     19        \u001b[36m0.0227\u001b[0m       0.9780        \u001b[35m0.0924\u001b[0m  1.2415\n","     20        \u001b[36m0.0205\u001b[0m       0.9784        \u001b[35m0.0922\u001b[0m  1.2416\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6780\u001b[0m       \u001b[32m0.5464\u001b[0m        \u001b[35m1.9951\u001b[0m  1.2601\n","      2        \u001b[36m1.3129\u001b[0m       \u001b[32m0.7971\u001b[0m        \u001b[35m0.8500\u001b[0m  1.2231\n","      3        \u001b[36m0.5490\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.3928\u001b[0m  1.2308\n","      4        \u001b[36m0.2771\u001b[0m       \u001b[32m0.9733\u001b[0m        \u001b[35m0.2169\u001b[0m  1.2228\n","      5        \u001b[36m0.1757\u001b[0m       \u001b[32m0.9756\u001b[0m        \u001b[35m0.1534\u001b[0m  1.2266\n","      6        \u001b[36m0.1272\u001b[0m       \u001b[32m0.9770\u001b[0m        \u001b[35m0.1249\u001b[0m  1.2239\n","      7        \u001b[36m0.1007\u001b[0m       \u001b[32m0.9789\u001b[0m        \u001b[35m0.1094\u001b[0m  1.2124\n","      8        \u001b[36m0.0838\u001b[0m       \u001b[32m0.9803\u001b[0m        \u001b[35m0.0999\u001b[0m  1.2255\n","      9        \u001b[36m0.0714\u001b[0m       \u001b[32m0.9808\u001b[0m        \u001b[35m0.0936\u001b[0m  1.2551\n","     10        \u001b[36m0.0616\u001b[0m       \u001b[32m0.9813\u001b[0m        \u001b[35m0.0890\u001b[0m  1.2270\n","     11        \u001b[36m0.0535\u001b[0m       \u001b[32m0.9822\u001b[0m        \u001b[35m0.0855\u001b[0m  1.2195\n","     12        \u001b[36m0.0467\u001b[0m       \u001b[32m0.9827\u001b[0m        \u001b[35m0.0826\u001b[0m  1.2697\n","     13        \u001b[36m0.0408\u001b[0m       \u001b[32m0.9831\u001b[0m        \u001b[35m0.0803\u001b[0m  1.2680\n","     14        \u001b[36m0.0359\u001b[0m       \u001b[32m0.9836\u001b[0m        \u001b[35m0.0784\u001b[0m  1.2223\n","     15        \u001b[36m0.0316\u001b[0m       \u001b[32m0.9841\u001b[0m        \u001b[35m0.0769\u001b[0m  1.2157\n","     16        \u001b[36m0.0279\u001b[0m       \u001b[32m0.9845\u001b[0m        \u001b[35m0.0758\u001b[0m  1.2328\n","     17        \u001b[36m0.0248\u001b[0m       0.9836        \u001b[35m0.0749\u001b[0m  1.2569\n","     18        \u001b[36m0.0221\u001b[0m       0.9836        \u001b[35m0.0742\u001b[0m  1.2275\n","     19        \u001b[36m0.0197\u001b[0m       0.9841        \u001b[35m0.0737\u001b[0m  1.2117\n","     20        \u001b[36m0.0177\u001b[0m       0.9836        \u001b[35m0.0733\u001b[0m  1.2415\n","     21        \u001b[36m0.0160\u001b[0m       0.9836        \u001b[35m0.0730\u001b[0m  1.2367\n","     22        \u001b[36m0.0145\u001b[0m       0.9836        \u001b[35m0.0728\u001b[0m  1.2368\n","     23        \u001b[36m0.0132\u001b[0m       0.9836        \u001b[35m0.0727\u001b[0m  1.2393\n","     24        \u001b[36m0.0121\u001b[0m       0.9836        \u001b[35m0.0726\u001b[0m  1.2358\n","     25        \u001b[36m0.0112\u001b[0m       0.9836        \u001b[35m0.0725\u001b[0m  1.2528\n","     26        \u001b[36m0.0103\u001b[0m       0.9841        \u001b[35m0.0725\u001b[0m  1.2405\n","     27        \u001b[36m0.0096\u001b[0m       0.9845        0.0725  1.2229\n","     28        \u001b[36m0.0089\u001b[0m       0.9841        0.0726  1.2227\n","     29        \u001b[36m0.0084\u001b[0m       0.9841        0.0726  1.2274\n","     30        \u001b[36m0.0079\u001b[0m       0.9841        0.0727  1.2238\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6711\u001b[0m       \u001b[32m0.6167\u001b[0m        \u001b[35m1.9795\u001b[0m  1.2271\n","      2        \u001b[36m1.2850\u001b[0m       \u001b[32m0.7765\u001b[0m        \u001b[35m0.8377\u001b[0m  1.2277\n","      3        \u001b[36m0.5710\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m0.3880\u001b[0m  1.2599\n","      4        \u001b[36m0.2992\u001b[0m       \u001b[32m0.9691\u001b[0m        \u001b[35m0.2536\u001b[0m  1.2428\n","      5        \u001b[36m0.1974\u001b[0m       \u001b[32m0.9728\u001b[0m        \u001b[35m0.1900\u001b[0m  1.2219\n","      6        \u001b[36m0.1427\u001b[0m       \u001b[32m0.9742\u001b[0m        \u001b[35m0.1546\u001b[0m  1.2306\n","      7        \u001b[36m0.1105\u001b[0m       \u001b[32m0.9761\u001b[0m        \u001b[35m0.1343\u001b[0m  1.2799\n","      8        \u001b[36m0.0897\u001b[0m       \u001b[32m0.9780\u001b[0m        \u001b[35m0.1219\u001b[0m  1.2521\n","      9        \u001b[36m0.0748\u001b[0m       \u001b[32m0.9794\u001b[0m        \u001b[35m0.1136\u001b[0m  1.2367\n","     10        \u001b[36m0.0636\u001b[0m       0.9780        \u001b[35m0.1078\u001b[0m  1.2388\n","     11        \u001b[36m0.0549\u001b[0m       0.9780        \u001b[35m0.1034\u001b[0m  1.2645\n","     12        \u001b[36m0.0479\u001b[0m       0.9770        \u001b[35m0.0998\u001b[0m  1.2377\n","     13        \u001b[36m0.0421\u001b[0m       0.9770        \u001b[35m0.0969\u001b[0m  1.2359\n","     14        \u001b[36m0.0372\u001b[0m       0.9766        \u001b[35m0.0945\u001b[0m  1.2307\n","     15        \u001b[36m0.0331\u001b[0m       0.9766        \u001b[35m0.0927\u001b[0m  1.2410\n","     16        \u001b[36m0.0295\u001b[0m       0.9770        \u001b[35m0.0912\u001b[0m  1.2249\n","     17        \u001b[36m0.0265\u001b[0m       0.9775        \u001b[35m0.0902\u001b[0m  1.2234\n","     18        \u001b[36m0.0238\u001b[0m       0.9775        \u001b[35m0.0894\u001b[0m  1.2265\n","     19        \u001b[36m0.0215\u001b[0m       0.9780        \u001b[35m0.0888\u001b[0m  1.2515\n","     20        \u001b[36m0.0195\u001b[0m       0.9780        \u001b[35m0.0885\u001b[0m  1.2339\n","     21        \u001b[36m0.0177\u001b[0m       0.9784        \u001b[35m0.0883\u001b[0m  1.2263\n","     22        \u001b[36m0.0162\u001b[0m       0.9789        \u001b[35m0.0881\u001b[0m  1.2277\n","     23        \u001b[36m0.0149\u001b[0m       0.9789        \u001b[35m0.0880\u001b[0m  1.2091\n","     24        \u001b[36m0.0137\u001b[0m       0.9789        \u001b[35m0.0879\u001b[0m  1.2160\n","     25        \u001b[36m0.0127\u001b[0m       0.9789        0.0880  1.2192\n","     26        \u001b[36m0.0118\u001b[0m       0.9794        0.0880  1.2251\n","     27        \u001b[36m0.0110\u001b[0m       0.9794        0.0881  1.2626\n","     28        \u001b[36m0.0104\u001b[0m       0.9789        0.0882  1.2262\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6704\u001b[0m       \u001b[32m0.4700\u001b[0m        \u001b[35m2.0567\u001b[0m  1.2471\n","      2        \u001b[36m1.2887\u001b[0m       \u001b[32m0.7132\u001b[0m        \u001b[35m0.9711\u001b[0m  1.2453\n","      3        \u001b[36m0.5668\u001b[0m       \u001b[32m0.8819\u001b[0m        \u001b[35m0.4448\u001b[0m  1.3297\n","      4        \u001b[36m0.3003\u001b[0m       \u001b[32m0.9517\u001b[0m        \u001b[35m0.2688\u001b[0m  1.2556\n","      5        \u001b[36m0.1975\u001b[0m       \u001b[32m0.9620\u001b[0m        \u001b[35m0.1999\u001b[0m  1.2596\n","      6        \u001b[36m0.1410\u001b[0m       \u001b[32m0.9691\u001b[0m        \u001b[35m0.1612\u001b[0m  1.2168\n","      7        \u001b[36m0.1100\u001b[0m       \u001b[32m0.9733\u001b[0m        \u001b[35m0.1416\u001b[0m  1.2200\n","      8        \u001b[36m0.0901\u001b[0m       \u001b[32m0.9766\u001b[0m        \u001b[35m0.1284\u001b[0m  1.2285\n","      9        \u001b[36m0.0758\u001b[0m       \u001b[32m0.9780\u001b[0m        \u001b[35m0.1193\u001b[0m  1.2172\n","     10        \u001b[36m0.0649\u001b[0m       0.9780        \u001b[35m0.1128\u001b[0m  1.2137\n","     11        \u001b[36m0.0562\u001b[0m       0.9770        \u001b[35m0.1082\u001b[0m  1.2402\n","     12        \u001b[36m0.0491\u001b[0m       \u001b[32m0.9789\u001b[0m        \u001b[35m0.1049\u001b[0m  1.2404\n","     13        \u001b[36m0.0432\u001b[0m       0.9784        \u001b[35m0.1025\u001b[0m  1.2769\n","     14        \u001b[36m0.0381\u001b[0m       0.9789        \u001b[35m0.1008\u001b[0m  1.2405\n","     15        \u001b[36m0.0338\u001b[0m       \u001b[32m0.9794\u001b[0m        \u001b[35m0.0993\u001b[0m  1.2481\n","     16        \u001b[36m0.0301\u001b[0m       0.9789        \u001b[35m0.0982\u001b[0m  1.2281\n","     17        \u001b[36m0.0268\u001b[0m       0.9789        \u001b[35m0.0974\u001b[0m  1.2324\n","     18        \u001b[36m0.0240\u001b[0m       0.9784        \u001b[35m0.0967\u001b[0m  1.2083\n","     19        \u001b[36m0.0216\u001b[0m       0.9784        \u001b[35m0.0962\u001b[0m  1.2382\n","     20        \u001b[36m0.0196\u001b[0m       0.9784        \u001b[35m0.0958\u001b[0m  1.2335\n","     21        \u001b[36m0.0178\u001b[0m       0.9789        \u001b[35m0.0956\u001b[0m  1.2589\n","     22        \u001b[36m0.0163\u001b[0m       0.9794        \u001b[35m0.0954\u001b[0m  1.2330\n","     23        \u001b[36m0.0150\u001b[0m       \u001b[32m0.9799\u001b[0m        \u001b[35m0.0954\u001b[0m  1.2536\n","     24        \u001b[36m0.0138\u001b[0m       0.9799        0.0954  1.2345\n","     25        \u001b[36m0.0128\u001b[0m       0.9799        0.0954  1.2173\n","     26        \u001b[36m0.0119\u001b[0m       0.9799        0.0955  1.2244\n","     27        \u001b[36m0.0111\u001b[0m       0.9794        0.0956  1.2093\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6767\u001b[0m       \u001b[32m0.6167\u001b[0m        \u001b[35m1.9715\u001b[0m  1.2803\n","      2        \u001b[36m1.2713\u001b[0m       \u001b[32m0.7324\u001b[0m        \u001b[35m0.8602\u001b[0m  1.2343\n","      3        \u001b[36m0.5440\u001b[0m       \u001b[32m0.8880\u001b[0m        \u001b[35m0.3932\u001b[0m  1.2218\n","      4        \u001b[36m0.2817\u001b[0m       \u001b[32m0.9705\u001b[0m        \u001b[35m0.2233\u001b[0m  1.2180\n","      5        \u001b[36m0.1821\u001b[0m       \u001b[32m0.9766\u001b[0m        \u001b[35m0.1569\u001b[0m  1.2199\n","      6        \u001b[36m0.1312\u001b[0m       \u001b[32m0.9799\u001b[0m        \u001b[35m0.1266\u001b[0m  1.2124\n","      7        \u001b[36m0.1035\u001b[0m       \u001b[32m0.9803\u001b[0m        \u001b[35m0.1096\u001b[0m  1.2247\n","      8        \u001b[36m0.0858\u001b[0m       \u001b[32m0.9817\u001b[0m        \u001b[35m0.0989\u001b[0m  1.2082\n","      9        \u001b[36m0.0730\u001b[0m       \u001b[32m0.9822\u001b[0m        \u001b[35m0.0914\u001b[0m  1.2384\n","     10        \u001b[36m0.0630\u001b[0m       \u001b[32m0.9831\u001b[0m        \u001b[35m0.0860\u001b[0m  1.2173\n","     11        \u001b[36m0.0549\u001b[0m       0.9831        \u001b[35m0.0820\u001b[0m  1.2049\n","     12        \u001b[36m0.0482\u001b[0m       \u001b[32m0.9841\u001b[0m        \u001b[35m0.0790\u001b[0m  1.2296\n","     13        \u001b[36m0.0424\u001b[0m       0.9841        \u001b[35m0.0766\u001b[0m  1.2135\n","     14        \u001b[36m0.0375\u001b[0m       \u001b[32m0.9845\u001b[0m        \u001b[35m0.0747\u001b[0m  1.2173\n","     15        \u001b[36m0.0332\u001b[0m       \u001b[32m0.9850\u001b[0m        \u001b[35m0.0733\u001b[0m  1.2216\n","     16        \u001b[36m0.0295\u001b[0m       0.9850        \u001b[35m0.0721\u001b[0m  1.2175\n","     17        \u001b[36m0.0263\u001b[0m       0.9845        \u001b[35m0.0712\u001b[0m  1.2520\n","     18        \u001b[36m0.0235\u001b[0m       0.9845        \u001b[35m0.0704\u001b[0m  1.2374\n","     19        \u001b[36m0.0211\u001b[0m       0.9845        \u001b[35m0.0698\u001b[0m  1.2374\n","     20        \u001b[36m0.0189\u001b[0m       0.9845        \u001b[35m0.0694\u001b[0m  1.2255\n","     21        \u001b[36m0.0171\u001b[0m       0.9845        \u001b[35m0.0691\u001b[0m  1.2124\n","     22        \u001b[36m0.0154\u001b[0m       0.9850        \u001b[35m0.0688\u001b[0m  1.2294\n","     23        \u001b[36m0.0140\u001b[0m       0.9850        \u001b[35m0.0686\u001b[0m  1.2391\n","     24        \u001b[36m0.0128\u001b[0m       \u001b[32m0.9855\u001b[0m        \u001b[35m0.0685\u001b[0m  1.2201\n","     25        \u001b[36m0.0117\u001b[0m       0.9855        \u001b[35m0.0684\u001b[0m  1.2517\n","     26        \u001b[36m0.0108\u001b[0m       0.9855        \u001b[35m0.0683\u001b[0m  1.3077\n","     27        \u001b[36m0.0100\u001b[0m       0.9855        \u001b[35m0.0683\u001b[0m  1.2203\n","     28        \u001b[36m0.0093\u001b[0m       0.9855        \u001b[35m0.0683\u001b[0m  1.2175\n","     29        \u001b[36m0.0086\u001b[0m       0.9855        0.0683  1.2169\n","     30        \u001b[36m0.0081\u001b[0m       0.9855        0.0683  1.2226\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7626\u001b[0m       \u001b[32m0.5487\u001b[0m        \u001b[35m2.2703\u001b[0m  1.2288\n","      2        \u001b[36m1.4601\u001b[0m       \u001b[32m0.7273\u001b[0m        \u001b[35m0.9189\u001b[0m  1.2195\n","      3        \u001b[36m0.6318\u001b[0m       \u001b[32m0.8918\u001b[0m        \u001b[35m0.4459\u001b[0m  1.2511\n","      4        \u001b[36m0.3200\u001b[0m       \u001b[32m0.9606\u001b[0m        \u001b[35m0.2580\u001b[0m  1.2237\n","      5        \u001b[36m0.1980\u001b[0m       \u001b[32m0.9672\u001b[0m        \u001b[35m0.1867\u001b[0m  1.2302\n","      6        \u001b[36m0.1419\u001b[0m       \u001b[32m0.9714\u001b[0m        \u001b[35m0.1511\u001b[0m  1.2185\n","      7        \u001b[36m0.1107\u001b[0m       \u001b[32m0.9724\u001b[0m        \u001b[35m0.1313\u001b[0m  1.2282\n","      8        \u001b[36m0.0907\u001b[0m       \u001b[32m0.9742\u001b[0m        \u001b[35m0.1192\u001b[0m  1.2288\n","      9        \u001b[36m0.0763\u001b[0m       \u001b[32m0.9761\u001b[0m        \u001b[35m0.1112\u001b[0m  1.2266\n","     10        \u001b[36m0.0655\u001b[0m       \u001b[32m0.9770\u001b[0m        \u001b[35m0.1056\u001b[0m  1.2241\n","     11        \u001b[36m0.0568\u001b[0m       0.9770        \u001b[35m0.1015\u001b[0m  1.2549\n","     12        \u001b[36m0.0498\u001b[0m       0.9761        \u001b[35m0.0983\u001b[0m  1.2470\n","     13        \u001b[36m0.0439\u001b[0m       0.9770        \u001b[35m0.0959\u001b[0m  1.2141\n","     14        \u001b[36m0.0389\u001b[0m       \u001b[32m0.9775\u001b[0m        \u001b[35m0.0941\u001b[0m  1.2261\n","     15        \u001b[36m0.0347\u001b[0m       0.9775        \u001b[35m0.0926\u001b[0m  1.2254\n","     16        \u001b[36m0.0311\u001b[0m       \u001b[32m0.9780\u001b[0m        \u001b[35m0.0916\u001b[0m  1.2302\n","     17        \u001b[36m0.0280\u001b[0m       0.9780        \u001b[35m0.0908\u001b[0m  1.2305\n","     18        \u001b[36m0.0252\u001b[0m       \u001b[32m0.9784\u001b[0m        \u001b[35m0.0903\u001b[0m  1.2266\n","     19        \u001b[36m0.0228\u001b[0m       0.9784        \u001b[35m0.0900\u001b[0m  1.2643\n","     20        \u001b[36m0.0207\u001b[0m       \u001b[32m0.9789\u001b[0m        \u001b[35m0.0899\u001b[0m  1.2234\n","     21        \u001b[36m0.0188\u001b[0m       0.9789        0.0900  1.3176\n","     22        \u001b[36m0.0171\u001b[0m       0.9789        0.0901  1.2477\n","     23        \u001b[36m0.0157\u001b[0m       0.9789        0.0903  1.2402\n","     24        \u001b[36m0.0144\u001b[0m       0.9789        0.0906  1.2101\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7296\u001b[0m       \u001b[32m0.4142\u001b[0m        \u001b[35m2.2741\u001b[0m  1.2461\n","      2        \u001b[36m1.4556\u001b[0m       \u001b[32m0.7451\u001b[0m        \u001b[35m0.9907\u001b[0m  1.2327\n","      3        \u001b[36m0.6016\u001b[0m       \u001b[32m0.8946\u001b[0m        \u001b[35m0.4648\u001b[0m  1.2171\n","      4        \u001b[36m0.3032\u001b[0m       \u001b[32m0.9560\u001b[0m        \u001b[35m0.2626\u001b[0m  1.2279\n","      5        \u001b[36m0.1876\u001b[0m       \u001b[32m0.9677\u001b[0m        \u001b[35m0.1872\u001b[0m  1.2196\n","      6        \u001b[36m0.1358\u001b[0m       \u001b[32m0.9728\u001b[0m        \u001b[35m0.1521\u001b[0m  1.2067\n","      7        \u001b[36m0.1068\u001b[0m       \u001b[32m0.9761\u001b[0m        \u001b[35m0.1334\u001b[0m  1.2168\n","      8        \u001b[36m0.0878\u001b[0m       \u001b[32m0.9780\u001b[0m        \u001b[35m0.1216\u001b[0m  1.2374\n","      9        \u001b[36m0.0740\u001b[0m       0.9770        \u001b[35m0.1134\u001b[0m  1.2705\n","     10        \u001b[36m0.0633\u001b[0m       \u001b[32m0.9789\u001b[0m        \u001b[35m0.1076\u001b[0m  1.2235\n","     11        \u001b[36m0.0547\u001b[0m       \u001b[32m0.9794\u001b[0m        \u001b[35m0.1033\u001b[0m  1.2249\n","     12        \u001b[36m0.0476\u001b[0m       \u001b[32m0.9799\u001b[0m        \u001b[35m0.1002\u001b[0m  1.2345\n","     13        \u001b[36m0.0416\u001b[0m       \u001b[32m0.9803\u001b[0m        \u001b[35m0.0979\u001b[0m  1.2212\n","     14        \u001b[36m0.0366\u001b[0m       0.9799        \u001b[35m0.0963\u001b[0m  1.2290\n","     15        \u001b[36m0.0323\u001b[0m       0.9803        \u001b[35m0.0950\u001b[0m  1.2290\n","     16        \u001b[36m0.0287\u001b[0m       0.9803        \u001b[35m0.0942\u001b[0m  1.2189\n","     17        \u001b[36m0.0256\u001b[0m       0.9799        \u001b[35m0.0935\u001b[0m  1.2449\n","     18        \u001b[36m0.0229\u001b[0m       0.9799        \u001b[35m0.0931\u001b[0m  1.2424\n","     19        \u001b[36m0.0206\u001b[0m       0.9803        \u001b[35m0.0929\u001b[0m  1.2177\n","     20        \u001b[36m0.0187\u001b[0m       0.9794        \u001b[35m0.0928\u001b[0m  1.2188\n","     21        \u001b[36m0.0170\u001b[0m       0.9789        0.0928  1.3196\n","     22        \u001b[36m0.0155\u001b[0m       0.9794        0.0930  1.2148\n","     23        \u001b[36m0.0143\u001b[0m       0.9789        0.0932  1.2259\n","     24        \u001b[36m0.0132\u001b[0m       0.9789        0.0934  1.2092\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.7258\u001b[0m       \u001b[32m0.5614\u001b[0m        \u001b[35m2.1296\u001b[0m  1.2333\n","      2        \u001b[36m1.3768\u001b[0m       \u001b[32m0.7113\u001b[0m        \u001b[35m0.8676\u001b[0m  1.2159\n","      3        \u001b[36m0.5825\u001b[0m       \u001b[32m0.9002\u001b[0m        \u001b[35m0.4272\u001b[0m  1.2350\n","      4        \u001b[36m0.3081\u001b[0m       \u001b[32m0.9695\u001b[0m        \u001b[35m0.2381\u001b[0m  1.2324\n","      5        \u001b[36m0.1959\u001b[0m       \u001b[32m0.9738\u001b[0m        \u001b[35m0.1638\u001b[0m  1.2287\n","      6        \u001b[36m0.1379\u001b[0m       \u001b[32m0.9775\u001b[0m        \u001b[35m0.1288\u001b[0m  1.2250\n","      7        \u001b[36m0.1058\u001b[0m       \u001b[32m0.9799\u001b[0m        \u001b[35m0.1104\u001b[0m  1.2301\n","      8        \u001b[36m0.0863\u001b[0m       \u001b[32m0.9813\u001b[0m        \u001b[35m0.0998\u001b[0m  1.2815\n","      9        \u001b[36m0.0727\u001b[0m       \u001b[32m0.9817\u001b[0m        \u001b[35m0.0929\u001b[0m  1.2388\n","     10        \u001b[36m0.0624\u001b[0m       \u001b[32m0.9822\u001b[0m        \u001b[35m0.0882\u001b[0m  1.2426\n","     11        \u001b[36m0.0540\u001b[0m       \u001b[32m0.9831\u001b[0m        \u001b[35m0.0847\u001b[0m  1.2403\n","     12        \u001b[36m0.0472\u001b[0m       0.9831        \u001b[35m0.0820\u001b[0m  1.2351\n","     13        \u001b[36m0.0414\u001b[0m       \u001b[32m0.9845\u001b[0m        \u001b[35m0.0799\u001b[0m  1.2223\n","     14        \u001b[36m0.0364\u001b[0m       \u001b[32m0.9850\u001b[0m        \u001b[35m0.0782\u001b[0m  1.2260\n","     15        \u001b[36m0.0322\u001b[0m       0.9845        \u001b[35m0.0767\u001b[0m  1.2273\n","     16        \u001b[36m0.0285\u001b[0m       0.9845        \u001b[35m0.0756\u001b[0m  1.2648\n","     17        \u001b[36m0.0253\u001b[0m       0.9845        \u001b[35m0.0746\u001b[0m  1.2420\n","     18        \u001b[36m0.0226\u001b[0m       0.9845        \u001b[35m0.0738\u001b[0m  1.2294\n","     19        \u001b[36m0.0202\u001b[0m       0.9841        \u001b[35m0.0731\u001b[0m  1.2307\n","     20        \u001b[36m0.0181\u001b[0m       0.9836        \u001b[35m0.0726\u001b[0m  1.2770\n","     21        \u001b[36m0.0163\u001b[0m       0.9836        \u001b[35m0.0722\u001b[0m  1.2608\n","     22        \u001b[36m0.0147\u001b[0m       0.9836        \u001b[35m0.0719\u001b[0m  1.2331\n","     23        \u001b[36m0.0134\u001b[0m       0.9836        \u001b[35m0.0716\u001b[0m  1.2244\n","     24        \u001b[36m0.0122\u001b[0m       0.9841        \u001b[35m0.0714\u001b[0m  1.2786\n","     25        \u001b[36m0.0112\u001b[0m       0.9836        \u001b[35m0.0713\u001b[0m  1.2186\n","     26        \u001b[36m0.0103\u001b[0m       0.9841        \u001b[35m0.0713\u001b[0m  1.2456\n","     27        \u001b[36m0.0095\u001b[0m       0.9841        \u001b[35m0.0712\u001b[0m  1.2270\n","     28        \u001b[36m0.0089\u001b[0m       0.9841        0.0712  1.2328\n","     29        \u001b[36m0.0083\u001b[0m       0.9841        0.0713  1.2203\n","     30        \u001b[36m0.0078\u001b[0m       0.9841        0.0713  1.2257\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6180\u001b[0m       \u001b[32m0.4522\u001b[0m        \u001b[35m1.9712\u001b[0m  1.2808\n","      2        \u001b[36m1.3509\u001b[0m       \u001b[32m0.7709\u001b[0m        \u001b[35m0.8939\u001b[0m  1.2353\n","      3        \u001b[36m0.5987\u001b[0m       \u001b[32m0.9157\u001b[0m        \u001b[35m0.4088\u001b[0m  1.2257\n","      4        \u001b[36m0.3046\u001b[0m       \u001b[32m0.9667\u001b[0m        \u001b[35m0.2486\u001b[0m  1.2339\n","      5        \u001b[36m0.1950\u001b[0m       \u001b[32m0.9724\u001b[0m        \u001b[35m0.1834\u001b[0m  1.2290\n","      6        \u001b[36m0.1406\u001b[0m       \u001b[32m0.9752\u001b[0m        \u001b[35m0.1508\u001b[0m  1.2225\n","      7        \u001b[36m0.1096\u001b[0m       \u001b[32m0.9780\u001b[0m        \u001b[35m0.1329\u001b[0m  1.2263\n","      8        \u001b[36m0.0898\u001b[0m       0.9775        \u001b[35m0.1221\u001b[0m  1.2403\n","      9        \u001b[36m0.0758\u001b[0m       0.9770        \u001b[35m0.1150\u001b[0m  1.2492\n","     10        \u001b[36m0.0652\u001b[0m       0.9766        \u001b[35m0.1100\u001b[0m  1.2602\n","     11        \u001b[36m0.0568\u001b[0m       0.9775        \u001b[35m0.1064\u001b[0m  1.2494\n","     12        \u001b[36m0.0499\u001b[0m       0.9775        \u001b[35m0.1037\u001b[0m  1.2427\n","     13        \u001b[36m0.0441\u001b[0m       0.9766        \u001b[35m0.1015\u001b[0m  1.2300\n","     14        \u001b[36m0.0391\u001b[0m       0.9766        \u001b[35m0.0998\u001b[0m  1.2230\n","     15        \u001b[36m0.0348\u001b[0m       0.9766        \u001b[35m0.0984\u001b[0m  1.3262\n","     16        \u001b[36m0.0310\u001b[0m       0.9766        \u001b[35m0.0973\u001b[0m  1.2425\n","     17        \u001b[36m0.0278\u001b[0m       0.9766        \u001b[35m0.0964\u001b[0m  1.2273\n","     18        \u001b[36m0.0249\u001b[0m       0.9766        \u001b[35m0.0958\u001b[0m  1.2588\n","     19        \u001b[36m0.0224\u001b[0m       0.9766        \u001b[35m0.0953\u001b[0m  1.2453\n","     20        \u001b[36m0.0203\u001b[0m       0.9770        \u001b[35m0.0950\u001b[0m  1.2351\n","     21        \u001b[36m0.0184\u001b[0m       0.9770        \u001b[35m0.0949\u001b[0m  1.2411\n","     22        \u001b[36m0.0167\u001b[0m       0.9775        \u001b[35m0.0949\u001b[0m  1.2340\n","     23        \u001b[36m0.0153\u001b[0m       0.9775        0.0950  1.2297\n","     24        \u001b[36m0.0141\u001b[0m       0.9770        0.0951  1.2333\n","     25        \u001b[36m0.0130\u001b[0m       0.9766        0.0953  1.2617\n","     26        \u001b[36m0.0121\u001b[0m       0.9766        0.0956  1.2521\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.6154\u001b[0m       \u001b[32m0.4705\u001b[0m        \u001b[35m1.9969\u001b[0m  1.2403\n","      2        \u001b[36m1.2677\u001b[0m       \u001b[32m0.7530\u001b[0m        \u001b[35m0.9302\u001b[0m  1.2287\n","      3        \u001b[36m0.5545\u001b[0m       \u001b[32m0.8833\u001b[0m        \u001b[35m0.4426\u001b[0m  1.2317\n","      4        \u001b[36m0.2896\u001b[0m       \u001b[32m0.9634\u001b[0m        \u001b[35m0.2517\u001b[0m  1.2369\n","      5        \u001b[36m0.1789\u001b[0m       \u001b[32m0.9700\u001b[0m        \u001b[35m0.1788\u001b[0m  1.2308\n","      6        \u001b[36m0.1281\u001b[0m       \u001b[32m0.9742\u001b[0m        \u001b[35m0.1468\u001b[0m  1.2439\n","      7        \u001b[36m0.1004\u001b[0m       \u001b[32m0.9756\u001b[0m        \u001b[35m0.1301\u001b[0m  1.2316\n","      8        \u001b[36m0.0827\u001b[0m       \u001b[32m0.9761\u001b[0m        \u001b[35m0.1198\u001b[0m  1.2121\n","      9        \u001b[36m0.0700\u001b[0m       0.9761        \u001b[35m0.1129\u001b[0m  1.2248\n","     10        \u001b[36m0.0603\u001b[0m       \u001b[32m0.9766\u001b[0m        \u001b[35m0.1079\u001b[0m  1.2216\n","     11        \u001b[36m0.0526\u001b[0m       0.9766        \u001b[35m0.1041\u001b[0m  1.2330\n","     12        \u001b[36m0.0461\u001b[0m       \u001b[32m0.9770\u001b[0m        \u001b[35m0.1013\u001b[0m  1.2546\n","     13        \u001b[36m0.0407\u001b[0m       \u001b[32m0.9780\u001b[0m        \u001b[35m0.0992\u001b[0m  1.2917\n","     14        \u001b[36m0.0361\u001b[0m       \u001b[32m0.9784\u001b[0m        \u001b[35m0.0977\u001b[0m  1.2925\n","     15        \u001b[36m0.0321\u001b[0m       0.9784        \u001b[35m0.0966\u001b[0m  1.2349\n","     16        \u001b[36m0.0286\u001b[0m       0.9784        \u001b[35m0.0958\u001b[0m  1.2325\n","     17        \u001b[36m0.0256\u001b[0m       0.9780        \u001b[35m0.0953\u001b[0m  1.2358\n","     18        \u001b[36m0.0231\u001b[0m       0.9784        \u001b[35m0.0950\u001b[0m  1.2266\n","     19        \u001b[36m0.0209\u001b[0m       0.9784        \u001b[35m0.0949\u001b[0m  1.2167\n","     20        \u001b[36m0.0190\u001b[0m       \u001b[32m0.9789\u001b[0m        \u001b[35m0.0948\u001b[0m  1.2316\n","     21        \u001b[36m0.0173\u001b[0m       0.9789        0.0949  1.2280\n","     22        \u001b[36m0.0159\u001b[0m       \u001b[32m0.9794\u001b[0m        0.0950  1.2664\n","     23        \u001b[36m0.0147\u001b[0m       0.9794        0.0952  1.2182\n","     24        \u001b[36m0.0136\u001b[0m       0.9794        0.0954  1.2306\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","  epoch    train_loss    valid_acc    valid_loss     dur\n","-------  ------------  -----------  ------------  ------\n","      1        \u001b[36m2.2857\u001b[0m       \u001b[32m0.6894\u001b[0m        \u001b[35m1.2004\u001b[0m  1.8220\n","      2        \u001b[36m0.6975\u001b[0m       \u001b[32m0.9116\u001b[0m        \u001b[35m0.3800\u001b[0m  1.8266\n","      3        \u001b[36m0.2765\u001b[0m       \u001b[32m0.9722\u001b[0m        \u001b[35m0.2067\u001b[0m  1.8697\n","      4        \u001b[36m0.1580\u001b[0m       \u001b[32m0.9750\u001b[0m        \u001b[35m0.1451\u001b[0m  1.8329\n","      5        \u001b[36m0.1114\u001b[0m       \u001b[32m0.9753\u001b[0m        \u001b[35m0.1208\u001b[0m  1.8325\n","      6        \u001b[36m0.0884\u001b[0m       \u001b[32m0.9775\u001b[0m        \u001b[35m0.1089\u001b[0m  1.8464\n","      7        \u001b[36m0.0737\u001b[0m       \u001b[32m0.9781\u001b[0m        \u001b[35m0.1019\u001b[0m  1.8639\n","      8        \u001b[36m0.0630\u001b[0m       \u001b[32m0.9788\u001b[0m        \u001b[35m0.0972\u001b[0m  1.8350\n","      9        \u001b[36m0.0545\u001b[0m       \u001b[32m0.9791\u001b[0m        \u001b[35m0.0938\u001b[0m  1.9739\n","     10        \u001b[36m0.0476\u001b[0m       0.9791        \u001b[35m0.0913\u001b[0m  1.8369\n","     11        \u001b[36m0.0418\u001b[0m       \u001b[32m0.9797\u001b[0m        \u001b[35m0.0897\u001b[0m  1.8209\n","     12        \u001b[36m0.0369\u001b[0m       \u001b[32m0.9806\u001b[0m        \u001b[35m0.0885\u001b[0m  1.8218\n","     13        \u001b[36m0.0327\u001b[0m       0.9803        \u001b[35m0.0877\u001b[0m  1.8189\n","     14        \u001b[36m0.0291\u001b[0m       0.9803        \u001b[35m0.0871\u001b[0m  1.8487\n","     15        \u001b[36m0.0259\u001b[0m       0.9803        \u001b[35m0.0867\u001b[0m  1.8541\n","     16        \u001b[36m0.0232\u001b[0m       0.9797        \u001b[35m0.0864\u001b[0m  1.8251\n","     17        \u001b[36m0.0208\u001b[0m       0.9794        \u001b[35m0.0863\u001b[0m  1.8205\n","     18        \u001b[36m0.0188\u001b[0m       0.9794        \u001b[35m0.0862\u001b[0m  1.8236\n","     19        \u001b[36m0.0169\u001b[0m       0.9803        0.0862  1.8659\n","     20        \u001b[36m0.0154\u001b[0m       0.9806        0.0863  1.8394\n","     21        \u001b[36m0.0140\u001b[0m       0.9803        0.0864  1.8293\n","     22        \u001b[36m0.0128\u001b[0m       0.9803        0.0866  1.8383\n","Stopping since valid_loss has not improved in the last 5 epochs.\n","Best parameters: {'callbacks': [('EarlyStopping', <skorch.callbacks.training.EarlyStopping object at 0x7de66474ba00>)], 'lr': 0.1, 'max_epochs': 30, 'module__input_size': 5000, 'module__nonlin': <function relu at 0x7de68ccf08b0>, 'module__num_units': 200}\n","Best score: 0.9802501248379017\n"]}],"source":["# Create GridSearchCV object\n","\n","gs = GridSearchCV(net_cv_gs, param_grid, refit=True, cv=3, scoring='accuracy')\n","\n","\n","\n","# Fit the GridSearchCV object\n","\n","gs.fit(X_cv_updated, y_cv_updted)\n","\n","\n","\n","# Print the best parameters and score\n","\n","print(\"Best parameters:\", gs.best_params_)\n","\n","print(\"Best score:\", gs.best_score_)\n","\n","\n","\n","# You can now use the best estimator to make predictions\n","\n","best_model = gs.best_estimator_"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-10-11T23:54:42.705494Z","iopub.status.busy":"2024-10-11T23:54:42.705039Z","iopub.status.idle":"2024-10-11T23:54:43.275211Z","shell.execute_reply":"2024-10-11T23:54:43.274148Z","shell.execute_reply.started":"2024-10-11T23:54:42.705443Z"},"id":"fH_fhHu82Fxh","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy with Best Model: 0.98\n"]}],"source":["# Predict and get accuracy using best model\n","\n","\n","\n","y_pred_best = best_model.predict(X_cv_updated_test)\n","\n","test_accuracy_best = np.mean(y_pred_best == y_test_np)\n","\n","print(f\"Test Accuracy with Best Model: {test_accuracy_best}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Best Parameters: \n","\n","* Learning Rate: 0.1\n","\n","* Max Epochs: 30\n","\n","* Module Input Size: 5000\n","\n","* Activation: ReLU\n","\n","* Number of Units: 200\n","\n","* Early Stopping: 5 Epochs\n","\n","\n","\n","### The effect of hyperparametrs is significant on the training. Some of the observations are as follows:\n","\n","* Changing learning rate from 0.01 to 0.1 results in a massive improvement in the validation accuracy. This is seen when the validation accuracy improves from ~30% to nearly 97.1%. This may be because increasing the learning rate resulted in \"escaping\" the local minima and converge faster.\n","\n","* Having more units in a layer does not necessarily mean a better accuracy. When the number of units increased from 200 to 300, the accuracy dropped instead of increasing. However, it increased when the number was changed from 100 to 200. This probably implies that 200 units provide sufficient complexity for the model to perform at its best and 300 just leads to overfitting. \n","\n","* ReLU outperforms the other activation functions like tanh (not shown on grid search but tested independently). This may be because ReLU does not suffer from the vanishing gradient problem. \n","\n","* Increasing max_features for the vectorizer (from 100 to 5000) leads to noticeable increase in accuracy from ~75% to ~97%. More features allowed our models to pick up on even more patterns in the text to make accurate predictions. \n","\n","* Early stopping did kick in during training when accuracy stalled for 5 epochs. This allowed the grid search to run at an accelerated pace and find the hyperparameters faster. \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lr48VZEGcXAb"},"source":["\n","\n","---\n","\n","\n","\n","ğŸ“â“ Write your lab report here addressing all questions in the notebook"]},{"cell_type":"markdown","metadata":{"id":"QFJ8eObYcyss"},"source":["# Lab Report\n","\n","\n","\n","## Introduction\n","\n","\n","\n","In this lab, we explored the use of neural networks for language classification using the `skorch` library. We experimented with different vectorizers and hyperparameters to improve the model's performance. The dataset consisted of text data in various languages, and the goal was to classify the text into one of the 20 languages.\n","\n","\n","\n","## Data Preparation\n","\n","\n","\n","We started by preparing the dataset, which involved:\n","\n","- Downloading the dataset.\n","\n","- Combining the training and testing data into dataframes.\n","\n","- Filtering the data to include only the 20 selected languages.\n","\n","- Splitting the data into training and testing sets.\n","\n","- Reorganising the training and test datasets to 80:20 split.\n","\n","- Encoding the labels using `LabelEncoder`.\n","\n","\n","\n","## Feature Extraction\n","\n","\n","\n","We experimented with different feature extraction techniques:\n","\n","- **Count Vectorizer**: Extracted character-level bigrams with a maximum of 100 and 5000 features.\n","\n","- **TF-IDF Vectorizer**: Extracted character-level bigrams with a maximum of 5000 features.\n","\n","\n","\n","## Neural Network Architecture\n","\n","\n","\n","We did not try to improve the vanilla neural network provided in the code template (other than altering the number of units in the hidden layer). This showed how a simple MLP is capable of outperforming ML techniques introduced in part 1 of the assignment. \n","\n","\n","\n","## Experiments and Results\n","\n","\n","\n","### Initial Experiments\n","\n","\n","\n","1. **Count Vectorizer with 100 Features**:\n","\n","    - Achieved a test accuracy of 68.2%.\n","\n","\n","\n","2. **Count Vectorizer with 5000 Features**:\n","\n","    - Improved test accuracy to ~98.1%.\n","\n","\n","\n","3. **TF-IDF Vectorizer**:\n","\n","    - Achieved a test accuracy of ~95.78%.\n","\n","\n","\n","### Why choose `Count Vectorizer` over `TF-IDF Vectoizer` for our grid search?\n","\n","- For our language classification task, the Count Vectorizer showed a slightly higher accuracy (98%) compared to TF-IDF (95.78%). This aligns with expectations for language identification, where the mere presence and frequency of specific character patterns or words are often more indicative of the language than their relative importance across documents.\n","\n","\n","### Hyperparameter Tuning\n","\n","\n","\n","We used `GridSearchCV` to find the best hyperparameters. The best parameters were:\n","\n","- Learning Rate: 0.1\n","\n","- Max Epochs: 30\n","\n","- Module Input Size: 5000\n","\n","- Activation: ReLU\n","\n","- Number of Units: 200\n","\n","\n","\n","The best model achieved a test accuracy of ~98%.\n","\n","\n","\n","### Observations Summary\n","\n","\n","\n","- **Learning Rate**: Increasing the learning rate from 0.01 to 0.1 resulted in a significant improvement in validation accuracy.\n","\n","- **Number of Units**: 200 units provided the best performance, while increasing to 300 units led to overfitting.\n","\n","- **Activation Function**: ReLU was chosen as initial testing done with tanh weren't promising.\n","\n","- **Vectorizer Features**: Increasing the maximum features for the vectorizer from 100 to 5000 led to a noticeable increase in accuracy.\n","\n","- **Early Stopping**: Did kick in during grid search where stalled accuracy led to training being stopped and a new combination of hyperparameters being tested.\n","\n","\n","\n","## Conclusion\n","\n","\n","\n","The experiments demonstrated the importance of hyperparameter tuning and feature extraction in improving the performance of neural networks for language classification. The best model achieved a test accuracy of ~98%, highlighting the effectiveness of the chosen hyperparameters and vectorizer settings.\n","\n","\n","\n","---\n","\n","\n","\n","## Questions\n","\n","\n","\n","### What is the effect of your modifications on validation performance? Discuss potential reasons.\n","\n","\n","* Changing learning rate from 0.01 to 0.1 results in a massive improvement in the validation accuracy. This is seen when the validation accuracy improves from ~30% to nearly 97.1%. This may be because increasing the learning rate resulted in \"escaping\" the local minima and converge faster.\n","\n","* Having more units in a layer does not necessarily mean a better accuracy. When the number of units increased from 200 to 300, the accuracy dropped instead of increasing. However, it increased when the number was changed from 100 to 200. This probably implies that 200 units provide sufficient complexity for the model to perform at its best and 300 just leads to overfitting. \n","\n","* ReLU outperforms the other activation functions like tanh (not shown on grid search but tested independently). This may be because ReLU does not suffer from the vanishing gradient problem. \n","\n","* Increasing max_features for the vectorizer (from 100 to 5000) leads to noticeable increase in accuracy from ~75% to ~97%. More features allowed our models to pick up on even more patterns in the text to make accurate predictions. \n","\n","* Early stopping did kick in during training when accuracy stalled for 5 epochs. This allowed the grid search to run at an accelerated pace and find the hyperparameters faster. "]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"vscode":{"interpreter":{"hash":"bd97b8bffa4d3737e84826bc3d37be3046061822757ce35137ab82ad4c5a2016"}}},"nbformat":4,"nbformat_minor":4}
